{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from skimage import feature\n",
    "from sklearn.metrics import (f1_score, precision_score, recall_score, \n",
    "accuracy_score, confusion_matrix)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import (RBF, Matern)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criarListaImagens(listaCategorias, data_dir, img_size):\n",
    "  lista = []\n",
    "  for categoria in listaCategorias:\n",
    "    path = os.path.join(data_dir, categoria)\n",
    "    class_num = listaCategorias.index(categoria)\n",
    "    for img in os.listdir(path):\n",
    "      try:\n",
    "        img_array = cv2.imread(os.path.join(path, img))\n",
    "        new_array = cv2.resize(img_array, (img_size, img_size))\n",
    "        lista.append([new_array, class_num])\n",
    "      except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "  return lista\n",
    "\n",
    "#----------------------------------------------------------------------#\n",
    "\n",
    "def criaListaTreinoTeste(lista):\n",
    "  classes = []\n",
    "  imagens = []\n",
    "  for imagem in lista:\n",
    "    imagens.append(imagem[0])\n",
    "    classes.append(imagem[1])\n",
    "  return imagens, classes\n",
    "\n",
    "#----------------------------------------------------------------------#\n",
    "\n",
    "def obterImagemPolar(image):\n",
    "  img = image.astype(np.float32)\n",
    "  value = np.sqrt(((img.shape[0]/2.0)**2.0)+((img.shape[1]/2.0)**2.0))\n",
    "  polar_image = cv2.linearPolar(img,(img.shape[0]/2, img.shape[1]/2), value, cv2.WARP_FILL_OUTLIERS)\n",
    "  return polar_image.astype(np.uint8)\n",
    "\n",
    "#----------------------------------------------------------------------#\n",
    "\n",
    "def obtemCanaisCoresRGB(listaOrigem):\n",
    "    listaDestino = []\n",
    "    for imagem in listaOrigem:\n",
    "        b, g, r = cv2.split(imagem)\n",
    "        gray = cv2.cvtColor(imagem, cv2.COLOR_BGR2GRAY)\n",
    "        aux = []\n",
    "        aux.append(obterImagemPolar(b))\n",
    "        aux.append(obterImagemPolar(g))\n",
    "        aux.append(obterImagemPolar(r))\n",
    "        aux.append(obterImagemPolar(gray))\n",
    "        listaDestino.append(aux)\n",
    "\n",
    "    return listaDestino\n",
    "\n",
    "#----------------------------------------------------------------------#\n",
    "\n",
    "def obterCanaisCores(listaOrigem, cvt):\n",
    "    listaDestino = []\n",
    "    for imagem in listaOrigem:    \n",
    "        i = cv2.cvtColor(imagem, cvt)\n",
    "        c1, c2, c3 = cv2.split(i)\n",
    "        aux = []\n",
    "        aux.append(obterImagemPolar(c1))\n",
    "        aux.append(obterImagemPolar(c2))\n",
    "        aux.append(obterImagemPolar(c3))\n",
    "        aux.append(cv2.cvtColor(i, cv2.COLOR_BGR2GRAY))\n",
    "        listaDestino.append(aux)\n",
    "\n",
    "    return listaDestino\n",
    "\n",
    "#----------------------------------------------------------------------#\n",
    "\n",
    "class LocalBinaryPatterns:\n",
    "    def __init__(self, numPoints, radius):\n",
    "        self.numPoints = numPoints\n",
    "        self.radius = radius\n",
    "    def describe(self, image, eps=1e-7):\n",
    "        lbp = feature.local_binary_pattern(image, self.numPoints,\n",
    "            self.radius, method=\"uniform\")\n",
    "        (hist, _) = np.histogram(lbp.ravel(),\n",
    "            bins=np.arange(0, self.numPoints + 3),\n",
    "            range=(0, self.numPoints + 2))\n",
    "        hist = hist.astype(\"float\")\n",
    "        hist /= (hist.sum() + eps)\n",
    "        return hist\n",
    "\n",
    "#----------------------------------------------------------------------#\n",
    "\n",
    "def obtemHistogramaCanais(listaImagens, lbp):\n",
    "  canal_1 = []\n",
    "  canal_2 = []\n",
    "  canal_3 = []\n",
    "  canal_cinza = []\n",
    "  for imagem in listaImagens:\n",
    "    canal_1.append(lbp.describe(imagem[0]))\n",
    "    canal_2.append(lbp.describe(imagem[1]))\n",
    "    canal_3.append(lbp.describe(imagem[2]))\n",
    "    canal_cinza.append(lbp.describe(imagem[3]))\n",
    "  return canal_1, canal_2, canal_3, canal_cinza\n",
    "\n",
    "#----------------------------------------------------------------------#\n",
    "\n",
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\", \"QDA\"]\n",
    "\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
    "        decision_function_shape='ovo', degree=3, gamma='scale', kernel='linear',\n",
    "        max_iter=-1, probability=False, random_state=109, shrinking=True, tol=0.001,\n",
    "        verbose=False),\n",
    "    SVC(C=10000, cache_size=200, class_weight=None, coef0=0.0,\n",
    "        decision_function_shape='ovo', degree=3, gamma=1, kernel='rbf', max_iter=-1,\n",
    "        probability=False, random_state=109, shrinking=True, tol=0.001,verbose=False),    \n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(class_weight=None, criterion='entropy',\n",
    "        max_depth=3, max_features=None, max_leaf_nodes=None,\n",
    "        min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "        min_samples_leaf=50, min_samples_split=2,\n",
    "        min_weight_fraction_leaf=0.0,\n",
    "        random_state=None, splitter='best'),\n",
    "    RandomForestClassifier (bootstrap=False, class_weight=None,\n",
    "        criterion='gini', max_depth=50, max_features='sqrt',\n",
    "        max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "        min_samples_leaf=1, min_samples_split=2,\n",
    "        min_weight_fraction_leaf=0.0, n_estimators=550,\n",
    "        n_jobs=None, oob_score=False, random_state=None,\n",
    "        verbose=0, warm_start=False),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()\n",
    "]\n",
    "\n",
    "#----------------------------------------------------------------------#\n",
    "\n",
    "def xgboost(listaTreino, listaTeste, classesTreino, classesTeste):\n",
    "    m = XGBClassifier(colsample_bytree= 0.6, \n",
    "        gamma= 5, learning_rate= 0.15, max_depth= 5, \n",
    "        min_child_weight= 1, n_estimators= 100, subsample=0.8, eta= 0.3 ).fit(listaTreino, classesTreino)\n",
    "    preds = m.predict(listaTeste)\n",
    "    y_pred = m.predict(listaTeste)     \n",
    "    acc = accuracy_score(classesTeste, y_pred)\n",
    "    f1  = f1_score(classesTeste, y_pred, average='weighted')\n",
    "    cm  = confusion_matrix(classesTeste, y_pred)\n",
    "    ps  = precision_score(classesTeste, y_pred, average='weighted')\n",
    "    rs  = recall_score(classesTeste, y_pred, average='weighted')\n",
    "    return acc, f1, cm, ps, rs\n",
    "\n",
    "#----------------------------------------------------------------------#\n",
    "\n",
    "def utilizarClassificadores(listaTreino, classesTreino, listaTeste, classesTeste, namesClassifiers, classifiers):\n",
    "    listaAccuracy = {}\n",
    "    listaCM = {}\n",
    "    listaF1Score = {}\n",
    "    listaPS = {}\n",
    "    listaRS = {}\n",
    "    for i, c in enumerate(classifiers):\n",
    "        m = c.fit(listaTreino, classesTreino)\n",
    "        y_pred = m.predict(listaTeste)         \n",
    "        listaAccuracy[namesClassifiers[i]] = accuracy_score(classesTeste, y_pred)\n",
    "        listaF1Score[namesClassifiers[i]]  = f1_score(classesTeste, y_pred, average='weighted')\n",
    "        listaCM[namesClassifiers[i]]       = confusion_matrix(classesTeste, y_pred)\n",
    "        listaPS[namesClassifiers[i]]       = precision_score(classesTeste, y_pred, average='weighted')\n",
    "        listaRS[namesClassifiers[i]]       = recall_score(classesTeste, y_pred, average='weighted')\n",
    "    listaAccuracy[\"XGBoost\"], listaF1Score[\"XGBoost\"], listaCM[\"XGBoost\"], listaPS[\"XGBoost\"], listaRS[\"XGBoost\"] = xgboost(np.asarray(listaTreino), np.asarray(listaTeste), np.asarray(classesTreino), np.asarray(classesTeste))\n",
    "    return listaAccuracy , listaF1Score, listaCM, listaPS, listaRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r\"C:\\Users\\Rosana\\Documents\\Mestrado\\DataSets\\RIM_ONE_v2\"\n",
    "categorias = [\"glaucoma\",\"normal\"]\n",
    "img_size = 200\n",
    "listaImagens = criarListaImagens(categorias, data_dir, img_size)\n",
    "random.shuffle(listaImagens)\n",
    "random.shuffle(listaImagens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagens, classes = criaListaTreinoTeste(listaImagens)\n",
    "imagens_treino, imagens_teste, classes_treino, classes_teste = train_test_split(imagens, classes, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163\n",
      "141\n"
     ]
    }
   ],
   "source": [
    "normal = 0\n",
    "glaucoma = 0\n",
    "for i in classes_treino:\n",
    "    if (i == 0):\n",
    "        glaucoma += 1\n",
    "    else:\n",
    "        normal += 1\n",
    "        \n",
    "print(normal)\n",
    "print(glaucoma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n",
      "59\n"
     ]
    }
   ],
   "source": [
    "normal = 0\n",
    "glaucoma = 0\n",
    "for i in classes_teste:\n",
    "    if (i == 0):\n",
    "        glaucoma += 1\n",
    "    else:\n",
    "        normal += 1\n",
    "        \n",
    "print(normal)\n",
    "print(glaucoma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "listaRgbTreino = obtemCanaisCoresRGB(imagens_treino)\n",
    "listaHsvTreino = obterCanaisCores(imagens_treino, cv2.COLOR_BGR2HSV)\n",
    "listaLabTreino = obterCanaisCores(imagens_treino, cv2.COLOR_BGR2LAB)\n",
    "listaLuvTreino = obterCanaisCores(imagens_treino, cv2.COLOR_BGR2LUV)\n",
    "\n",
    "listaRgbTeste = obtemCanaisCoresRGB(imagens_teste)\n",
    "listaHsvTeste = obterCanaisCores(imagens_teste, cv2.COLOR_BGR2HSV)\n",
    "listaLabTeste = obterCanaisCores(imagens_teste, cv2.COLOR_BGR2LAB)\n",
    "listaLuvTeste = obterCanaisCores(imagens_teste, cv2.COLOR_BGR2LUV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classificarImagens(pontos, raio):\n",
    "    _lbp = LocalBinaryPatterns(pontos, raio)\n",
    "\n",
    "    lista_treino_rgb_b, lista_treino_rgb_g, lista_treino_rgb_r, lista_treino_rgb_gray = obtemHistogramaCanais(listaRgbTreino, _lbp)\n",
    "    lista_treino_hsv_h, lista_treino_hsv_s, lista_treino_hsv_v, _ = obtemHistogramaCanais(listaHsvTreino, _lbp)\n",
    "    lista_treino_lab_l, lista_treino_lab_a, lista_treino_lab_b, _ = obtemHistogramaCanais(listaLabTreino, _lbp)\n",
    "    lista_treino_luv_l, lista_treino_luv_u, lista_treino_luv_v, _ = obtemHistogramaCanais(listaLuvTreino, _lbp)\n",
    "\n",
    "    lista_teste_rgb_b, lista_teste_rgb_g, lista_teste_rgb_r, lista_teste_rgb_gray = obtemHistogramaCanais(listaRgbTeste, _lbp)\n",
    "    lista_teste_hsv_h, lista_teste_hsv_s, lista_teste_hsv_v, _ = obtemHistogramaCanais(listaHsvTeste, _lbp)\n",
    "    lista_teste_lab_l, lista_teste_lab_a, lista_teste_lab_b, _ = obtemHistogramaCanais(listaLabTeste, _lbp)\n",
    "    lista_teste_luv_l, lista_teste_luv_u, lista_teste_luv_v, _ = obtemHistogramaCanais(listaLuvTeste, _lbp)\n",
    "\n",
    "    linha = []\n",
    "    listaF1Score = []\n",
    "    listaCM = [] \n",
    "    conf_matrix = []\n",
    "    listaPS = []\n",
    "    listaRS = []\n",
    "\n",
    "    #('------------------ RGB ----------------')\n",
    "    l, f1, cm, ps, rs = pd.Series(utilizarClassificadores(lista_treino_rgb_gray, classes_treino, lista_teste_rgb_gray, classes_teste, names, classifiers))\n",
    "    linha.append(l)\n",
    "    listaF1Score.append(f1)\n",
    "    listaCM.append(cm)\n",
    "    listaPS.append(ps)\n",
    "    listaRS.append(rs)\n",
    "    #('------------------ RGB - R ------------')\n",
    "    l, f1, cm, ps, rs = pd.Series(utilizarClassificadores(lista_treino_rgb_r, classes_treino, lista_teste_rgb_r, classes_teste, names, classifiers))\n",
    "    linha.append(l)\n",
    "    listaF1Score.append(f1)\n",
    "    listaCM.append(cm)\n",
    "    listaPS.append(ps)\n",
    "    listaRS.append(rs)\n",
    "    #('------------------ RGB - G ------------')\n",
    "    l, f1, cm, ps, rs = pd.Series(utilizarClassificadores(lista_treino_rgb_g, classes_treino, lista_teste_rgb_g, classes_teste, names, classifiers))\n",
    "    linha.append(l)\n",
    "    listaF1Score.append(f1)\n",
    "    listaCM.append(cm)\n",
    "    listaPS.append(ps)\n",
    "    listaRS.append(rs)\n",
    "    #('------------------ RGB - B ------------')\n",
    "    l, f1, cm, ps, rs = pd.Series(utilizarClassificadores(lista_treino_rgb_b, classes_treino, lista_teste_rgb_b, classes_teste, names, classifiers))\n",
    "    linha.append(l)\n",
    "    listaF1Score.append(f1)\n",
    "    listaCM.append(cm)\n",
    "    listaPS.append(ps)\n",
    "    listaRS.append(rs)\n",
    "\n",
    "    #('------------------ HSV - H ------------')\n",
    "    l, f1, cm, ps, rs = pd.Series(utilizarClassificadores(lista_treino_hsv_h, classes_treino, lista_teste_hsv_h, classes_teste, names, classifiers))\n",
    "    linha.append(l)\n",
    "    listaF1Score.append(f1)\n",
    "    listaCM.append(cm)\n",
    "    listaPS.append(ps)\n",
    "    listaRS.append(rs)\n",
    "    #('------------------ HSV - S ------------')\n",
    "    l, f1, cm, ps, rs = pd.Series(utilizarClassificadores(lista_treino_hsv_s, classes_treino, lista_teste_hsv_s, classes_teste, names, classifiers))\n",
    "    linha.append(l)\n",
    "    listaF1Score.append(f1)\n",
    "    listaCM.append(cm)\n",
    "    listaPS.append(ps)\n",
    "    listaRS.append(rs)\n",
    "    #('------------------ HSV - V ------------')\n",
    "    l, f1, cm, ps, rs = pd.Series(utilizarClassificadores(lista_treino_hsv_v, classes_treino, lista_teste_hsv_v, classes_teste, names, classifiers))\n",
    "    linha.append(l)\n",
    "    listaF1Score.append(f1)\n",
    "    listaCM.append(cm)\n",
    "    listaPS.append(ps)\n",
    "    listaRS.append(rs)\n",
    "    \n",
    "    \n",
    "    #('------------------ LAB - L ------------')\n",
    "    l, f1, cm, ps, rs = pd.Series(utilizarClassificadores(lista_treino_lab_l, classes_treino, lista_teste_lab_l, classes_teste, names, classifiers))\n",
    "    linha.append(l)\n",
    "    listaF1Score.append(f1)\n",
    "    listaCM.append(cm)\n",
    "    listaPS.append(ps)\n",
    "    listaRS.append(rs)\n",
    "    #('------------------ LAB - A ------------')\n",
    "    l, f1, cm, ps, rs = pd.Series(utilizarClassificadores(lista_treino_lab_a, classes_treino, lista_teste_lab_a, classes_teste, names, classifiers))\n",
    "    linha.append(l)\n",
    "    listaF1Score.append(f1)\n",
    "    listaCM.append(cm)\n",
    "    listaPS.append(ps)\n",
    "    listaRS.append(rs)\n",
    "    #('------------------ LAB - B ------------')\n",
    "    l, f1, cm, ps, rs = pd.Series(utilizarClassificadores(lista_treino_lab_b, classes_treino, lista_teste_lab_b, classes_teste, names, classifiers))\n",
    "    linha.append(l)\n",
    "    listaF1Score.append(f1)\n",
    "    listaCM.append(cm)\n",
    "    listaPS.append(ps)\n",
    "    listaRS.append(rs)\n",
    "    \n",
    "    #('------------------ LUV - L ------------')\n",
    "    l, f1, cm, ps, rs = pd.Series(utilizarClassificadores(lista_treino_luv_l, classes_treino, lista_teste_luv_l, classes_teste, names, classifiers))\n",
    "    linha.append(l)\n",
    "    listaF1Score.append(f1)\n",
    "    listaCM.append(cm)\n",
    "    listaPS.append(ps)\n",
    "    listaRS.append(rs)    \n",
    "    \n",
    "    #('------------------ LUV - U ------------')\n",
    "    l, f1, cm, ps, rs = pd.Series(utilizarClassificadores(lista_treino_luv_u, classes_treino, lista_teste_luv_u, classes_teste, names, classifiers))\n",
    "    linha.append(l)\n",
    "    listaF1Score.append(f1)\n",
    "    listaCM.append(cm)\n",
    "    listaPS.append(ps)\n",
    "    listaRS.append(rs)    \n",
    "    \n",
    "    #('------------------ LUV - V ------------')\n",
    "    l, f1, cm, ps, rs = pd.Series(utilizarClassificadores(lista_treino_luv_v, classes_treino, lista_teste_luv_v, classes_teste, names, classifiers))\n",
    "    linha.append(l)\n",
    "    listaF1Score.append(f1)\n",
    "    listaCM.append(cm)\n",
    "    listaPS.append(ps)\n",
    "    listaRS.append(rs)    \n",
    "        \n",
    "    return linha, listaF1Score, listaCM, listaPS, listaRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obterResultados (pontos, raio):\n",
    "    linhas, listaF1Score, listaCM, listaPS, listaRS = classificarImagens(pontos, raio)\n",
    "    print('------ %s pontos - %s raio ------' % (pontos, raio))\n",
    "    print('--- Acuracia ---')\n",
    "    display(pd.DataFrame(linhas))\n",
    "    print('--- F1 ---')\n",
    "    display(pd.DataFrame(listaF1Score))\n",
    "    print('--- Precision Score ---')\n",
    "    display(pd.DataFrame(listaPS))\n",
    "    print('--- Recall Score ---')\n",
    "    display(pd.DataFrame(listaRS))\n",
    "    print('--- Matriz confusao ---')\n",
    "    display(pd.DataFrame(listaCM))\n",
    "    print('---------------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ 4 pontos - 1 raio ------\n",
      "--- Acuracia ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.874172</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.841060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.794702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.874172</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.847682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.880795</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.834437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.642384</td>\n",
       "      <td>0.721854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.655629</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.754967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.682119</td>\n",
       "      <td>0.794702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.867550</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.821192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.682119</td>\n",
       "      <td>0.615894</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.754967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.801325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.867550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.615894</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.715232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.807947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.801325    0.847682  0.874172          0.834437       0.781457   \n",
       "1            0.728477    0.814570  0.801325          0.807947       0.754967   \n",
       "2            0.807947    0.847682  0.874172          0.854305       0.814570   \n",
       "3            0.801325    0.854305  0.880795          0.847682       0.735099   \n",
       "4            0.735099    0.735099  0.741722          0.741722       0.688742   \n",
       "5            0.708609    0.788079  0.794702          0.741722       0.655629   \n",
       "6            0.728477    0.814570  0.801325          0.807947       0.754967   \n",
       "7            0.801325    0.841060  0.867550          0.834437       0.774834   \n",
       "8            0.735099    0.781457  0.807947          0.774834       0.701987   \n",
       "9            0.761589    0.841060  0.854305          0.821192       0.821192   \n",
       "10           0.754967    0.821192  0.847682          0.834437       0.761589   \n",
       "11           0.794702    0.774834  0.781457          0.788079       0.728477   \n",
       "12           0.741722    0.794702  0.807947          0.794702       0.754967   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.827815    0.609272  0.807947     0.728477  0.794702  0.841060  \n",
       "1        0.794702    0.609272  0.728477     0.701987  0.688742  0.794702  \n",
       "2        0.827815    0.609272  0.801325     0.735099  0.781457  0.847682  \n",
       "3        0.821192    0.609272  0.841060     0.748344  0.761589  0.834437  \n",
       "4        0.715232    0.609272  0.715232     0.708609  0.642384  0.721854  \n",
       "5        0.735099    0.609272  0.741722     0.728477  0.781457  0.754967  \n",
       "6        0.794702    0.609272  0.728477     0.701987  0.682119  0.794702  \n",
       "7        0.854305    0.609272  0.821192     0.748344  0.774834  0.821192  \n",
       "8        0.682119    0.615894  0.748344     0.761589  0.768212  0.754967  \n",
       "9        0.768212    0.609272  0.761589     0.794702  0.715232  0.801325  \n",
       "10       0.827815    0.609272  0.827815     0.754967  0.781457  0.867550  \n",
       "11       0.748344    0.615894  0.708609     0.728477  0.728477  0.715232  \n",
       "12       0.794702    0.609272  0.774834     0.768212  0.735099  0.807947  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- F1 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.799953</td>\n",
       "      <td>0.847443</td>\n",
       "      <td>0.873975</td>\n",
       "      <td>0.835117</td>\n",
       "      <td>0.783827</td>\n",
       "      <td>0.828724</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.807645</td>\n",
       "      <td>0.715128</td>\n",
       "      <td>0.788767</td>\n",
       "      <td>0.841511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.728876</td>\n",
       "      <td>0.811690</td>\n",
       "      <td>0.801889</td>\n",
       "      <td>0.808229</td>\n",
       "      <td>0.757850</td>\n",
       "      <td>0.792876</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.726061</td>\n",
       "      <td>0.676843</td>\n",
       "      <td>0.623388</td>\n",
       "      <td>0.794380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.806238</td>\n",
       "      <td>0.847443</td>\n",
       "      <td>0.874357</td>\n",
       "      <td>0.854718</td>\n",
       "      <td>0.813968</td>\n",
       "      <td>0.825921</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.723061</td>\n",
       "      <td>0.768994</td>\n",
       "      <td>0.847906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.797247</td>\n",
       "      <td>0.853832</td>\n",
       "      <td>0.881133</td>\n",
       "      <td>0.845670</td>\n",
       "      <td>0.737488</td>\n",
       "      <td>0.817979</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.839962</td>\n",
       "      <td>0.736908</td>\n",
       "      <td>0.734894</td>\n",
       "      <td>0.831462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.733270</td>\n",
       "      <td>0.733270</td>\n",
       "      <td>0.741316</td>\n",
       "      <td>0.742101</td>\n",
       "      <td>0.692481</td>\n",
       "      <td>0.717574</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.717574</td>\n",
       "      <td>0.697411</td>\n",
       "      <td>0.549115</td>\n",
       "      <td>0.722644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.710148</td>\n",
       "      <td>0.786616</td>\n",
       "      <td>0.795004</td>\n",
       "      <td>0.739424</td>\n",
       "      <td>0.648280</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.743364</td>\n",
       "      <td>0.720627</td>\n",
       "      <td>0.782847</td>\n",
       "      <td>0.753736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.728876</td>\n",
       "      <td>0.811690</td>\n",
       "      <td>0.801889</td>\n",
       "      <td>0.808229</td>\n",
       "      <td>0.757850</td>\n",
       "      <td>0.792876</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.726061</td>\n",
       "      <td>0.676843</td>\n",
       "      <td>0.612362</td>\n",
       "      <td>0.794380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.802783</td>\n",
       "      <td>0.840544</td>\n",
       "      <td>0.867120</td>\n",
       "      <td>0.835490</td>\n",
       "      <td>0.777527</td>\n",
       "      <td>0.853299</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.820911</td>\n",
       "      <td>0.736908</td>\n",
       "      <td>0.759080</td>\n",
       "      <td>0.821455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.779513</td>\n",
       "      <td>0.806238</td>\n",
       "      <td>0.773280</td>\n",
       "      <td>0.702425</td>\n",
       "      <td>0.684986</td>\n",
       "      <td>0.476272</td>\n",
       "      <td>0.749674</td>\n",
       "      <td>0.752427</td>\n",
       "      <td>0.748656</td>\n",
       "      <td>0.753736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.758968</td>\n",
       "      <td>0.841511</td>\n",
       "      <td>0.854718</td>\n",
       "      <td>0.822663</td>\n",
       "      <td>0.819601</td>\n",
       "      <td>0.769164</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.764051</td>\n",
       "      <td>0.794380</td>\n",
       "      <td>0.669842</td>\n",
       "      <td>0.802783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.755974</td>\n",
       "      <td>0.819601</td>\n",
       "      <td>0.847906</td>\n",
       "      <td>0.835117</td>\n",
       "      <td>0.764470</td>\n",
       "      <td>0.827256</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.826626</td>\n",
       "      <td>0.746360</td>\n",
       "      <td>0.783379</td>\n",
       "      <td>0.867550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.795546</td>\n",
       "      <td>0.772358</td>\n",
       "      <td>0.781114</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.726061</td>\n",
       "      <td>0.749674</td>\n",
       "      <td>0.476272</td>\n",
       "      <td>0.709436</td>\n",
       "      <td>0.715128</td>\n",
       "      <td>0.699677</td>\n",
       "      <td>0.713802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.741316</td>\n",
       "      <td>0.796391</td>\n",
       "      <td>0.807645</td>\n",
       "      <td>0.796391</td>\n",
       "      <td>0.755974</td>\n",
       "      <td>0.795004</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.767848</td>\n",
       "      <td>0.730985</td>\n",
       "      <td>0.809527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.799953    0.847443  0.873975          0.835117       0.783827   \n",
       "1            0.728876    0.811690  0.801889          0.808229       0.757850   \n",
       "2            0.806238    0.847443  0.874357          0.854718       0.813968   \n",
       "3            0.797247    0.853832  0.881133          0.845670       0.737488   \n",
       "4            0.733270    0.733270  0.741316          0.742101       0.692481   \n",
       "5            0.710148    0.786616  0.795004          0.739424       0.648280   \n",
       "6            0.728876    0.811690  0.801889          0.808229       0.757850   \n",
       "7            0.802783    0.840544  0.867120          0.835490       0.777527   \n",
       "8            0.735099    0.779513  0.806238          0.773280       0.702425   \n",
       "9            0.758968    0.841511  0.854718          0.822663       0.819601   \n",
       "10           0.755974    0.819601  0.847906          0.835117       0.764470   \n",
       "11           0.795546    0.772358  0.781114          0.788079       0.726061   \n",
       "12           0.741316    0.796391  0.807645          0.796391       0.755974   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.828724    0.461341  0.807645     0.715128  0.788767  0.841511  \n",
       "1        0.792876    0.461341  0.726061     0.676843  0.623388  0.794380  \n",
       "2        0.825921    0.461341  0.801325     0.723061  0.768994  0.847906  \n",
       "3        0.817979    0.461341  0.839962     0.736908  0.734894  0.831462  \n",
       "4        0.717574    0.461341  0.717574     0.697411  0.549115  0.722644  \n",
       "5        0.735099    0.461341  0.743364     0.720627  0.782847  0.753736  \n",
       "6        0.792876    0.461341  0.726061     0.676843  0.612362  0.794380  \n",
       "7        0.853299    0.461341  0.820911     0.736908  0.759080  0.821455  \n",
       "8        0.684986    0.476272  0.749674     0.752427  0.748656  0.753736  \n",
       "9        0.769164    0.461341  0.764051     0.794380  0.669842  0.802783  \n",
       "10       0.827256    0.461341  0.826626     0.746360  0.783379  0.867550  \n",
       "11       0.749674    0.476272  0.709436     0.715128  0.699677  0.713802  \n",
       "12       0.795004    0.461341  0.774834     0.767848  0.730985  0.809527  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Precision Score ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.799754</td>\n",
       "      <td>0.847281</td>\n",
       "      <td>0.873857</td>\n",
       "      <td>0.836468</td>\n",
       "      <td>0.794459</td>\n",
       "      <td>0.830810</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.807417</td>\n",
       "      <td>0.727882</td>\n",
       "      <td>0.795896</td>\n",
       "      <td>0.842263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.729339</td>\n",
       "      <td>0.813718</td>\n",
       "      <td>0.802738</td>\n",
       "      <td>0.808584</td>\n",
       "      <td>0.784623</td>\n",
       "      <td>0.792875</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.725291</td>\n",
       "      <td>0.705790</td>\n",
       "      <td>0.767518</td>\n",
       "      <td>0.794129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.806392</td>\n",
       "      <td>0.847281</td>\n",
       "      <td>0.874621</td>\n",
       "      <td>0.855439</td>\n",
       "      <td>0.813662</td>\n",
       "      <td>0.826805</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.734544</td>\n",
       "      <td>0.792728</td>\n",
       "      <td>0.848206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.800794</td>\n",
       "      <td>0.853672</td>\n",
       "      <td>0.881789</td>\n",
       "      <td>0.847574</td>\n",
       "      <td>0.743986</td>\n",
       "      <td>0.821086</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.840106</td>\n",
       "      <td>0.749613</td>\n",
       "      <td>0.803999</td>\n",
       "      <td>0.834933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.732501</td>\n",
       "      <td>0.732501</td>\n",
       "      <td>0.740977</td>\n",
       "      <td>0.742547</td>\n",
       "      <td>0.709715</td>\n",
       "      <td>0.722975</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.722975</td>\n",
       "      <td>0.703544</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.723688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.712680</td>\n",
       "      <td>0.786303</td>\n",
       "      <td>0.795376</td>\n",
       "      <td>0.738808</td>\n",
       "      <td>0.767140</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.746634</td>\n",
       "      <td>0.724413</td>\n",
       "      <td>0.785959</td>\n",
       "      <td>0.753118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.729339</td>\n",
       "      <td>0.813718</td>\n",
       "      <td>0.802738</td>\n",
       "      <td>0.808584</td>\n",
       "      <td>0.784623</td>\n",
       "      <td>0.792875</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.725291</td>\n",
       "      <td>0.705790</td>\n",
       "      <td>0.762438</td>\n",
       "      <td>0.794129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.806784</td>\n",
       "      <td>0.840335</td>\n",
       "      <td>0.867008</td>\n",
       "      <td>0.838392</td>\n",
       "      <td>0.802199</td>\n",
       "      <td>0.853557</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.820705</td>\n",
       "      <td>0.749613</td>\n",
       "      <td>0.791864</td>\n",
       "      <td>0.821791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.779358</td>\n",
       "      <td>0.806392</td>\n",
       "      <td>0.772853</td>\n",
       "      <td>0.702924</td>\n",
       "      <td>0.691646</td>\n",
       "      <td>0.764415</td>\n",
       "      <td>0.752057</td>\n",
       "      <td>0.762456</td>\n",
       "      <td>0.792441</td>\n",
       "      <td>0.753118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.758858</td>\n",
       "      <td>0.842263</td>\n",
       "      <td>0.855439</td>\n",
       "      <td>0.827679</td>\n",
       "      <td>0.819909</td>\n",
       "      <td>0.770729</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.773165</td>\n",
       "      <td>0.794129</td>\n",
       "      <td>0.770239</td>\n",
       "      <td>0.806784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.757581</td>\n",
       "      <td>0.819909</td>\n",
       "      <td>0.848206</td>\n",
       "      <td>0.836468</td>\n",
       "      <td>0.784380</td>\n",
       "      <td>0.826999</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.826656</td>\n",
       "      <td>0.754271</td>\n",
       "      <td>0.828731</td>\n",
       "      <td>0.867550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.797024</td>\n",
       "      <td>0.772448</td>\n",
       "      <td>0.780841</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.725291</td>\n",
       "      <td>0.752057</td>\n",
       "      <td>0.764415</td>\n",
       "      <td>0.710513</td>\n",
       "      <td>0.727882</td>\n",
       "      <td>0.751904</td>\n",
       "      <td>0.712946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.740977</td>\n",
       "      <td>0.801503</td>\n",
       "      <td>0.807417</td>\n",
       "      <td>0.801503</td>\n",
       "      <td>0.757581</td>\n",
       "      <td>0.795376</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.767553</td>\n",
       "      <td>0.731193</td>\n",
       "      <td>0.814591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.799754    0.847281  0.873857          0.836468       0.794459   \n",
       "1            0.729339    0.813718  0.802738          0.808584       0.784623   \n",
       "2            0.806392    0.847281  0.874621          0.855439       0.813662   \n",
       "3            0.800794    0.853672  0.881789          0.847574       0.743986   \n",
       "4            0.732501    0.732501  0.740977          0.742547       0.709715   \n",
       "5            0.712680    0.786303  0.795376          0.738808       0.767140   \n",
       "6            0.729339    0.813718  0.802738          0.808584       0.784623   \n",
       "7            0.806784    0.840335  0.867008          0.838392       0.802199   \n",
       "8            0.735099    0.779358  0.806392          0.772853       0.702924   \n",
       "9            0.758858    0.842263  0.855439          0.827679       0.819909   \n",
       "10           0.757581    0.819909  0.848206          0.836468       0.784380   \n",
       "11           0.797024    0.772448  0.780841          0.788079       0.725291   \n",
       "12           0.740977    0.801503  0.807417          0.801503       0.757581   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.830810    0.371212  0.807417     0.727882  0.795896  0.842263  \n",
       "1        0.792875    0.371212  0.725291     0.705790  0.767518  0.794129  \n",
       "2        0.826805    0.371212  0.801325     0.734544  0.792728  0.848206  \n",
       "3        0.821086    0.371212  0.840106     0.749613  0.803999  0.834933  \n",
       "4        0.722975    0.371212  0.722975     0.703544  0.690058  0.723688  \n",
       "5        0.735099    0.371212  0.746634     0.724413  0.785959  0.753118  \n",
       "6        0.792875    0.371212  0.725291     0.705790  0.762438  0.794129  \n",
       "7        0.853557    0.371212  0.820705     0.749613  0.791864  0.821791  \n",
       "8        0.691646    0.764415  0.752057     0.762456  0.792441  0.753118  \n",
       "9        0.770729    0.371212  0.773165     0.794129  0.770239  0.806784  \n",
       "10       0.826999    0.371212  0.826656     0.754271  0.828731  0.867550  \n",
       "11       0.752057    0.764415  0.710513     0.727882  0.751904  0.712946  \n",
       "12       0.795376    0.371212  0.774834     0.767553  0.731193  0.814591  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Recall Score ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.874172</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.841060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.794702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.874172</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.847682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.880795</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.834437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.642384</td>\n",
       "      <td>0.721854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.655629</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.754967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.682119</td>\n",
       "      <td>0.794702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.867550</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.821192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.682119</td>\n",
       "      <td>0.615894</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.754967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.801325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.867550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.615894</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.715232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.807947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.801325    0.847682  0.874172          0.834437       0.781457   \n",
       "1            0.728477    0.814570  0.801325          0.807947       0.754967   \n",
       "2            0.807947    0.847682  0.874172          0.854305       0.814570   \n",
       "3            0.801325    0.854305  0.880795          0.847682       0.735099   \n",
       "4            0.735099    0.735099  0.741722          0.741722       0.688742   \n",
       "5            0.708609    0.788079  0.794702          0.741722       0.655629   \n",
       "6            0.728477    0.814570  0.801325          0.807947       0.754967   \n",
       "7            0.801325    0.841060  0.867550          0.834437       0.774834   \n",
       "8            0.735099    0.781457  0.807947          0.774834       0.701987   \n",
       "9            0.761589    0.841060  0.854305          0.821192       0.821192   \n",
       "10           0.754967    0.821192  0.847682          0.834437       0.761589   \n",
       "11           0.794702    0.774834  0.781457          0.788079       0.728477   \n",
       "12           0.741722    0.794702  0.807947          0.794702       0.754967   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.827815    0.609272  0.807947     0.728477  0.794702  0.841060  \n",
       "1        0.794702    0.609272  0.728477     0.701987  0.688742  0.794702  \n",
       "2        0.827815    0.609272  0.801325     0.735099  0.781457  0.847682  \n",
       "3        0.821192    0.609272  0.841060     0.748344  0.761589  0.834437  \n",
       "4        0.715232    0.609272  0.715232     0.708609  0.642384  0.721854  \n",
       "5        0.735099    0.609272  0.741722     0.728477  0.781457  0.754967  \n",
       "6        0.794702    0.609272  0.728477     0.701987  0.682119  0.794702  \n",
       "7        0.854305    0.609272  0.821192     0.748344  0.774834  0.821192  \n",
       "8        0.682119    0.615894  0.748344     0.761589  0.768212  0.754967  \n",
       "9        0.768212    0.609272  0.761589     0.794702  0.715232  0.801325  \n",
       "10       0.827815    0.609272  0.827815     0.754967  0.781457  0.867550  \n",
       "11       0.748344    0.615894  0.708609     0.728477  0.728477  0.715232  \n",
       "12       0.794702    0.609272  0.774834     0.768212  0.735099  0.807947  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Matriz confusao ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[42, 17], [13, 79]]</td>\n",
       "      <td>[[47, 12], [11, 81]]</td>\n",
       "      <td>[[49, 10], [9, 83]]</td>\n",
       "      <td>[[48, 11], [14, 78]]</td>\n",
       "      <td>[[48, 11], [22, 70]]</td>\n",
       "      <td>[[48, 11], [15, 77]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[44, 15], [14, 78]]</td>\n",
       "      <td>[[29, 30], [11, 81]]</td>\n",
       "      <td>[[37, 22], [9, 83]]</td>\n",
       "      <td>[[48, 11], [13, 79]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[39, 20], [21, 71]]</td>\n",
       "      <td>[[41, 18], [10, 82]]</td>\n",
       "      <td>[[45, 14], [16, 76]]</td>\n",
       "      <td>[[45, 14], [15, 77]]</td>\n",
       "      <td>[[50, 9], [28, 64]]</td>\n",
       "      <td>[[41, 18], [13, 79]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[36, 23], [18, 74]]</td>\n",
       "      <td>[[23, 36], [9, 83]]</td>\n",
       "      <td>[[13, 46], [1, 91]]</td>\n",
       "      <td>[[43, 16], [15, 77]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[42, 17], [12, 80]]</td>\n",
       "      <td>[[47, 12], [11, 81]]</td>\n",
       "      <td>[[50, 9], [10, 82]]</td>\n",
       "      <td>[[49, 10], [12, 80]]</td>\n",
       "      <td>[[44, 15], [13, 79]]</td>\n",
       "      <td>[[43, 16], [10, 82]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[44, 15], [15, 77]]</td>\n",
       "      <td>[[30, 29], [11, 81]]</td>\n",
       "      <td>[[32, 27], [6, 86]]</td>\n",
       "      <td>[[48, 11], [12, 80]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[39, 20], [10, 82]]</td>\n",
       "      <td>[[47, 12], [10, 82]]</td>\n",
       "      <td>[[51, 8], [10, 82]]</td>\n",
       "      <td>[[44, 15], [8, 84]]</td>\n",
       "      <td>[[43, 16], [24, 68]]</td>\n",
       "      <td>[[41, 18], [9, 83]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[45, 14], [10, 82]]</td>\n",
       "      <td>[[31, 28], [10, 82]]</td>\n",
       "      <td>[[25, 34], [2, 90]]</td>\n",
       "      <td>[[42, 17], [8, 84]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[37, 22], [18, 74]]</td>\n",
       "      <td>[[37, 22], [18, 74]]</td>\n",
       "      <td>[[39, 20], [19, 73]]</td>\n",
       "      <td>[[40, 19], [20, 72]]</td>\n",
       "      <td>[[43, 16], [31, 61]]</td>\n",
       "      <td>[[41, 18], [25, 67]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[41, 18], [25, 67]]</td>\n",
       "      <td>[[29, 30], [14, 78]]</td>\n",
       "      <td>[[7, 52], [2, 90]]</td>\n",
       "      <td>[[39, 20], [22, 70]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[[39, 20], [24, 68]]</td>\n",
       "      <td>[[41, 18], [14, 78]]</td>\n",
       "      <td>[[44, 15], [16, 76]]</td>\n",
       "      <td>[[37, 22], [17, 75]]</td>\n",
       "      <td>[[55, 4], [48, 44]]</td>\n",
       "      <td>[[39, 20], [20, 72]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[42, 17], [22, 70]]</td>\n",
       "      <td>[[32, 27], [14, 78]]</td>\n",
       "      <td>[[45, 14], [19, 73]]</td>\n",
       "      <td>[[39, 20], [17, 75]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[[39, 20], [21, 71]]</td>\n",
       "      <td>[[41, 18], [10, 82]]</td>\n",
       "      <td>[[45, 14], [16, 76]]</td>\n",
       "      <td>[[45, 14], [15, 77]]</td>\n",
       "      <td>[[50, 9], [28, 64]]</td>\n",
       "      <td>[[41, 18], [13, 79]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[36, 23], [18, 74]]</td>\n",
       "      <td>[[23, 36], [9, 83]]</td>\n",
       "      <td>[[12, 47], [1, 91]]</td>\n",
       "      <td>[[43, 16], [15, 77]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[[47, 12], [18, 74]]</td>\n",
       "      <td>[[46, 13], [11, 81]]</td>\n",
       "      <td>[[48, 11], [9, 83]]</td>\n",
       "      <td>[[49, 10], [15, 77]]</td>\n",
       "      <td>[[51, 8], [26, 66]]</td>\n",
       "      <td>[[46, 13], [9, 83]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[45, 14], [13, 79]]</td>\n",
       "      <td>[[31, 28], [10, 82]]</td>\n",
       "      <td>[[30, 29], [5, 87]]</td>\n",
       "      <td>[[46, 13], [14, 78]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[[39, 20], [20, 72]]</td>\n",
       "      <td>[[40, 19], [14, 78]]</td>\n",
       "      <td>[[42, 17], [12, 80]]</td>\n",
       "      <td>[[40, 19], [15, 77]]</td>\n",
       "      <td>[[37, 22], [23, 69]]</td>\n",
       "      <td>[[39, 20], [28, 64]]</td>\n",
       "      <td>[[1, 58], [0, 92]]</td>\n",
       "      <td>[[42, 17], [21, 71]]</td>\n",
       "      <td>[[33, 26], [10, 82]]</td>\n",
       "      <td>[[28, 31], [4, 88]]</td>\n",
       "      <td>[[39, 20], [17, 75]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[[38, 21], [15, 77]]</td>\n",
       "      <td>[[48, 11], [13, 79]]</td>\n",
       "      <td>[[49, 10], [12, 80]]</td>\n",
       "      <td>[[49, 10], [17, 75]]</td>\n",
       "      <td>[[43, 16], [11, 81]]</td>\n",
       "      <td>[[43, 16], [19, 73]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[46, 13], [23, 69]]</td>\n",
       "      <td>[[43, 16], [15, 77]]</td>\n",
       "      <td>[[18, 41], [2, 90]]</td>\n",
       "      <td>[[47, 12], [18, 74]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[[42, 17], [20, 72]]</td>\n",
       "      <td>[[43, 16], [11, 81]]</td>\n",
       "      <td>[[48, 11], [12, 80]]</td>\n",
       "      <td>[[48, 11], [14, 78]]</td>\n",
       "      <td>[[49, 10], [26, 66]]</td>\n",
       "      <td>[[45, 14], [12, 80]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[44, 15], [11, 81]]</td>\n",
       "      <td>[[33, 26], [11, 81]]</td>\n",
       "      <td>[[55, 4], [29, 63]]</td>\n",
       "      <td>[[49, 10], [10, 82]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[[45, 14], [17, 75]]</td>\n",
       "      <td>[[39, 20], [14, 78]]</td>\n",
       "      <td>[[42, 17], [16, 76]]</td>\n",
       "      <td>[[43, 16], [16, 76]]</td>\n",
       "      <td>[[36, 23], [18, 74]]</td>\n",
       "      <td>[[42, 17], [21, 71]]</td>\n",
       "      <td>[[1, 58], [0, 92]]</td>\n",
       "      <td>[[38, 21], [23, 69]]</td>\n",
       "      <td>[[29, 30], [11, 81]]</td>\n",
       "      <td>[[23, 36], [5, 87]]</td>\n",
       "      <td>[[36, 23], [20, 72]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[[39, 20], [19, 73]]</td>\n",
       "      <td>[[47, 12], [19, 73]]</td>\n",
       "      <td>[[44, 15], [14, 78]]</td>\n",
       "      <td>[[47, 12], [19, 73]]</td>\n",
       "      <td>[[42, 17], [20, 72]]</td>\n",
       "      <td>[[44, 15], [16, 76]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[42, 17], [17, 75]]</td>\n",
       "      <td>[[41, 18], [17, 75]]</td>\n",
       "      <td>[[35, 24], [16, 76]]</td>\n",
       "      <td>[[48, 11], [18, 74]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Nearest Neighbors            Linear SVM               RBF SVM  \\\n",
       "0   [[42, 17], [13, 79]]  [[47, 12], [11, 81]]   [[49, 10], [9, 83]]   \n",
       "1   [[39, 20], [21, 71]]  [[41, 18], [10, 82]]  [[45, 14], [16, 76]]   \n",
       "2   [[42, 17], [12, 80]]  [[47, 12], [11, 81]]   [[50, 9], [10, 82]]   \n",
       "3   [[39, 20], [10, 82]]  [[47, 12], [10, 82]]   [[51, 8], [10, 82]]   \n",
       "4   [[37, 22], [18, 74]]  [[37, 22], [18, 74]]  [[39, 20], [19, 73]]   \n",
       "5   [[39, 20], [24, 68]]  [[41, 18], [14, 78]]  [[44, 15], [16, 76]]   \n",
       "6   [[39, 20], [21, 71]]  [[41, 18], [10, 82]]  [[45, 14], [16, 76]]   \n",
       "7   [[47, 12], [18, 74]]  [[46, 13], [11, 81]]   [[48, 11], [9, 83]]   \n",
       "8   [[39, 20], [20, 72]]  [[40, 19], [14, 78]]  [[42, 17], [12, 80]]   \n",
       "9   [[38, 21], [15, 77]]  [[48, 11], [13, 79]]  [[49, 10], [12, 80]]   \n",
       "10  [[42, 17], [20, 72]]  [[43, 16], [11, 81]]  [[48, 11], [12, 80]]   \n",
       "11  [[45, 14], [17, 75]]  [[39, 20], [14, 78]]  [[42, 17], [16, 76]]   \n",
       "12  [[39, 20], [19, 73]]  [[47, 12], [19, 73]]  [[44, 15], [14, 78]]   \n",
       "\n",
       "        Gaussian Process         Decision Tree         Random Forest  \\\n",
       "0   [[48, 11], [14, 78]]  [[48, 11], [22, 70]]  [[48, 11], [15, 77]]   \n",
       "1   [[45, 14], [15, 77]]   [[50, 9], [28, 64]]  [[41, 18], [13, 79]]   \n",
       "2   [[49, 10], [12, 80]]  [[44, 15], [13, 79]]  [[43, 16], [10, 82]]   \n",
       "3    [[44, 15], [8, 84]]  [[43, 16], [24, 68]]   [[41, 18], [9, 83]]   \n",
       "4   [[40, 19], [20, 72]]  [[43, 16], [31, 61]]  [[41, 18], [25, 67]]   \n",
       "5   [[37, 22], [17, 75]]   [[55, 4], [48, 44]]  [[39, 20], [20, 72]]   \n",
       "6   [[45, 14], [15, 77]]   [[50, 9], [28, 64]]  [[41, 18], [13, 79]]   \n",
       "7   [[49, 10], [15, 77]]   [[51, 8], [26, 66]]   [[46, 13], [9, 83]]   \n",
       "8   [[40, 19], [15, 77]]  [[37, 22], [23, 69]]  [[39, 20], [28, 64]]   \n",
       "9   [[49, 10], [17, 75]]  [[43, 16], [11, 81]]  [[43, 16], [19, 73]]   \n",
       "10  [[48, 11], [14, 78]]  [[49, 10], [26, 66]]  [[45, 14], [12, 80]]   \n",
       "11  [[43, 16], [16, 76]]  [[36, 23], [18, 74]]  [[42, 17], [21, 71]]   \n",
       "12  [[47, 12], [19, 73]]  [[42, 17], [20, 72]]  [[44, 15], [16, 76]]   \n",
       "\n",
       "            Neural Net              AdaBoost           Naive Bayes  \\\n",
       "0   [[0, 59], [0, 92]]  [[44, 15], [14, 78]]  [[29, 30], [11, 81]]   \n",
       "1   [[0, 59], [0, 92]]  [[36, 23], [18, 74]]   [[23, 36], [9, 83]]   \n",
       "2   [[0, 59], [0, 92]]  [[44, 15], [15, 77]]  [[30, 29], [11, 81]]   \n",
       "3   [[0, 59], [0, 92]]  [[45, 14], [10, 82]]  [[31, 28], [10, 82]]   \n",
       "4   [[0, 59], [0, 92]]  [[41, 18], [25, 67]]  [[29, 30], [14, 78]]   \n",
       "5   [[0, 59], [0, 92]]  [[42, 17], [22, 70]]  [[32, 27], [14, 78]]   \n",
       "6   [[0, 59], [0, 92]]  [[36, 23], [18, 74]]   [[23, 36], [9, 83]]   \n",
       "7   [[0, 59], [0, 92]]  [[45, 14], [13, 79]]  [[31, 28], [10, 82]]   \n",
       "8   [[1, 58], [0, 92]]  [[42, 17], [21, 71]]  [[33, 26], [10, 82]]   \n",
       "9   [[0, 59], [0, 92]]  [[46, 13], [23, 69]]  [[43, 16], [15, 77]]   \n",
       "10  [[0, 59], [0, 92]]  [[44, 15], [11, 81]]  [[33, 26], [11, 81]]   \n",
       "11  [[1, 58], [0, 92]]  [[38, 21], [23, 69]]  [[29, 30], [11, 81]]   \n",
       "12  [[0, 59], [0, 92]]  [[42, 17], [17, 75]]  [[41, 18], [17, 75]]   \n",
       "\n",
       "                     QDA               XGBoost  \n",
       "0    [[37, 22], [9, 83]]  [[48, 11], [13, 79]]  \n",
       "1    [[13, 46], [1, 91]]  [[43, 16], [15, 77]]  \n",
       "2    [[32, 27], [6, 86]]  [[48, 11], [12, 80]]  \n",
       "3    [[25, 34], [2, 90]]   [[42, 17], [8, 84]]  \n",
       "4     [[7, 52], [2, 90]]  [[39, 20], [22, 70]]  \n",
       "5   [[45, 14], [19, 73]]  [[39, 20], [17, 75]]  \n",
       "6    [[12, 47], [1, 91]]  [[43, 16], [15, 77]]  \n",
       "7    [[30, 29], [5, 87]]  [[46, 13], [14, 78]]  \n",
       "8    [[28, 31], [4, 88]]  [[39, 20], [17, 75]]  \n",
       "9    [[18, 41], [2, 90]]  [[47, 12], [18, 74]]  \n",
       "10   [[55, 4], [29, 63]]  [[49, 10], [10, 82]]  \n",
       "11   [[23, 36], [5, 87]]  [[36, 23], [20, 72]]  \n",
       "12  [[35, 24], [16, 76]]  [[48, 11], [18, 74]]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ 8 pontos - 1 raio ------\n",
      "--- Acuracia ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.867550</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.860927</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.880795</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.847682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.748344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.860927</td>\n",
       "      <td>0.867550</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.874172</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.860927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.867550</td>\n",
       "      <td>0.887417</td>\n",
       "      <td>0.867550</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.860927</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.854305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.642384</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.801325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.668874</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.794702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.748344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.880795</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.900662</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.907285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.814570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.781457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.874172</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.867550</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.860927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.682119</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.622517</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.774834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.801325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.814570    0.854305  0.854305          0.867550       0.801325   \n",
       "1            0.688742    0.728477  0.801325          0.801325       0.728477   \n",
       "2            0.768212    0.860927  0.867550          0.834437       0.748344   \n",
       "3            0.801325    0.867550  0.887417          0.867550       0.708609   \n",
       "4            0.721854    0.728477  0.748344          0.768212       0.642384   \n",
       "5            0.715232    0.834437  0.841060          0.801325       0.668874   \n",
       "6            0.688742    0.728477  0.801325          0.801325       0.728477   \n",
       "7            0.774834    0.841060  0.847682          0.880795       0.748344   \n",
       "8            0.701987    0.801325  0.807947          0.774834       0.701987   \n",
       "9            0.754967    0.821192  0.821192          0.807947       0.774834   \n",
       "10           0.761589    0.821192  0.854305          0.874172       0.761589   \n",
       "11           0.761589    0.768212  0.781457          0.761589       0.682119   \n",
       "12           0.715232    0.821192  0.827815          0.847682       0.781457   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.860927    0.609272  0.880795     0.728477  0.841060  0.847682  \n",
       "1        0.741722    0.609272  0.741722     0.675497  0.721854  0.748344  \n",
       "2        0.847682    0.609272  0.874172     0.741722  0.814570  0.860927  \n",
       "3        0.834437    0.609272  0.860927     0.748344  0.768212  0.854305  \n",
       "4        0.788079    0.609272  0.781457     0.701987  0.774834  0.801325  \n",
       "5        0.814570    0.609272  0.814570     0.715232  0.781457  0.794702  \n",
       "6        0.748344    0.609272  0.741722     0.675497  0.721854  0.748344  \n",
       "7        0.900662    0.609272  0.834437     0.735099  0.768212  0.907285  \n",
       "8        0.754967    0.609272  0.794702     0.728477  0.748344  0.814570  \n",
       "9        0.774834    0.609272  0.794702     0.761589  0.768212  0.781457  \n",
       "10       0.867550    0.609272  0.834437     0.715232  0.735099  0.860927  \n",
       "11       0.774834    0.622517  0.701987     0.735099  0.768212  0.774834  \n",
       "12       0.807947    0.609272  0.801325     0.788079  0.761589  0.801325  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- F1 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.813968</td>\n",
       "      <td>0.853832</td>\n",
       "      <td>0.853299</td>\n",
       "      <td>0.866093</td>\n",
       "      <td>0.802783</td>\n",
       "      <td>0.860229</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.880408</td>\n",
       "      <td>0.712992</td>\n",
       "      <td>0.842851</td>\n",
       "      <td>0.846917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.685973</td>\n",
       "      <td>0.708221</td>\n",
       "      <td>0.801889</td>\n",
       "      <td>0.800680</td>\n",
       "      <td>0.731116</td>\n",
       "      <td>0.741316</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.741316</td>\n",
       "      <td>0.644719</td>\n",
       "      <td>0.687253</td>\n",
       "      <td>0.747528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.769686</td>\n",
       "      <td>0.860709</td>\n",
       "      <td>0.867120</td>\n",
       "      <td>0.832964</td>\n",
       "      <td>0.749891</td>\n",
       "      <td>0.846327</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.873975</td>\n",
       "      <td>0.732649</td>\n",
       "      <td>0.816659</td>\n",
       "      <td>0.860709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.799953</td>\n",
       "      <td>0.866093</td>\n",
       "      <td>0.886416</td>\n",
       "      <td>0.865493</td>\n",
       "      <td>0.708175</td>\n",
       "      <td>0.832964</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.858428</td>\n",
       "      <td>0.736908</td>\n",
       "      <td>0.769392</td>\n",
       "      <td>0.853299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.719934</td>\n",
       "      <td>0.728050</td>\n",
       "      <td>0.746607</td>\n",
       "      <td>0.765151</td>\n",
       "      <td>0.646077</td>\n",
       "      <td>0.786616</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.781778</td>\n",
       "      <td>0.687336</td>\n",
       "      <td>0.761058</td>\n",
       "      <td>0.797247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.713802</td>\n",
       "      <td>0.832251</td>\n",
       "      <td>0.841511</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.666112</td>\n",
       "      <td>0.813968</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.813289</td>\n",
       "      <td>0.705229</td>\n",
       "      <td>0.768994</td>\n",
       "      <td>0.793671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.685973</td>\n",
       "      <td>0.708221</td>\n",
       "      <td>0.801889</td>\n",
       "      <td>0.800680</td>\n",
       "      <td>0.731116</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.741316</td>\n",
       "      <td>0.644719</td>\n",
       "      <td>0.690710</td>\n",
       "      <td>0.747528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.839962</td>\n",
       "      <td>0.846917</td>\n",
       "      <td>0.879972</td>\n",
       "      <td>0.738673</td>\n",
       "      <td>0.900163</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.832964</td>\n",
       "      <td>0.718891</td>\n",
       "      <td>0.743627</td>\n",
       "      <td>0.906645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.703211</td>\n",
       "      <td>0.800680</td>\n",
       "      <td>0.808229</td>\n",
       "      <td>0.774104</td>\n",
       "      <td>0.705446</td>\n",
       "      <td>0.753736</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.795004</td>\n",
       "      <td>0.720627</td>\n",
       "      <td>0.732947</td>\n",
       "      <td>0.812530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.756983</td>\n",
       "      <td>0.820911</td>\n",
       "      <td>0.821455</td>\n",
       "      <td>0.809168</td>\n",
       "      <td>0.775474</td>\n",
       "      <td>0.775474</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.795546</td>\n",
       "      <td>0.757887</td>\n",
       "      <td>0.762835</td>\n",
       "      <td>0.782847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.819601</td>\n",
       "      <td>0.853832</td>\n",
       "      <td>0.873053</td>\n",
       "      <td>0.753971</td>\n",
       "      <td>0.866635</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.833606</td>\n",
       "      <td>0.696580</td>\n",
       "      <td>0.711386</td>\n",
       "      <td>0.859690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.762266</td>\n",
       "      <td>0.766150</td>\n",
       "      <td>0.781778</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.685771</td>\n",
       "      <td>0.774104</td>\n",
       "      <td>0.490791</td>\n",
       "      <td>0.701519</td>\n",
       "      <td>0.726635</td>\n",
       "      <td>0.753030</td>\n",
       "      <td>0.772358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.715650</td>\n",
       "      <td>0.821927</td>\n",
       "      <td>0.826626</td>\n",
       "      <td>0.848308</td>\n",
       "      <td>0.782847</td>\n",
       "      <td>0.808736</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.801889</td>\n",
       "      <td>0.785749</td>\n",
       "      <td>0.764441</td>\n",
       "      <td>0.802374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.813968    0.853832  0.853299          0.866093       0.802783   \n",
       "1            0.685973    0.708221  0.801889          0.800680       0.731116   \n",
       "2            0.769686    0.860709  0.867120          0.832964       0.749891   \n",
       "3            0.799953    0.866093  0.886416          0.865493       0.708175   \n",
       "4            0.719934    0.728050  0.746607          0.765151       0.646077   \n",
       "5            0.713802    0.832251  0.841511          0.801325       0.666112   \n",
       "6            0.685973    0.708221  0.801889          0.800680       0.731116   \n",
       "7            0.774834    0.839962  0.846917          0.879972       0.738673   \n",
       "8            0.703211    0.800680  0.808229          0.774104       0.705446   \n",
       "9            0.756983    0.820911  0.821455          0.809168       0.775474   \n",
       "10           0.761589    0.819601  0.853832          0.873053       0.753971   \n",
       "11           0.762266    0.766150  0.781778          0.761589       0.685771   \n",
       "12           0.715650    0.821927  0.826626          0.848308       0.782847   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.860229    0.461341  0.880408     0.712992  0.842851  0.846917  \n",
       "1        0.741316    0.461341  0.741316     0.644719  0.687253  0.747528  \n",
       "2        0.846327    0.461341  0.873975     0.732649  0.816659  0.860709  \n",
       "3        0.832964    0.461341  0.858428     0.736908  0.769392  0.853299  \n",
       "4        0.786616    0.461341  0.781778     0.687336  0.761058  0.797247  \n",
       "5        0.813968    0.461341  0.813289     0.705229  0.768994  0.793671  \n",
       "6        0.748344    0.461341  0.741316     0.644719  0.690710  0.747528  \n",
       "7        0.900163    0.461341  0.832964     0.718891  0.743627  0.906645  \n",
       "8        0.753736    0.461341  0.795004     0.720627  0.732947  0.812530  \n",
       "9        0.775474    0.461341  0.795546     0.757887  0.762835  0.782847  \n",
       "10       0.866635    0.461341  0.833606     0.696580  0.711386  0.859690  \n",
       "11       0.774104    0.490791  0.701519     0.726635  0.753030  0.772358  \n",
       "12       0.808736    0.461341  0.801889     0.785749  0.764441  0.802374  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Precision Score ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.813662</td>\n",
       "      <td>0.853672</td>\n",
       "      <td>0.853557</td>\n",
       "      <td>0.867573</td>\n",
       "      <td>0.806784</td>\n",
       "      <td>0.860244</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.880345</td>\n",
       "      <td>0.730031</td>\n",
       "      <td>0.855247</td>\n",
       "      <td>0.846853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.684740</td>\n",
       "      <td>0.736218</td>\n",
       "      <td>0.802738</td>\n",
       "      <td>0.800326</td>\n",
       "      <td>0.738900</td>\n",
       "      <td>0.740977</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.740977</td>\n",
       "      <td>0.673380</td>\n",
       "      <td>0.753735</td>\n",
       "      <td>0.746980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.772851</td>\n",
       "      <td>0.860569</td>\n",
       "      <td>0.867008</td>\n",
       "      <td>0.833426</td>\n",
       "      <td>0.804193</td>\n",
       "      <td>0.846942</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.873857</td>\n",
       "      <td>0.739696</td>\n",
       "      <td>0.829008</td>\n",
       "      <td>0.860569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.799754</td>\n",
       "      <td>0.867573</td>\n",
       "      <td>0.887493</td>\n",
       "      <td>0.868734</td>\n",
       "      <td>0.783623</td>\n",
       "      <td>0.833426</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.862627</td>\n",
       "      <td>0.749613</td>\n",
       "      <td>0.828904</td>\n",
       "      <td>0.853557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.719050</td>\n",
       "      <td>0.727689</td>\n",
       "      <td>0.745951</td>\n",
       "      <td>0.765564</td>\n",
       "      <td>0.655329</td>\n",
       "      <td>0.786303</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.782169</td>\n",
       "      <td>0.697367</td>\n",
       "      <td>0.786993</td>\n",
       "      <td>0.800794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.712946</td>\n",
       "      <td>0.833906</td>\n",
       "      <td>0.842263</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.755066</td>\n",
       "      <td>0.813662</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.813205</td>\n",
       "      <td>0.710548</td>\n",
       "      <td>0.792728</td>\n",
       "      <td>0.793290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.684740</td>\n",
       "      <td>0.736218</td>\n",
       "      <td>0.802738</td>\n",
       "      <td>0.800326</td>\n",
       "      <td>0.738900</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.740977</td>\n",
       "      <td>0.673380</td>\n",
       "      <td>0.745844</td>\n",
       "      <td>0.746980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.840106</td>\n",
       "      <td>0.846853</td>\n",
       "      <td>0.880459</td>\n",
       "      <td>0.747728</td>\n",
       "      <td>0.900416</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.833426</td>\n",
       "      <td>0.739279</td>\n",
       "      <td>0.808628</td>\n",
       "      <td>0.907360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.704990</td>\n",
       "      <td>0.800326</td>\n",
       "      <td>0.808584</td>\n",
       "      <td>0.773653</td>\n",
       "      <td>0.719226</td>\n",
       "      <td>0.753118</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.795376</td>\n",
       "      <td>0.724413</td>\n",
       "      <td>0.755184</td>\n",
       "      <td>0.813215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.762239</td>\n",
       "      <td>0.820705</td>\n",
       "      <td>0.821791</td>\n",
       "      <td>0.812175</td>\n",
       "      <td>0.776388</td>\n",
       "      <td>0.776388</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.797024</td>\n",
       "      <td>0.758701</td>\n",
       "      <td>0.766267</td>\n",
       "      <td>0.785959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.819909</td>\n",
       "      <td>0.853672</td>\n",
       "      <td>0.873976</td>\n",
       "      <td>0.760792</td>\n",
       "      <td>0.867008</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.833462</td>\n",
       "      <td>0.716630</td>\n",
       "      <td>0.751748</td>\n",
       "      <td>0.860459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.763213</td>\n",
       "      <td>0.765841</td>\n",
       "      <td>0.782169</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.713369</td>\n",
       "      <td>0.773653</td>\n",
       "      <td>0.766923</td>\n",
       "      <td>0.701113</td>\n",
       "      <td>0.731931</td>\n",
       "      <td>0.781236</td>\n",
       "      <td>0.772448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.716132</td>\n",
       "      <td>0.823320</td>\n",
       "      <td>0.826656</td>\n",
       "      <td>0.849616</td>\n",
       "      <td>0.785959</td>\n",
       "      <td>0.810172</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.802738</td>\n",
       "      <td>0.786037</td>\n",
       "      <td>0.788891</td>\n",
       "      <td>0.804559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.813662    0.853672  0.853557          0.867573       0.806784   \n",
       "1            0.684740    0.736218  0.802738          0.800326       0.738900   \n",
       "2            0.772851    0.860569  0.867008          0.833426       0.804193   \n",
       "3            0.799754    0.867573  0.887493          0.868734       0.783623   \n",
       "4            0.719050    0.727689  0.745951          0.765564       0.655329   \n",
       "5            0.712946    0.833906  0.842263          0.801325       0.755066   \n",
       "6            0.684740    0.736218  0.802738          0.800326       0.738900   \n",
       "7            0.774834    0.840106  0.846853          0.880459       0.747728   \n",
       "8            0.704990    0.800326  0.808584          0.773653       0.719226   \n",
       "9            0.762239    0.820705  0.821791          0.812175       0.776388   \n",
       "10           0.761589    0.819909  0.853672          0.873976       0.760792   \n",
       "11           0.763213    0.765841  0.782169          0.761589       0.713369   \n",
       "12           0.716132    0.823320  0.826656          0.849616       0.785959   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.860244    0.371212  0.880345     0.730031  0.855247  0.846853  \n",
       "1        0.740977    0.371212  0.740977     0.673380  0.753735  0.746980  \n",
       "2        0.846942    0.371212  0.873857     0.739696  0.829008  0.860569  \n",
       "3        0.833426    0.371212  0.862627     0.749613  0.828904  0.853557  \n",
       "4        0.786303    0.371212  0.782169     0.697367  0.786993  0.800794  \n",
       "5        0.813662    0.371212  0.813205     0.710548  0.792728  0.793290  \n",
       "6        0.748344    0.371212  0.740977     0.673380  0.745844  0.746980  \n",
       "7        0.900416    0.371212  0.833426     0.739279  0.808628  0.907360  \n",
       "8        0.753118    0.371212  0.795376     0.724413  0.755184  0.813215  \n",
       "9        0.776388    0.371212  0.797024     0.758701  0.766267  0.785959  \n",
       "10       0.867008    0.371212  0.833462     0.716630  0.751748  0.860459  \n",
       "11       0.773653    0.766923  0.701113     0.731931  0.781236  0.772448  \n",
       "12       0.810172    0.371212  0.802738     0.786037  0.788891  0.804559  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Recall Score ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.867550</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.860927</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.880795</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.847682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.748344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.860927</td>\n",
       "      <td>0.867550</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.874172</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.860927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.867550</td>\n",
       "      <td>0.887417</td>\n",
       "      <td>0.867550</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.860927</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.854305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.642384</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.801325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.668874</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.794702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.748344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.880795</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.900662</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.907285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.814570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.781457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.874172</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.867550</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.860927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.682119</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.622517</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.774834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.801325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.814570    0.854305  0.854305          0.867550       0.801325   \n",
       "1            0.688742    0.728477  0.801325          0.801325       0.728477   \n",
       "2            0.768212    0.860927  0.867550          0.834437       0.748344   \n",
       "3            0.801325    0.867550  0.887417          0.867550       0.708609   \n",
       "4            0.721854    0.728477  0.748344          0.768212       0.642384   \n",
       "5            0.715232    0.834437  0.841060          0.801325       0.668874   \n",
       "6            0.688742    0.728477  0.801325          0.801325       0.728477   \n",
       "7            0.774834    0.841060  0.847682          0.880795       0.748344   \n",
       "8            0.701987    0.801325  0.807947          0.774834       0.701987   \n",
       "9            0.754967    0.821192  0.821192          0.807947       0.774834   \n",
       "10           0.761589    0.821192  0.854305          0.874172       0.761589   \n",
       "11           0.761589    0.768212  0.781457          0.761589       0.682119   \n",
       "12           0.715232    0.821192  0.827815          0.847682       0.781457   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.860927    0.609272  0.880795     0.728477  0.841060  0.847682  \n",
       "1        0.741722    0.609272  0.741722     0.675497  0.721854  0.748344  \n",
       "2        0.847682    0.609272  0.874172     0.741722  0.814570  0.860927  \n",
       "3        0.834437    0.609272  0.860927     0.748344  0.768212  0.854305  \n",
       "4        0.788079    0.609272  0.781457     0.701987  0.774834  0.801325  \n",
       "5        0.814570    0.609272  0.814570     0.715232  0.781457  0.794702  \n",
       "6        0.748344    0.609272  0.741722     0.675497  0.721854  0.748344  \n",
       "7        0.900662    0.609272  0.834437     0.735099  0.768212  0.907285  \n",
       "8        0.754967    0.609272  0.794702     0.728477  0.748344  0.814570  \n",
       "9        0.774834    0.609272  0.794702     0.761589  0.768212  0.781457  \n",
       "10       0.867550    0.609272  0.834437     0.715232  0.735099  0.860927  \n",
       "11       0.774834    0.622517  0.701987     0.735099  0.768212  0.774834  \n",
       "12       0.807947    0.609272  0.801325     0.788079  0.761589  0.801325  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Matriz confusao ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[44, 15], [13, 79]]</td>\n",
       "      <td>[[47, 12], [10, 82]]</td>\n",
       "      <td>[[46, 13], [9, 83]]</td>\n",
       "      <td>[[46, 13], [7, 85]]</td>\n",
       "      <td>[[47, 12], [18, 74]]</td>\n",
       "      <td>[[47, 12], [9, 83]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[49, 10], [8, 84]]</td>\n",
       "      <td>[[28, 31], [10, 82]]</td>\n",
       "      <td>[[53, 6], [18, 74]]</td>\n",
       "      <td>[[46, 13], [10, 82]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[33, 26], [21, 71]]</td>\n",
       "      <td>[[26, 33], [8, 84]]</td>\n",
       "      <td>[[45, 14], [16, 76]]</td>\n",
       "      <td>[[43, 16], [14, 78]]</td>\n",
       "      <td>[[43, 16], [25, 67]]</td>\n",
       "      <td>[[39, 20], [19, 73]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[39, 20], [19, 73]]</td>\n",
       "      <td>[[20, 39], [10, 82]]</td>\n",
       "      <td>[[21, 38], [4, 88]]</td>\n",
       "      <td>[[39, 20], [18, 74]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[44, 15], [20, 72]]</td>\n",
       "      <td>[[48, 11], [10, 82]]</td>\n",
       "      <td>[[48, 11], [9, 83]]</td>\n",
       "      <td>[[44, 15], [10, 82]]</td>\n",
       "      <td>[[54, 5], [33, 59]]</td>\n",
       "      <td>[[45, 14], [9, 83]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[49, 10], [9, 83]]</td>\n",
       "      <td>[[32, 27], [12, 80]]</td>\n",
       "      <td>[[51, 8], [20, 72]]</td>\n",
       "      <td>[[48, 11], [10, 82]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[42, 17], [13, 79]]</td>\n",
       "      <td>[[46, 13], [7, 85]]</td>\n",
       "      <td>[[48, 11], [6, 86]]</td>\n",
       "      <td>[[45, 14], [6, 86]]</td>\n",
       "      <td>[[54, 5], [39, 53]]</td>\n",
       "      <td>[[44, 15], [10, 82]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[44, 15], [6, 86]]</td>\n",
       "      <td>[[31, 28], [10, 82]]</td>\n",
       "      <td>[[56, 3], [32, 60]]</td>\n",
       "      <td>[[46, 13], [9, 83]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[36, 23], [19, 73]]</td>\n",
       "      <td>[[38, 21], [20, 72]]</td>\n",
       "      <td>[[38, 21], [17, 75]]</td>\n",
       "      <td>[[38, 21], [14, 78]]</td>\n",
       "      <td>[[37, 22], [32, 60]]</td>\n",
       "      <td>[[41, 18], [14, 78]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[43, 16], [17, 75]]</td>\n",
       "      <td>[[27, 32], [13, 79]]</td>\n",
       "      <td>[[31, 28], [6, 86]]</td>\n",
       "      <td>[[39, 20], [10, 82]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[[36, 23], [20, 72]]</td>\n",
       "      <td>[[43, 16], [9, 83]]</td>\n",
       "      <td>[[48, 11], [13, 79]]</td>\n",
       "      <td>[[44, 15], [15, 77]]</td>\n",
       "      <td>[[53, 6], [44, 48]]</td>\n",
       "      <td>[[44, 15], [13, 79]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[43, 16], [12, 80]]</td>\n",
       "      <td>[[30, 29], [14, 78]]</td>\n",
       "      <td>[[32, 27], [6, 86]]</td>\n",
       "      <td>[[42, 17], [14, 78]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[[33, 26], [21, 71]]</td>\n",
       "      <td>[[26, 33], [8, 84]]</td>\n",
       "      <td>[[45, 14], [16, 76]]</td>\n",
       "      <td>[[43, 16], [14, 78]]</td>\n",
       "      <td>[[43, 16], [25, 67]]</td>\n",
       "      <td>[[40, 19], [19, 73]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[39, 20], [19, 73]]</td>\n",
       "      <td>[[20, 39], [10, 82]]</td>\n",
       "      <td>[[22, 37], [5, 87]]</td>\n",
       "      <td>[[39, 20], [18, 74]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[[42, 17], [17, 75]]</td>\n",
       "      <td>[[45, 14], [10, 82]]</td>\n",
       "      <td>[[46, 13], [10, 82]]</td>\n",
       "      <td>[[48, 11], [7, 85]]</td>\n",
       "      <td>[[32, 27], [11, 81]]</td>\n",
       "      <td>[[50, 9], [6, 86]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[44, 15], [10, 82]]</td>\n",
       "      <td>[[28, 31], [9, 83]]</td>\n",
       "      <td>[[26, 33], [2, 90]]</td>\n",
       "      <td>[[50, 9], [5, 87]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[[38, 21], [24, 68]]</td>\n",
       "      <td>[[43, 16], [14, 78]]</td>\n",
       "      <td>[[45, 14], [15, 77]]</td>\n",
       "      <td>[[41, 18], [16, 76]]</td>\n",
       "      <td>[[43, 16], [29, 63]]</td>\n",
       "      <td>[[39, 20], [17, 75]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[44, 15], [16, 76]]</td>\n",
       "      <td>[[32, 27], [14, 78]]</td>\n",
       "      <td>[[29, 30], [8, 84]]</td>\n",
       "      <td>[[42, 17], [11, 81]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[[44, 15], [22, 70]]</td>\n",
       "      <td>[[45, 14], [13, 79]]</td>\n",
       "      <td>[[46, 13], [14, 78]]</td>\n",
       "      <td>[[47, 12], [17, 75]]</td>\n",
       "      <td>[[43, 16], [18, 74]]</td>\n",
       "      <td>[[43, 16], [18, 74]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[45, 14], [17, 75]]</td>\n",
       "      <td>[[37, 22], [14, 78]]</td>\n",
       "      <td>[[36, 23], [12, 80]]</td>\n",
       "      <td>[[45, 14], [19, 73]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[[41, 18], [18, 74]]</td>\n",
       "      <td>[[43, 16], [11, 81]]</td>\n",
       "      <td>[[47, 12], [10, 82]]</td>\n",
       "      <td>[[47, 12], [7, 85]]</td>\n",
       "      <td>[[34, 25], [11, 81]]</td>\n",
       "      <td>[[47, 12], [8, 84]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[45, 14], [11, 81]]</td>\n",
       "      <td>[[26, 33], [10, 82]]</td>\n",
       "      <td>[[25, 34], [6, 86]]</td>\n",
       "      <td>[[46, 13], [8, 84]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[[42, 17], [19, 73]]</td>\n",
       "      <td>[[39, 20], [15, 77]]</td>\n",
       "      <td>[[43, 16], [17, 75]]</td>\n",
       "      <td>[[41, 18], [18, 74]]</td>\n",
       "      <td>[[45, 14], [34, 58]]</td>\n",
       "      <td>[[41, 18], [16, 76]]</td>\n",
       "      <td>[[2, 57], [0, 92]]</td>\n",
       "      <td>[[36, 23], [22, 70]]</td>\n",
       "      <td>[[32, 27], [13, 79]]</td>\n",
       "      <td>[[30, 29], [6, 86]]</td>\n",
       "      <td>[[39, 20], [14, 78]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[[38, 21], [22, 70]]</td>\n",
       "      <td>[[47, 12], [15, 77]]</td>\n",
       "      <td>[[44, 15], [11, 81]]</td>\n",
       "      <td>[[49, 10], [13, 79]]</td>\n",
       "      <td>[[45, 14], [19, 73]]</td>\n",
       "      <td>[[46, 13], [16, 76]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[45, 14], [16, 76]]</td>\n",
       "      <td>[[40, 19], [13, 79]]</td>\n",
       "      <td>[[50, 9], [27, 65]]</td>\n",
       "      <td>[[46, 13], [17, 75]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Nearest Neighbors            Linear SVM               RBF SVM  \\\n",
       "0   [[44, 15], [13, 79]]  [[47, 12], [10, 82]]   [[46, 13], [9, 83]]   \n",
       "1   [[33, 26], [21, 71]]   [[26, 33], [8, 84]]  [[45, 14], [16, 76]]   \n",
       "2   [[44, 15], [20, 72]]  [[48, 11], [10, 82]]   [[48, 11], [9, 83]]   \n",
       "3   [[42, 17], [13, 79]]   [[46, 13], [7, 85]]   [[48, 11], [6, 86]]   \n",
       "4   [[36, 23], [19, 73]]  [[38, 21], [20, 72]]  [[38, 21], [17, 75]]   \n",
       "5   [[36, 23], [20, 72]]   [[43, 16], [9, 83]]  [[48, 11], [13, 79]]   \n",
       "6   [[33, 26], [21, 71]]   [[26, 33], [8, 84]]  [[45, 14], [16, 76]]   \n",
       "7   [[42, 17], [17, 75]]  [[45, 14], [10, 82]]  [[46, 13], [10, 82]]   \n",
       "8   [[38, 21], [24, 68]]  [[43, 16], [14, 78]]  [[45, 14], [15, 77]]   \n",
       "9   [[44, 15], [22, 70]]  [[45, 14], [13, 79]]  [[46, 13], [14, 78]]   \n",
       "10  [[41, 18], [18, 74]]  [[43, 16], [11, 81]]  [[47, 12], [10, 82]]   \n",
       "11  [[42, 17], [19, 73]]  [[39, 20], [15, 77]]  [[43, 16], [17, 75]]   \n",
       "12  [[38, 21], [22, 70]]  [[47, 12], [15, 77]]  [[44, 15], [11, 81]]   \n",
       "\n",
       "        Gaussian Process         Decision Tree         Random Forest  \\\n",
       "0    [[46, 13], [7, 85]]  [[47, 12], [18, 74]]   [[47, 12], [9, 83]]   \n",
       "1   [[43, 16], [14, 78]]  [[43, 16], [25, 67]]  [[39, 20], [19, 73]]   \n",
       "2   [[44, 15], [10, 82]]   [[54, 5], [33, 59]]   [[45, 14], [9, 83]]   \n",
       "3    [[45, 14], [6, 86]]   [[54, 5], [39, 53]]  [[44, 15], [10, 82]]   \n",
       "4   [[38, 21], [14, 78]]  [[37, 22], [32, 60]]  [[41, 18], [14, 78]]   \n",
       "5   [[44, 15], [15, 77]]   [[53, 6], [44, 48]]  [[44, 15], [13, 79]]   \n",
       "6   [[43, 16], [14, 78]]  [[43, 16], [25, 67]]  [[40, 19], [19, 73]]   \n",
       "7    [[48, 11], [7, 85]]  [[32, 27], [11, 81]]    [[50, 9], [6, 86]]   \n",
       "8   [[41, 18], [16, 76]]  [[43, 16], [29, 63]]  [[39, 20], [17, 75]]   \n",
       "9   [[47, 12], [17, 75]]  [[43, 16], [18, 74]]  [[43, 16], [18, 74]]   \n",
       "10   [[47, 12], [7, 85]]  [[34, 25], [11, 81]]   [[47, 12], [8, 84]]   \n",
       "11  [[41, 18], [18, 74]]  [[45, 14], [34, 58]]  [[41, 18], [16, 76]]   \n",
       "12  [[49, 10], [13, 79]]  [[45, 14], [19, 73]]  [[46, 13], [16, 76]]   \n",
       "\n",
       "            Neural Net              AdaBoost           Naive Bayes  \\\n",
       "0   [[0, 59], [0, 92]]   [[49, 10], [8, 84]]  [[28, 31], [10, 82]]   \n",
       "1   [[0, 59], [0, 92]]  [[39, 20], [19, 73]]  [[20, 39], [10, 82]]   \n",
       "2   [[0, 59], [0, 92]]   [[49, 10], [9, 83]]  [[32, 27], [12, 80]]   \n",
       "3   [[0, 59], [0, 92]]   [[44, 15], [6, 86]]  [[31, 28], [10, 82]]   \n",
       "4   [[0, 59], [0, 92]]  [[43, 16], [17, 75]]  [[27, 32], [13, 79]]   \n",
       "5   [[0, 59], [0, 92]]  [[43, 16], [12, 80]]  [[30, 29], [14, 78]]   \n",
       "6   [[0, 59], [0, 92]]  [[39, 20], [19, 73]]  [[20, 39], [10, 82]]   \n",
       "7   [[0, 59], [0, 92]]  [[44, 15], [10, 82]]   [[28, 31], [9, 83]]   \n",
       "8   [[0, 59], [0, 92]]  [[44, 15], [16, 76]]  [[32, 27], [14, 78]]   \n",
       "9   [[0, 59], [0, 92]]  [[45, 14], [17, 75]]  [[37, 22], [14, 78]]   \n",
       "10  [[0, 59], [0, 92]]  [[45, 14], [11, 81]]  [[26, 33], [10, 82]]   \n",
       "11  [[2, 57], [0, 92]]  [[36, 23], [22, 70]]  [[32, 27], [13, 79]]   \n",
       "12  [[0, 59], [0, 92]]  [[45, 14], [16, 76]]  [[40, 19], [13, 79]]   \n",
       "\n",
       "                     QDA               XGBoost  \n",
       "0    [[53, 6], [18, 74]]  [[46, 13], [10, 82]]  \n",
       "1    [[21, 38], [4, 88]]  [[39, 20], [18, 74]]  \n",
       "2    [[51, 8], [20, 72]]  [[48, 11], [10, 82]]  \n",
       "3    [[56, 3], [32, 60]]   [[46, 13], [9, 83]]  \n",
       "4    [[31, 28], [6, 86]]  [[39, 20], [10, 82]]  \n",
       "5    [[32, 27], [6, 86]]  [[42, 17], [14, 78]]  \n",
       "6    [[22, 37], [5, 87]]  [[39, 20], [18, 74]]  \n",
       "7    [[26, 33], [2, 90]]    [[50, 9], [5, 87]]  \n",
       "8    [[29, 30], [8, 84]]  [[42, 17], [11, 81]]  \n",
       "9   [[36, 23], [12, 80]]  [[45, 14], [19, 73]]  \n",
       "10   [[25, 34], [6, 86]]   [[46, 13], [8, 84]]  \n",
       "11   [[30, 29], [6, 86]]  [[39, 20], [14, 78]]  \n",
       "12   [[50, 9], [27, 65]]  [[46, 13], [17, 75]]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ 8 pontos - 2 raio ------\n",
      "--- Acuracia ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.887417</td>\n",
       "      <td>0.860927</td>\n",
       "      <td>0.874172</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.801325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.754967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.894040</td>\n",
       "      <td>0.887417</td>\n",
       "      <td>0.874172</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.874172</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.854305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.867550</td>\n",
       "      <td>0.874172</td>\n",
       "      <td>0.867550</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.801325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.774834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.662252</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.821192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.754967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.847682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.781457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.874172</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.774834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.841060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.794702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.801325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.814570    0.887417  0.860927          0.874172       0.794702   \n",
       "1            0.728477    0.788079  0.768212          0.788079       0.768212   \n",
       "2            0.807947    0.894040  0.887417          0.874172       0.814570   \n",
       "3            0.867550    0.874172  0.867550          0.841060       0.735099   \n",
       "4            0.721854    0.834437  0.854305          0.807947       0.675497   \n",
       "5            0.721854    0.821192  0.814570          0.834437       0.662252   \n",
       "6            0.728477    0.788079  0.768212          0.788079       0.768212   \n",
       "7            0.794702    0.854305  0.847682          0.847682       0.834437   \n",
       "8            0.761589    0.807947  0.794702          0.801325       0.748344   \n",
       "9            0.728477    0.854305  0.854305          0.874172       0.781457   \n",
       "10           0.781457    0.841060  0.847682          0.827815       0.801325   \n",
       "11           0.748344    0.761589  0.748344          0.774834       0.768212   \n",
       "12           0.761589    0.801325  0.801325          0.807947       0.754967   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.847682    0.609272  0.834437     0.801325  0.854305  0.801325  \n",
       "1        0.768212    0.609272  0.708609     0.741722  0.675497  0.754967  \n",
       "2        0.874172    0.609272  0.827815     0.801325  0.834437  0.854305  \n",
       "3        0.807947    0.609272  0.781457     0.741722  0.814570  0.801325  \n",
       "4        0.768212    0.609272  0.748344     0.768212  0.807947  0.774834  \n",
       "5        0.788079    0.609272  0.814570     0.728477  0.748344  0.821192  \n",
       "6        0.761589    0.609272  0.708609     0.741722  0.695364  0.754967  \n",
       "7        0.827815    0.609272  0.814570     0.794702  0.847682  0.847682  \n",
       "8        0.781457    0.609272  0.741722     0.781457  0.741722  0.781457  \n",
       "9        0.807947    0.609272  0.774834     0.781457  0.754967  0.774834  \n",
       "10       0.827815    0.609272  0.827815     0.788079  0.781457  0.841060  \n",
       "11       0.781457    0.609272  0.761589     0.788079  0.794702  0.794702  \n",
       "12       0.801325    0.609272  0.821192     0.814570  0.834437  0.801325  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- F1 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.811690</td>\n",
       "      <td>0.887880</td>\n",
       "      <td>0.860229</td>\n",
       "      <td>0.873540</td>\n",
       "      <td>0.789940</td>\n",
       "      <td>0.847443</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.833606</td>\n",
       "      <td>0.799953</td>\n",
       "      <td>0.852703</td>\n",
       "      <td>0.800680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.724891</td>\n",
       "      <td>0.785749</td>\n",
       "      <td>0.764047</td>\n",
       "      <td>0.788681</td>\n",
       "      <td>0.762835</td>\n",
       "      <td>0.769164</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.710748</td>\n",
       "      <td>0.730908</td>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.755327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.803492</td>\n",
       "      <td>0.894040</td>\n",
       "      <td>0.887240</td>\n",
       "      <td>0.873975</td>\n",
       "      <td>0.816768</td>\n",
       "      <td>0.873053</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.825140</td>\n",
       "      <td>0.800680</td>\n",
       "      <td>0.829651</td>\n",
       "      <td>0.853832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.866093</td>\n",
       "      <td>0.873053</td>\n",
       "      <td>0.867926</td>\n",
       "      <td>0.840544</td>\n",
       "      <td>0.737835</td>\n",
       "      <td>0.806238</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.777530</td>\n",
       "      <td>0.735731</td>\n",
       "      <td>0.804738</td>\n",
       "      <td>0.801325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.719934</td>\n",
       "      <td>0.834177</td>\n",
       "      <td>0.854718</td>\n",
       "      <td>0.806238</td>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.770119</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.746607</td>\n",
       "      <td>0.764047</td>\n",
       "      <td>0.810264</td>\n",
       "      <td>0.776024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.722644</td>\n",
       "      <td>0.818831</td>\n",
       "      <td>0.816242</td>\n",
       "      <td>0.835799</td>\n",
       "      <td>0.657379</td>\n",
       "      <td>0.789635</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.815096</td>\n",
       "      <td>0.723598</td>\n",
       "      <td>0.736908</td>\n",
       "      <td>0.822329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.724891</td>\n",
       "      <td>0.785749</td>\n",
       "      <td>0.764047</td>\n",
       "      <td>0.788681</td>\n",
       "      <td>0.762835</td>\n",
       "      <td>0.762266</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.710748</td>\n",
       "      <td>0.730908</td>\n",
       "      <td>0.698615</td>\n",
       "      <td>0.755327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.791013</td>\n",
       "      <td>0.853299</td>\n",
       "      <td>0.845670</td>\n",
       "      <td>0.846327</td>\n",
       "      <td>0.832251</td>\n",
       "      <td>0.826626</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.812530</td>\n",
       "      <td>0.792876</td>\n",
       "      <td>0.843279</td>\n",
       "      <td>0.846917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.762849</td>\n",
       "      <td>0.808229</td>\n",
       "      <td>0.795004</td>\n",
       "      <td>0.802374</td>\n",
       "      <td>0.740303</td>\n",
       "      <td>0.781114</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.742783</td>\n",
       "      <td>0.776387</td>\n",
       "      <td>0.742424</td>\n",
       "      <td>0.782355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.730203</td>\n",
       "      <td>0.853832</td>\n",
       "      <td>0.854718</td>\n",
       "      <td>0.874689</td>\n",
       "      <td>0.780359</td>\n",
       "      <td>0.807645</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.778571</td>\n",
       "      <td>0.757692</td>\n",
       "      <td>0.775474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.777530</td>\n",
       "      <td>0.839962</td>\n",
       "      <td>0.846917</td>\n",
       "      <td>0.825921</td>\n",
       "      <td>0.799953</td>\n",
       "      <td>0.825921</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.825140</td>\n",
       "      <td>0.786616</td>\n",
       "      <td>0.784029</td>\n",
       "      <td>0.840544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.749059</td>\n",
       "      <td>0.759943</td>\n",
       "      <td>0.749059</td>\n",
       "      <td>0.775474</td>\n",
       "      <td>0.769686</td>\n",
       "      <td>0.781778</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.762266</td>\n",
       "      <td>0.783730</td>\n",
       "      <td>0.796697</td>\n",
       "      <td>0.795004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.800680</td>\n",
       "      <td>0.809527</td>\n",
       "      <td>0.750564</td>\n",
       "      <td>0.802783</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.821455</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.832964</td>\n",
       "      <td>0.802783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.811690    0.887880  0.860229          0.873540       0.789940   \n",
       "1            0.724891    0.785749  0.764047          0.788681       0.762835   \n",
       "2            0.803492    0.894040  0.887240          0.873975       0.816768   \n",
       "3            0.866093    0.873053  0.867926          0.840544       0.737835   \n",
       "4            0.719934    0.834177  0.854718          0.806238       0.675497   \n",
       "5            0.722644    0.818831  0.816242          0.835799       0.657379   \n",
       "6            0.724891    0.785749  0.764047          0.788681       0.762835   \n",
       "7            0.791013    0.853299  0.845670          0.846327       0.832251   \n",
       "8            0.762849    0.808229  0.795004          0.802374       0.740303   \n",
       "9            0.730203    0.853832  0.854718          0.874689       0.780359   \n",
       "10           0.777530    0.839962  0.846917          0.825921       0.799953   \n",
       "11           0.749059    0.759943  0.749059          0.775474       0.769686   \n",
       "12           0.761589    0.801325  0.800680          0.809527       0.750564   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.847443    0.461341  0.833606     0.799953  0.852703  0.800680  \n",
       "1        0.769164    0.461341  0.710748     0.730908  0.675497  0.755327  \n",
       "2        0.873053    0.461341  0.825140     0.800680  0.829651  0.853832  \n",
       "3        0.806238    0.461341  0.777530     0.735731  0.804738  0.801325  \n",
       "4        0.770119    0.461341  0.746607     0.764047  0.810264  0.776024  \n",
       "5        0.789635    0.461341  0.815096     0.723598  0.736908  0.822329  \n",
       "6        0.762266    0.461341  0.710748     0.730908  0.698615  0.755327  \n",
       "7        0.826626    0.461341  0.812530     0.792876  0.843279  0.846917  \n",
       "8        0.781114    0.461341  0.742783     0.776387  0.742424  0.782355  \n",
       "9        0.807645    0.461341  0.774834     0.778571  0.757692  0.775474  \n",
       "10       0.825921    0.461341  0.825140     0.786616  0.784029  0.840544  \n",
       "11       0.781778    0.461341  0.762266     0.783730  0.796697  0.795004  \n",
       "12       0.802783    0.461341  0.821455     0.814570  0.832964  0.802783  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Precision Score ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.813718</td>\n",
       "      <td>0.889059</td>\n",
       "      <td>0.860244</td>\n",
       "      <td>0.873634</td>\n",
       "      <td>0.794378</td>\n",
       "      <td>0.847281</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.833462</td>\n",
       "      <td>0.799754</td>\n",
       "      <td>0.853983</td>\n",
       "      <td>0.800326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.724560</td>\n",
       "      <td>0.786037</td>\n",
       "      <td>0.765698</td>\n",
       "      <td>0.789563</td>\n",
       "      <td>0.766267</td>\n",
       "      <td>0.770729</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.741156</td>\n",
       "      <td>0.743258</td>\n",
       "      <td>0.755754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.808433</td>\n",
       "      <td>0.894040</td>\n",
       "      <td>0.887145</td>\n",
       "      <td>0.873857</td>\n",
       "      <td>0.832920</td>\n",
       "      <td>0.873976</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.827472</td>\n",
       "      <td>0.800326</td>\n",
       "      <td>0.838786</td>\n",
       "      <td>0.853672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.867573</td>\n",
       "      <td>0.873976</td>\n",
       "      <td>0.868614</td>\n",
       "      <td>0.840335</td>\n",
       "      <td>0.746980</td>\n",
       "      <td>0.806392</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.779545</td>\n",
       "      <td>0.738156</td>\n",
       "      <td>0.829367</td>\n",
       "      <td>0.801325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.719050</td>\n",
       "      <td>0.833993</td>\n",
       "      <td>0.855439</td>\n",
       "      <td>0.806392</td>\n",
       "      <td>0.743258</td>\n",
       "      <td>0.775327</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.745951</td>\n",
       "      <td>0.765698</td>\n",
       "      <td>0.833012</td>\n",
       "      <td>0.778308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.723688</td>\n",
       "      <td>0.820238</td>\n",
       "      <td>0.822496</td>\n",
       "      <td>0.840767</td>\n",
       "      <td>0.760532</td>\n",
       "      <td>0.793688</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.815913</td>\n",
       "      <td>0.724157</td>\n",
       "      <td>0.749613</td>\n",
       "      <td>0.825284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.724560</td>\n",
       "      <td>0.786037</td>\n",
       "      <td>0.765698</td>\n",
       "      <td>0.789563</td>\n",
       "      <td>0.766267</td>\n",
       "      <td>0.763213</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.741156</td>\n",
       "      <td>0.731544</td>\n",
       "      <td>0.755754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.793392</td>\n",
       "      <td>0.853557</td>\n",
       "      <td>0.847574</td>\n",
       "      <td>0.846942</td>\n",
       "      <td>0.833906</td>\n",
       "      <td>0.826656</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.813215</td>\n",
       "      <td>0.792875</td>\n",
       "      <td>0.853083</td>\n",
       "      <td>0.846853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.765183</td>\n",
       "      <td>0.808584</td>\n",
       "      <td>0.795376</td>\n",
       "      <td>0.804559</td>\n",
       "      <td>0.746362</td>\n",
       "      <td>0.780841</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.744433</td>\n",
       "      <td>0.780322</td>\n",
       "      <td>0.808098</td>\n",
       "      <td>0.783876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.733526</td>\n",
       "      <td>0.853672</td>\n",
       "      <td>0.855439</td>\n",
       "      <td>0.875911</td>\n",
       "      <td>0.779900</td>\n",
       "      <td>0.807417</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.779233</td>\n",
       "      <td>0.789711</td>\n",
       "      <td>0.776388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.779545</td>\n",
       "      <td>0.840106</td>\n",
       "      <td>0.846853</td>\n",
       "      <td>0.826805</td>\n",
       "      <td>0.799754</td>\n",
       "      <td>0.826805</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.827472</td>\n",
       "      <td>0.786303</td>\n",
       "      <td>0.811334</td>\n",
       "      <td>0.840335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.750038</td>\n",
       "      <td>0.759402</td>\n",
       "      <td>0.750038</td>\n",
       "      <td>0.776388</td>\n",
       "      <td>0.772851</td>\n",
       "      <td>0.782169</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.763213</td>\n",
       "      <td>0.786847</td>\n",
       "      <td>0.804333</td>\n",
       "      <td>0.795376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.800326</td>\n",
       "      <td>0.814591</td>\n",
       "      <td>0.751851</td>\n",
       "      <td>0.806784</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.821791</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.833426</td>\n",
       "      <td>0.806784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.813718    0.889059  0.860244          0.873634       0.794378   \n",
       "1            0.724560    0.786037  0.765698          0.789563       0.766267   \n",
       "2            0.808433    0.894040  0.887145          0.873857       0.832920   \n",
       "3            0.867573    0.873976  0.868614          0.840335       0.746980   \n",
       "4            0.719050    0.833993  0.855439          0.806392       0.743258   \n",
       "5            0.723688    0.820238  0.822496          0.840767       0.760532   \n",
       "6            0.724560    0.786037  0.765698          0.789563       0.766267   \n",
       "7            0.793392    0.853557  0.847574          0.846942       0.833906   \n",
       "8            0.765183    0.808584  0.795376          0.804559       0.746362   \n",
       "9            0.733526    0.853672  0.855439          0.875911       0.779900   \n",
       "10           0.779545    0.840106  0.846853          0.826805       0.799754   \n",
       "11           0.750038    0.759402  0.750038          0.776388       0.772851   \n",
       "12           0.761589    0.801325  0.800326          0.814591       0.751851   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.847281    0.371212  0.833462     0.799754  0.853983  0.800326  \n",
       "1        0.770729    0.371212  0.715113     0.741156  0.743258  0.755754  \n",
       "2        0.873976    0.371212  0.827472     0.800326  0.838786  0.853672  \n",
       "3        0.806392    0.371212  0.779545     0.738156  0.829367  0.801325  \n",
       "4        0.775327    0.371212  0.745951     0.765698  0.833012  0.778308  \n",
       "5        0.793688    0.371212  0.815913     0.724157  0.749613  0.825284  \n",
       "6        0.763213    0.371212  0.715113     0.741156  0.731544  0.755754  \n",
       "7        0.826656    0.371212  0.813215     0.792875  0.853083  0.846853  \n",
       "8        0.780841    0.371212  0.744433     0.780322  0.808098  0.783876  \n",
       "9        0.807417    0.371212  0.774834     0.779233  0.789711  0.776388  \n",
       "10       0.826805    0.371212  0.827472     0.786303  0.811334  0.840335  \n",
       "11       0.782169    0.371212  0.763213     0.786847  0.804333  0.795376  \n",
       "12       0.806784    0.371212  0.821791     0.814570  0.833426  0.806784  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Recall Score ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.887417</td>\n",
       "      <td>0.860927</td>\n",
       "      <td>0.874172</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.801325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.754967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.894040</td>\n",
       "      <td>0.887417</td>\n",
       "      <td>0.874172</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.874172</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.854305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.867550</td>\n",
       "      <td>0.874172</td>\n",
       "      <td>0.867550</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.801325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.774834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.662252</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.821192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.754967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.847682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.781457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.874172</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.774834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.841060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.794702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.801325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.814570    0.887417  0.860927          0.874172       0.794702   \n",
       "1            0.728477    0.788079  0.768212          0.788079       0.768212   \n",
       "2            0.807947    0.894040  0.887417          0.874172       0.814570   \n",
       "3            0.867550    0.874172  0.867550          0.841060       0.735099   \n",
       "4            0.721854    0.834437  0.854305          0.807947       0.675497   \n",
       "5            0.721854    0.821192  0.814570          0.834437       0.662252   \n",
       "6            0.728477    0.788079  0.768212          0.788079       0.768212   \n",
       "7            0.794702    0.854305  0.847682          0.847682       0.834437   \n",
       "8            0.761589    0.807947  0.794702          0.801325       0.748344   \n",
       "9            0.728477    0.854305  0.854305          0.874172       0.781457   \n",
       "10           0.781457    0.841060  0.847682          0.827815       0.801325   \n",
       "11           0.748344    0.761589  0.748344          0.774834       0.768212   \n",
       "12           0.761589    0.801325  0.801325          0.807947       0.754967   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.847682    0.609272  0.834437     0.801325  0.854305  0.801325  \n",
       "1        0.768212    0.609272  0.708609     0.741722  0.675497  0.754967  \n",
       "2        0.874172    0.609272  0.827815     0.801325  0.834437  0.854305  \n",
       "3        0.807947    0.609272  0.781457     0.741722  0.814570  0.801325  \n",
       "4        0.768212    0.609272  0.748344     0.768212  0.807947  0.774834  \n",
       "5        0.788079    0.609272  0.814570     0.728477  0.748344  0.821192  \n",
       "6        0.761589    0.609272  0.708609     0.741722  0.695364  0.754967  \n",
       "7        0.827815    0.609272  0.814570     0.794702  0.847682  0.847682  \n",
       "8        0.781457    0.609272  0.741722     0.781457  0.741722  0.781457  \n",
       "9        0.807947    0.609272  0.774834     0.781457  0.754967  0.774834  \n",
       "10       0.827815    0.609272  0.827815     0.788079  0.781457  0.841060  \n",
       "11       0.781457    0.609272  0.761589     0.788079  0.794702  0.794702  \n",
       "12       0.801325    0.609272  0.821192     0.814570  0.834437  0.801325  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Matriz confusao ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[41, 18], [10, 82]]</td>\n",
       "      <td>[[52, 7], [10, 82]]</td>\n",
       "      <td>[[47, 12], [9, 83]]</td>\n",
       "      <td>[[48, 11], [8, 84]]</td>\n",
       "      <td>[[38, 21], [10, 82]]</td>\n",
       "      <td>[[47, 12], [11, 81]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[45, 14], [11, 81]]</td>\n",
       "      <td>[[42, 17], [13, 79]]</td>\n",
       "      <td>[[45, 14], [8, 84]]</td>\n",
       "      <td>[[43, 16], [14, 78]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[35, 24], [17, 75]]</td>\n",
       "      <td>[[40, 19], [13, 79]]</td>\n",
       "      <td>[[37, 22], [13, 79]]</td>\n",
       "      <td>[[44, 15], [17, 75]]</td>\n",
       "      <td>[[36, 23], [12, 80]]</td>\n",
       "      <td>[[43, 16], [19, 73]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[40, 19], [25, 67]]</td>\n",
       "      <td>[[31, 28], [11, 81]]</td>\n",
       "      <td>[[51, 8], [41, 51]]</td>\n",
       "      <td>[[41, 18], [19, 73]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[39, 20], [9, 83]]</td>\n",
       "      <td>[[51, 8], [8, 84]]</td>\n",
       "      <td>[[50, 9], [8, 84]]</td>\n",
       "      <td>[[49, 10], [9, 83]]</td>\n",
       "      <td>[[52, 7], [21, 71]]</td>\n",
       "      <td>[[47, 12], [7, 85]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[42, 17], [9, 83]]</td>\n",
       "      <td>[[43, 16], [14, 78]]</td>\n",
       "      <td>[[40, 19], [6, 86]]</td>\n",
       "      <td>[[47, 12], [10, 82]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[46, 13], [7, 85]]</td>\n",
       "      <td>[[47, 12], [7, 85]]</td>\n",
       "      <td>[[50, 9], [11, 81]]</td>\n",
       "      <td>[[46, 13], [11, 81]]</td>\n",
       "      <td>[[44, 15], [25, 67]]</td>\n",
       "      <td>[[42, 17], [12, 80]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[38, 21], [12, 80]]</td>\n",
       "      <td>[[34, 25], [14, 78]]</td>\n",
       "      <td>[[35, 24], [4, 88]]</td>\n",
       "      <td>[[44, 15], [15, 77]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[36, 23], [19, 73]]</td>\n",
       "      <td>[[46, 13], [12, 80]]</td>\n",
       "      <td>[[49, 10], [12, 80]]</td>\n",
       "      <td>[[42, 17], [12, 80]]</td>\n",
       "      <td>[[51, 8], [41, 51]]</td>\n",
       "      <td>[[45, 14], [21, 71]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[38, 21], [17, 75]]</td>\n",
       "      <td>[[37, 22], [13, 79]]</td>\n",
       "      <td>[[53, 6], [23, 69]]</td>\n",
       "      <td>[[44, 15], [19, 73]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[[39, 20], [22, 70]]</td>\n",
       "      <td>[[42, 17], [10, 82]]</td>\n",
       "      <td>[[49, 10], [18, 74]]</td>\n",
       "      <td>[[50, 9], [16, 76]]</td>\n",
       "      <td>[[54, 5], [46, 46]]</td>\n",
       "      <td>[[46, 13], [19, 73]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[46, 13], [15, 77]]</td>\n",
       "      <td>[[34, 25], [16, 76]]</td>\n",
       "      <td>[[31, 28], [10, 82]]</td>\n",
       "      <td>[[48, 11], [16, 76]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[[35, 24], [17, 75]]</td>\n",
       "      <td>[[40, 19], [13, 79]]</td>\n",
       "      <td>[[37, 22], [13, 79]]</td>\n",
       "      <td>[[44, 15], [17, 75]]</td>\n",
       "      <td>[[36, 23], [12, 80]]</td>\n",
       "      <td>[[42, 17], [19, 73]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[40, 19], [25, 67]]</td>\n",
       "      <td>[[31, 28], [11, 81]]</td>\n",
       "      <td>[[47, 12], [34, 58]]</td>\n",
       "      <td>[[41, 18], [19, 73]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[[39, 20], [11, 81]]</td>\n",
       "      <td>[[46, 13], [9, 83]]</td>\n",
       "      <td>[[44, 15], [8, 84]]</td>\n",
       "      <td>[[45, 14], [9, 83]]</td>\n",
       "      <td>[[43, 16], [9, 83]]</td>\n",
       "      <td>[[44, 15], [11, 81]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[42, 17], [11, 81]]</td>\n",
       "      <td>[[41, 18], [13, 79]]</td>\n",
       "      <td>[[41, 18], [5, 87]]</td>\n",
       "      <td>[[46, 13], [10, 82]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[[43, 16], [20, 72]]</td>\n",
       "      <td>[[45, 14], [15, 77]]</td>\n",
       "      <td>[[44, 15], [16, 76]]</td>\n",
       "      <td>[[46, 13], [17, 75]]</td>\n",
       "      <td>[[33, 26], [12, 80]]</td>\n",
       "      <td>[[42, 17], [16, 76]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[41, 18], [21, 71]]</td>\n",
       "      <td>[[37, 22], [11, 81]]</td>\n",
       "      <td>[[55, 4], [35, 57]]</td>\n",
       "      <td>[[44, 15], [18, 74]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[[41, 18], [23, 69]]</td>\n",
       "      <td>[[47, 12], [10, 82]]</td>\n",
       "      <td>[[49, 10], [12, 80]]</td>\n",
       "      <td>[[51, 8], [11, 81]]</td>\n",
       "      <td>[[41, 18], [15, 77]]</td>\n",
       "      <td>[[44, 15], [14, 78]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[42, 17], [17, 75]]</td>\n",
       "      <td>[[39, 20], [13, 79]]</td>\n",
       "      <td>[[51, 8], [29, 63]]</td>\n",
       "      <td>[[43, 16], [18, 74]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[[38, 21], [12, 80]]</td>\n",
       "      <td>[[45, 14], [10, 82]]</td>\n",
       "      <td>[[46, 13], [10, 82]]</td>\n",
       "      <td>[[43, 16], [10, 82]]</td>\n",
       "      <td>[[42, 17], [13, 79]]</td>\n",
       "      <td>[[43, 16], [10, 82]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[42, 17], [9, 83]]</td>\n",
       "      <td>[[41, 18], [14, 78]]</td>\n",
       "      <td>[[52, 7], [26, 66]]</td>\n",
       "      <td>[[46, 13], [11, 81]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[[41, 18], [20, 72]]</td>\n",
       "      <td>[[39, 20], [16, 76]]</td>\n",
       "      <td>[[41, 18], [20, 72]]</td>\n",
       "      <td>[[43, 16], [18, 74]]</td>\n",
       "      <td>[[44, 15], [20, 72]]</td>\n",
       "      <td>[[43, 16], [17, 75]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[42, 17], [19, 73]]</td>\n",
       "      <td>[[38, 21], [11, 81]]</td>\n",
       "      <td>[[48, 11], [20, 72]]</td>\n",
       "      <td>[[44, 15], [16, 76]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[[41, 18], [18, 74]]</td>\n",
       "      <td>[[44, 15], [15, 77]]</td>\n",
       "      <td>[[43, 16], [14, 78]]</td>\n",
       "      <td>[[48, 11], [18, 74]]</td>\n",
       "      <td>[[36, 23], [14, 78]]</td>\n",
       "      <td>[[47, 12], [18, 74]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[46, 13], [14, 78]]</td>\n",
       "      <td>[[45, 14], [14, 78]]</td>\n",
       "      <td>[[44, 15], [10, 82]]</td>\n",
       "      <td>[[47, 12], [18, 74]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Nearest Neighbors            Linear SVM               RBF SVM  \\\n",
       "0   [[41, 18], [10, 82]]   [[52, 7], [10, 82]]   [[47, 12], [9, 83]]   \n",
       "1   [[35, 24], [17, 75]]  [[40, 19], [13, 79]]  [[37, 22], [13, 79]]   \n",
       "2    [[39, 20], [9, 83]]    [[51, 8], [8, 84]]    [[50, 9], [8, 84]]   \n",
       "3    [[46, 13], [7, 85]]   [[47, 12], [7, 85]]   [[50, 9], [11, 81]]   \n",
       "4   [[36, 23], [19, 73]]  [[46, 13], [12, 80]]  [[49, 10], [12, 80]]   \n",
       "5   [[39, 20], [22, 70]]  [[42, 17], [10, 82]]  [[49, 10], [18, 74]]   \n",
       "6   [[35, 24], [17, 75]]  [[40, 19], [13, 79]]  [[37, 22], [13, 79]]   \n",
       "7   [[39, 20], [11, 81]]   [[46, 13], [9, 83]]   [[44, 15], [8, 84]]   \n",
       "8   [[43, 16], [20, 72]]  [[45, 14], [15, 77]]  [[44, 15], [16, 76]]   \n",
       "9   [[41, 18], [23, 69]]  [[47, 12], [10, 82]]  [[49, 10], [12, 80]]   \n",
       "10  [[38, 21], [12, 80]]  [[45, 14], [10, 82]]  [[46, 13], [10, 82]]   \n",
       "11  [[41, 18], [20, 72]]  [[39, 20], [16, 76]]  [[41, 18], [20, 72]]   \n",
       "12  [[41, 18], [18, 74]]  [[44, 15], [15, 77]]  [[43, 16], [14, 78]]   \n",
       "\n",
       "        Gaussian Process         Decision Tree         Random Forest  \\\n",
       "0    [[48, 11], [8, 84]]  [[38, 21], [10, 82]]  [[47, 12], [11, 81]]   \n",
       "1   [[44, 15], [17, 75]]  [[36, 23], [12, 80]]  [[43, 16], [19, 73]]   \n",
       "2    [[49, 10], [9, 83]]   [[52, 7], [21, 71]]   [[47, 12], [7, 85]]   \n",
       "3   [[46, 13], [11, 81]]  [[44, 15], [25, 67]]  [[42, 17], [12, 80]]   \n",
       "4   [[42, 17], [12, 80]]   [[51, 8], [41, 51]]  [[45, 14], [21, 71]]   \n",
       "5    [[50, 9], [16, 76]]   [[54, 5], [46, 46]]  [[46, 13], [19, 73]]   \n",
       "6   [[44, 15], [17, 75]]  [[36, 23], [12, 80]]  [[42, 17], [19, 73]]   \n",
       "7    [[45, 14], [9, 83]]   [[43, 16], [9, 83]]  [[44, 15], [11, 81]]   \n",
       "8   [[46, 13], [17, 75]]  [[33, 26], [12, 80]]  [[42, 17], [16, 76]]   \n",
       "9    [[51, 8], [11, 81]]  [[41, 18], [15, 77]]  [[44, 15], [14, 78]]   \n",
       "10  [[43, 16], [10, 82]]  [[42, 17], [13, 79]]  [[43, 16], [10, 82]]   \n",
       "11  [[43, 16], [18, 74]]  [[44, 15], [20, 72]]  [[43, 16], [17, 75]]   \n",
       "12  [[48, 11], [18, 74]]  [[36, 23], [14, 78]]  [[47, 12], [18, 74]]   \n",
       "\n",
       "            Neural Net              AdaBoost           Naive Bayes  \\\n",
       "0   [[0, 59], [0, 92]]  [[45, 14], [11, 81]]  [[42, 17], [13, 79]]   \n",
       "1   [[0, 59], [0, 92]]  [[40, 19], [25, 67]]  [[31, 28], [11, 81]]   \n",
       "2   [[0, 59], [0, 92]]   [[42, 17], [9, 83]]  [[43, 16], [14, 78]]   \n",
       "3   [[0, 59], [0, 92]]  [[38, 21], [12, 80]]  [[34, 25], [14, 78]]   \n",
       "4   [[0, 59], [0, 92]]  [[38, 21], [17, 75]]  [[37, 22], [13, 79]]   \n",
       "5   [[0, 59], [0, 92]]  [[46, 13], [15, 77]]  [[34, 25], [16, 76]]   \n",
       "6   [[0, 59], [0, 92]]  [[40, 19], [25, 67]]  [[31, 28], [11, 81]]   \n",
       "7   [[0, 59], [0, 92]]  [[42, 17], [11, 81]]  [[41, 18], [13, 79]]   \n",
       "8   [[0, 59], [0, 92]]  [[41, 18], [21, 71]]  [[37, 22], [11, 81]]   \n",
       "9   [[0, 59], [0, 92]]  [[42, 17], [17, 75]]  [[39, 20], [13, 79]]   \n",
       "10  [[0, 59], [0, 92]]   [[42, 17], [9, 83]]  [[41, 18], [14, 78]]   \n",
       "11  [[0, 59], [0, 92]]  [[42, 17], [19, 73]]  [[38, 21], [11, 81]]   \n",
       "12  [[0, 59], [0, 92]]  [[46, 13], [14, 78]]  [[45, 14], [14, 78]]   \n",
       "\n",
       "                     QDA               XGBoost  \n",
       "0    [[45, 14], [8, 84]]  [[43, 16], [14, 78]]  \n",
       "1    [[51, 8], [41, 51]]  [[41, 18], [19, 73]]  \n",
       "2    [[40, 19], [6, 86]]  [[47, 12], [10, 82]]  \n",
       "3    [[35, 24], [4, 88]]  [[44, 15], [15, 77]]  \n",
       "4    [[53, 6], [23, 69]]  [[44, 15], [19, 73]]  \n",
       "5   [[31, 28], [10, 82]]  [[48, 11], [16, 76]]  \n",
       "6   [[47, 12], [34, 58]]  [[41, 18], [19, 73]]  \n",
       "7    [[41, 18], [5, 87]]  [[46, 13], [10, 82]]  \n",
       "8    [[55, 4], [35, 57]]  [[44, 15], [18, 74]]  \n",
       "9    [[51, 8], [29, 63]]  [[43, 16], [18, 74]]  \n",
       "10   [[52, 7], [26, 66]]  [[46, 13], [11, 81]]  \n",
       "11  [[48, 11], [20, 72]]  [[44, 15], [16, 76]]  \n",
       "12  [[44, 15], [10, 82]]  [[47, 12], [18, 74]]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ 12 pontos - 2 raio ------\n",
      "--- Acuracia ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.860927</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.880795</td>\n",
       "      <td>0.841060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.662252</td>\n",
       "      <td>0.781457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.887417</td>\n",
       "      <td>0.880795</td>\n",
       "      <td>0.880795</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.860927</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.841060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.880795</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.860927</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.841060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.668874</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.748344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.781457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.649007</td>\n",
       "      <td>0.781457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.814570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.615894</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.781457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.867550</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.615894</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.847682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.860927</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.860927</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.880795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.622517</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.774834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.821192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.814570    0.854305  0.847682          0.860927       0.768212   \n",
       "1            0.761589    0.801325  0.821192          0.821192       0.748344   \n",
       "2            0.834437    0.887417  0.880795          0.880795       0.715232   \n",
       "3            0.794702    0.880795  0.834437          0.860927       0.708609   \n",
       "4            0.721854    0.761589  0.768212          0.794702       0.668874   \n",
       "5            0.721854    0.807947  0.814570          0.847682       0.708609   \n",
       "6            0.761589    0.801325  0.821192          0.821192       0.748344   \n",
       "7            0.807947    0.854305  0.841060          0.834437       0.841060   \n",
       "8            0.741722    0.807947  0.814570          0.794702       0.748344   \n",
       "9            0.768212    0.834437  0.821192          0.867550       0.781457   \n",
       "10           0.801325    0.860927  0.834437          0.860927       0.781457   \n",
       "11           0.748344    0.781457  0.814570          0.774834       0.754967   \n",
       "12           0.721854    0.801325  0.854305          0.854305       0.741722   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.841060    0.609272  0.807947     0.807947  0.880795  0.841060  \n",
       "1        0.754967    0.609272  0.741722     0.748344  0.662252  0.781457  \n",
       "2        0.860927    0.609272  0.768212     0.807947  0.834437  0.841060  \n",
       "3        0.827815    0.609272  0.761589     0.754967  0.827815  0.841060  \n",
       "4        0.754967    0.609272  0.741722     0.735099  0.807947  0.748344  \n",
       "5        0.794702    0.609272  0.774834     0.774834  0.754967  0.781457  \n",
       "6        0.754967    0.609272  0.741722     0.748344  0.649007  0.781457  \n",
       "7        0.847682    0.609272  0.794702     0.794702  0.821192  0.814570  \n",
       "8        0.754967    0.615894  0.768212     0.774834  0.728477  0.781457  \n",
       "9        0.841060    0.615894  0.841060     0.761589  0.794702  0.847682  \n",
       "10       0.847682    0.609272  0.807947     0.794702  0.801325  0.880795  \n",
       "11       0.774834    0.622517  0.754967     0.774834  0.735099  0.774834  \n",
       "12       0.794702    0.609272  0.821192     0.801325  0.768212  0.821192  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- F1 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.853299</td>\n",
       "      <td>0.846327</td>\n",
       "      <td>0.859690</td>\n",
       "      <td>0.770560</td>\n",
       "      <td>0.842226</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.807645</td>\n",
       "      <td>0.805411</td>\n",
       "      <td>0.877696</td>\n",
       "      <td>0.841511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.762849</td>\n",
       "      <td>0.797247</td>\n",
       "      <td>0.821455</td>\n",
       "      <td>0.821927</td>\n",
       "      <td>0.740303</td>\n",
       "      <td>0.755974</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.741316</td>\n",
       "      <td>0.740303</td>\n",
       "      <td>0.663170</td>\n",
       "      <td>0.782355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.833606</td>\n",
       "      <td>0.886852</td>\n",
       "      <td>0.880408</td>\n",
       "      <td>0.880408</td>\n",
       "      <td>0.718583</td>\n",
       "      <td>0.861499</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.766150</td>\n",
       "      <td>0.805411</td>\n",
       "      <td>0.833606</td>\n",
       "      <td>0.840544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.791991</td>\n",
       "      <td>0.879484</td>\n",
       "      <td>0.832251</td>\n",
       "      <td>0.858428</td>\n",
       "      <td>0.710748</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.756696</td>\n",
       "      <td>0.746360</td>\n",
       "      <td>0.818685</td>\n",
       "      <td>0.839312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.718796</td>\n",
       "      <td>0.756696</td>\n",
       "      <td>0.761511</td>\n",
       "      <td>0.791013</td>\n",
       "      <td>0.670623</td>\n",
       "      <td>0.754582</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.735731</td>\n",
       "      <td>0.730985</td>\n",
       "      <td>0.796995</td>\n",
       "      <td>0.744436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.719934</td>\n",
       "      <td>0.802395</td>\n",
       "      <td>0.816484</td>\n",
       "      <td>0.847906</td>\n",
       "      <td>0.707664</td>\n",
       "      <td>0.794380</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.776024</td>\n",
       "      <td>0.770213</td>\n",
       "      <td>0.755327</td>\n",
       "      <td>0.782355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.762849</td>\n",
       "      <td>0.797247</td>\n",
       "      <td>0.821455</td>\n",
       "      <td>0.821927</td>\n",
       "      <td>0.740303</td>\n",
       "      <td>0.755974</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.741316</td>\n",
       "      <td>0.740303</td>\n",
       "      <td>0.645399</td>\n",
       "      <td>0.782355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.806983</td>\n",
       "      <td>0.853299</td>\n",
       "      <td>0.840544</td>\n",
       "      <td>0.832964</td>\n",
       "      <td>0.837798</td>\n",
       "      <td>0.847443</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.792876</td>\n",
       "      <td>0.792876</td>\n",
       "      <td>0.816023</td>\n",
       "      <td>0.815096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.743364</td>\n",
       "      <td>0.806983</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.795004</td>\n",
       "      <td>0.750614</td>\n",
       "      <td>0.756983</td>\n",
       "      <td>0.476272</td>\n",
       "      <td>0.767848</td>\n",
       "      <td>0.772358</td>\n",
       "      <td>0.699677</td>\n",
       "      <td>0.782355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.770119</td>\n",
       "      <td>0.833606</td>\n",
       "      <td>0.821455</td>\n",
       "      <td>0.867120</td>\n",
       "      <td>0.768994</td>\n",
       "      <td>0.842226</td>\n",
       "      <td>0.476272</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.760816</td>\n",
       "      <td>0.795546</td>\n",
       "      <td>0.848308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.799140</td>\n",
       "      <td>0.859690</td>\n",
       "      <td>0.832964</td>\n",
       "      <td>0.859690</td>\n",
       "      <td>0.783255</td>\n",
       "      <td>0.845670</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.806238</td>\n",
       "      <td>0.792876</td>\n",
       "      <td>0.802783</td>\n",
       "      <td>0.880408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.749059</td>\n",
       "      <td>0.780359</td>\n",
       "      <td>0.816242</td>\n",
       "      <td>0.775474</td>\n",
       "      <td>0.756983</td>\n",
       "      <td>0.774104</td>\n",
       "      <td>0.490791</td>\n",
       "      <td>0.757624</td>\n",
       "      <td>0.768982</td>\n",
       "      <td>0.716565</td>\n",
       "      <td>0.775474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.719934</td>\n",
       "      <td>0.802783</td>\n",
       "      <td>0.854718</td>\n",
       "      <td>0.855619</td>\n",
       "      <td>0.743364</td>\n",
       "      <td>0.796928</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.823267</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.768842</td>\n",
       "      <td>0.822663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.814570    0.853299  0.846327          0.859690       0.770560   \n",
       "1            0.762849    0.797247  0.821455          0.821927       0.740303   \n",
       "2            0.833606    0.886852  0.880408          0.880408       0.718583   \n",
       "3            0.791991    0.879484  0.832251          0.858428       0.710748   \n",
       "4            0.718796    0.756696  0.761511          0.791013       0.670623   \n",
       "5            0.719934    0.802395  0.816484          0.847906       0.707664   \n",
       "6            0.762849    0.797247  0.821455          0.821927       0.740303   \n",
       "7            0.806983    0.853299  0.840544          0.832964       0.837798   \n",
       "8            0.743364    0.806983  0.814570          0.795004       0.750614   \n",
       "9            0.770119    0.833606  0.821455          0.867120       0.768994   \n",
       "10           0.799140    0.859690  0.832964          0.859690       0.783255   \n",
       "11           0.749059    0.780359  0.816242          0.775474       0.756983   \n",
       "12           0.719934    0.802783  0.854718          0.855619       0.743364   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.842226    0.461341  0.807645     0.805411  0.877696  0.841511  \n",
       "1        0.755974    0.461341  0.741316     0.740303  0.663170  0.782355  \n",
       "2        0.861499    0.461341  0.766150     0.805411  0.833606  0.840544  \n",
       "3        0.827815    0.461341  0.756696     0.746360  0.818685  0.839312  \n",
       "4        0.754582    0.461341  0.735731     0.730985  0.796995  0.744436  \n",
       "5        0.794380    0.461341  0.776024     0.770213  0.755327  0.782355  \n",
       "6        0.755974    0.461341  0.741316     0.740303  0.645399  0.782355  \n",
       "7        0.847443    0.461341  0.792876     0.792876  0.816023  0.815096  \n",
       "8        0.756983    0.476272  0.767848     0.772358  0.699677  0.782355  \n",
       "9        0.842226    0.476272  0.841060     0.760816  0.795546  0.848308  \n",
       "10       0.845670    0.461341  0.806238     0.792876  0.802783  0.880408  \n",
       "11       0.774104    0.490791  0.757624     0.768982  0.716565  0.775474  \n",
       "12       0.796928    0.461341  0.823267     0.801325  0.768842  0.822663  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Precision Score ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.853557</td>\n",
       "      <td>0.846942</td>\n",
       "      <td>0.860459</td>\n",
       "      <td>0.808835</td>\n",
       "      <td>0.846071</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.807417</td>\n",
       "      <td>0.806569</td>\n",
       "      <td>0.887184</td>\n",
       "      <td>0.842263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.765183</td>\n",
       "      <td>0.800794</td>\n",
       "      <td>0.821791</td>\n",
       "      <td>0.823320</td>\n",
       "      <td>0.746362</td>\n",
       "      <td>0.757581</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.740977</td>\n",
       "      <td>0.746362</td>\n",
       "      <td>0.722121</td>\n",
       "      <td>0.783876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.833462</td>\n",
       "      <td>0.887025</td>\n",
       "      <td>0.880345</td>\n",
       "      <td>0.880345</td>\n",
       "      <td>0.744556</td>\n",
       "      <td>0.862763</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.765841</td>\n",
       "      <td>0.806569</td>\n",
       "      <td>0.833462</td>\n",
       "      <td>0.840335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.792901</td>\n",
       "      <td>0.881162</td>\n",
       "      <td>0.833906</td>\n",
       "      <td>0.862627</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.758953</td>\n",
       "      <td>0.754271</td>\n",
       "      <td>0.844826</td>\n",
       "      <td>0.840394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.718090</td>\n",
       "      <td>0.758953</td>\n",
       "      <td>0.767303</td>\n",
       "      <td>0.793392</td>\n",
       "      <td>0.673304</td>\n",
       "      <td>0.754265</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.738156</td>\n",
       "      <td>0.731193</td>\n",
       "      <td>0.824076</td>\n",
       "      <td>0.744947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.719050</td>\n",
       "      <td>0.810193</td>\n",
       "      <td>0.825537</td>\n",
       "      <td>0.848206</td>\n",
       "      <td>0.706970</td>\n",
       "      <td>0.794129</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.778308</td>\n",
       "      <td>0.772900</td>\n",
       "      <td>0.755754</td>\n",
       "      <td>0.783876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.765183</td>\n",
       "      <td>0.800794</td>\n",
       "      <td>0.821791</td>\n",
       "      <td>0.823320</td>\n",
       "      <td>0.746362</td>\n",
       "      <td>0.757581</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.740977</td>\n",
       "      <td>0.746362</td>\n",
       "      <td>0.736127</td>\n",
       "      <td>0.783876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.806681</td>\n",
       "      <td>0.853557</td>\n",
       "      <td>0.840335</td>\n",
       "      <td>0.833426</td>\n",
       "      <td>0.842636</td>\n",
       "      <td>0.847281</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.792875</td>\n",
       "      <td>0.792875</td>\n",
       "      <td>0.824490</td>\n",
       "      <td>0.815913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.746634</td>\n",
       "      <td>0.806681</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.795376</td>\n",
       "      <td>0.757071</td>\n",
       "      <td>0.762239</td>\n",
       "      <td>0.764415</td>\n",
       "      <td>0.767553</td>\n",
       "      <td>0.772448</td>\n",
       "      <td>0.751904</td>\n",
       "      <td>0.783876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.775327</td>\n",
       "      <td>0.833462</td>\n",
       "      <td>0.821791</td>\n",
       "      <td>0.867008</td>\n",
       "      <td>0.792728</td>\n",
       "      <td>0.846071</td>\n",
       "      <td>0.764415</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.760316</td>\n",
       "      <td>0.797024</td>\n",
       "      <td>0.849616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.799626</td>\n",
       "      <td>0.860459</td>\n",
       "      <td>0.833426</td>\n",
       "      <td>0.860459</td>\n",
       "      <td>0.788415</td>\n",
       "      <td>0.847574</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.806392</td>\n",
       "      <td>0.792875</td>\n",
       "      <td>0.806784</td>\n",
       "      <td>0.880345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.750038</td>\n",
       "      <td>0.779900</td>\n",
       "      <td>0.822496</td>\n",
       "      <td>0.776388</td>\n",
       "      <td>0.762239</td>\n",
       "      <td>0.773653</td>\n",
       "      <td>0.766923</td>\n",
       "      <td>0.768252</td>\n",
       "      <td>0.773810</td>\n",
       "      <td>0.742616</td>\n",
       "      <td>0.776388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.719050</td>\n",
       "      <td>0.806784</td>\n",
       "      <td>0.855439</td>\n",
       "      <td>0.861751</td>\n",
       "      <td>0.746634</td>\n",
       "      <td>0.807563</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.837478</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.836757</td>\n",
       "      <td>0.827679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.814570    0.853557  0.846942          0.860459       0.808835   \n",
       "1            0.765183    0.800794  0.821791          0.823320       0.746362   \n",
       "2            0.833462    0.887025  0.880345          0.880345       0.744556   \n",
       "3            0.792901    0.881162  0.833906          0.862627       0.715113   \n",
       "4            0.718090    0.758953  0.767303          0.793392       0.673304   \n",
       "5            0.719050    0.810193  0.825537          0.848206       0.706970   \n",
       "6            0.765183    0.800794  0.821791          0.823320       0.746362   \n",
       "7            0.806681    0.853557  0.840335          0.833426       0.842636   \n",
       "8            0.746634    0.806681  0.814570          0.795376       0.757071   \n",
       "9            0.775327    0.833462  0.821791          0.867008       0.792728   \n",
       "10           0.799626    0.860459  0.833426          0.860459       0.788415   \n",
       "11           0.750038    0.779900  0.822496          0.776388       0.762239   \n",
       "12           0.719050    0.806784  0.855439          0.861751       0.746634   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.846071    0.371212  0.807417     0.806569  0.887184  0.842263  \n",
       "1        0.757581    0.371212  0.740977     0.746362  0.722121  0.783876  \n",
       "2        0.862763    0.371212  0.765841     0.806569  0.833462  0.840335  \n",
       "3        0.827815    0.371212  0.758953     0.754271  0.844826  0.840394  \n",
       "4        0.754265    0.371212  0.738156     0.731193  0.824076  0.744947  \n",
       "5        0.794129    0.371212  0.778308     0.772900  0.755754  0.783876  \n",
       "6        0.757581    0.371212  0.740977     0.746362  0.736127  0.783876  \n",
       "7        0.847281    0.371212  0.792875     0.792875  0.824490  0.815913  \n",
       "8        0.762239    0.764415  0.767553     0.772448  0.751904  0.783876  \n",
       "9        0.846071    0.764415  0.841060     0.760316  0.797024  0.849616  \n",
       "10       0.847574    0.371212  0.806392     0.792875  0.806784  0.880345  \n",
       "11       0.773653    0.766923  0.768252     0.773810  0.742616  0.776388  \n",
       "12       0.807563    0.371212  0.837478     0.801325  0.836757  0.827679  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Recall Score ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.860927</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.880795</td>\n",
       "      <td>0.841060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.662252</td>\n",
       "      <td>0.781457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.887417</td>\n",
       "      <td>0.880795</td>\n",
       "      <td>0.880795</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.860927</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.841060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.880795</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.860927</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.841060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.668874</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.748344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.781457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.649007</td>\n",
       "      <td>0.781457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.814570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.615894</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.781457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.867550</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.615894</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.847682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.860927</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.860927</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.880795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.622517</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.774834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.821192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.814570    0.854305  0.847682          0.860927       0.768212   \n",
       "1            0.761589    0.801325  0.821192          0.821192       0.748344   \n",
       "2            0.834437    0.887417  0.880795          0.880795       0.715232   \n",
       "3            0.794702    0.880795  0.834437          0.860927       0.708609   \n",
       "4            0.721854    0.761589  0.768212          0.794702       0.668874   \n",
       "5            0.721854    0.807947  0.814570          0.847682       0.708609   \n",
       "6            0.761589    0.801325  0.821192          0.821192       0.748344   \n",
       "7            0.807947    0.854305  0.841060          0.834437       0.841060   \n",
       "8            0.741722    0.807947  0.814570          0.794702       0.748344   \n",
       "9            0.768212    0.834437  0.821192          0.867550       0.781457   \n",
       "10           0.801325    0.860927  0.834437          0.860927       0.781457   \n",
       "11           0.748344    0.781457  0.814570          0.774834       0.754967   \n",
       "12           0.721854    0.801325  0.854305          0.854305       0.741722   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.841060    0.609272  0.807947     0.807947  0.880795  0.841060  \n",
       "1        0.754967    0.609272  0.741722     0.748344  0.662252  0.781457  \n",
       "2        0.860927    0.609272  0.768212     0.807947  0.834437  0.841060  \n",
       "3        0.827815    0.609272  0.761589     0.754967  0.827815  0.841060  \n",
       "4        0.754967    0.609272  0.741722     0.735099  0.807947  0.748344  \n",
       "5        0.794702    0.609272  0.774834     0.774834  0.754967  0.781457  \n",
       "6        0.754967    0.609272  0.741722     0.748344  0.649007  0.781457  \n",
       "7        0.847682    0.609272  0.794702     0.794702  0.821192  0.814570  \n",
       "8        0.754967    0.615894  0.768212     0.774834  0.728477  0.781457  \n",
       "9        0.841060    0.615894  0.841060     0.761589  0.794702  0.847682  \n",
       "10       0.847682    0.609272  0.807947     0.794702  0.801325  0.880795  \n",
       "11       0.774834    0.622517  0.754967     0.774834  0.735099  0.774834  \n",
       "12       0.794702    0.609272  0.821192     0.801325  0.768212  0.821192  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Matriz confusao ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[45, 14], [14, 78]]</td>\n",
       "      <td>[[46, 13], [9, 83]]</td>\n",
       "      <td>[[45, 14], [9, 83]]</td>\n",
       "      <td>[[46, 13], [8, 84]]</td>\n",
       "      <td>[[53, 6], [29, 63]]</td>\n",
       "      <td>[[50, 9], [15, 77]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[44, 15], [14, 78]]</td>\n",
       "      <td>[[41, 18], [11, 81]]</td>\n",
       "      <td>[[44, 15], [3, 89]]</td>\n",
       "      <td>[[48, 11], [13, 79]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[43, 16], [20, 72]]</td>\n",
       "      <td>[[39, 20], [10, 82]]</td>\n",
       "      <td>[[46, 13], [14, 78]]</td>\n",
       "      <td>[[47, 12], [15, 77]]</td>\n",
       "      <td>[[33, 26], [12, 80]]</td>\n",
       "      <td>[[42, 17], [20, 72]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[39, 20], [19, 73]]</td>\n",
       "      <td>[[33, 26], [12, 80]]</td>\n",
       "      <td>[[49, 10], [41, 51]]</td>\n",
       "      <td>[[44, 15], [18, 74]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[45, 14], [11, 81]]</td>\n",
       "      <td>[[49, 10], [7, 85]]</td>\n",
       "      <td>[[49, 10], [8, 84]]</td>\n",
       "      <td>[[49, 10], [8, 84]]</td>\n",
       "      <td>[[47, 12], [31, 61]]</td>\n",
       "      <td>[[50, 9], [12, 80]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[39, 20], [15, 77]]</td>\n",
       "      <td>[[41, 18], [11, 81]]</td>\n",
       "      <td>[[45, 14], [11, 81]]</td>\n",
       "      <td>[[46, 13], [11, 81]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[40, 19], [12, 80]]</td>\n",
       "      <td>[[47, 12], [6, 86]]</td>\n",
       "      <td>[[43, 16], [9, 83]]</td>\n",
       "      <td>[[44, 15], [6, 86]]</td>\n",
       "      <td>[[40, 19], [25, 67]]</td>\n",
       "      <td>[[46, 13], [13, 79]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[36, 23], [13, 79]]</td>\n",
       "      <td>[[33, 26], [11, 81]]</td>\n",
       "      <td>[[36, 23], [3, 89]]</td>\n",
       "      <td>[[44, 15], [9, 83]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[35, 24], [18, 74]]</td>\n",
       "      <td>[[36, 23], [13, 79]]</td>\n",
       "      <td>[[35, 24], [11, 81]]</td>\n",
       "      <td>[[39, 20], [11, 81]]</td>\n",
       "      <td>[[36, 23], [27, 65]]</td>\n",
       "      <td>[[40, 19], [18, 74]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[34, 25], [14, 78]]</td>\n",
       "      <td>[[35, 24], [16, 76]]</td>\n",
       "      <td>[[34, 25], [4, 88]]</td>\n",
       "      <td>[[36, 23], [15, 77]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[[36, 23], [19, 73]]</td>\n",
       "      <td>[[38, 21], [8, 84]]</td>\n",
       "      <td>[[50, 9], [19, 73]]</td>\n",
       "      <td>[[48, 11], [12, 80]]</td>\n",
       "      <td>[[36, 23], [21, 71]]</td>\n",
       "      <td>[[43, 16], [15, 77]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[44, 15], [19, 73]]</td>\n",
       "      <td>[[37, 22], [12, 80]]</td>\n",
       "      <td>[[41, 18], [19, 73]]</td>\n",
       "      <td>[[44, 15], [18, 74]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[[43, 16], [20, 72]]</td>\n",
       "      <td>[[39, 20], [10, 82]]</td>\n",
       "      <td>[[46, 13], [14, 78]]</td>\n",
       "      <td>[[47, 12], [15, 77]]</td>\n",
       "      <td>[[33, 26], [12, 80]]</td>\n",
       "      <td>[[42, 17], [20, 72]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[39, 20], [19, 73]]</td>\n",
       "      <td>[[33, 26], [12, 80]]</td>\n",
       "      <td>[[52, 7], [46, 46]]</td>\n",
       "      <td>[[44, 15], [18, 74]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[[43, 16], [13, 79]]</td>\n",
       "      <td>[[46, 13], [9, 83]]</td>\n",
       "      <td>[[46, 13], [11, 81]]</td>\n",
       "      <td>[[44, 15], [10, 82]]</td>\n",
       "      <td>[[42, 17], [7, 85]]</td>\n",
       "      <td>[[47, 12], [11, 81]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[41, 18], [13, 79]]</td>\n",
       "      <td>[[41, 18], [13, 79]]</td>\n",
       "      <td>[[39, 20], [7, 85]]</td>\n",
       "      <td>[[46, 13], [15, 77]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[[42, 17], [22, 70]]</td>\n",
       "      <td>[[43, 16], [13, 79]]</td>\n",
       "      <td>[[45, 14], [14, 78]]</td>\n",
       "      <td>[[44, 15], [16, 76]]</td>\n",
       "      <td>[[44, 15], [23, 69]]</td>\n",
       "      <td>[[44, 15], [22, 70]]</td>\n",
       "      <td>[[1, 58], [0, 92]]</td>\n",
       "      <td>[[41, 18], [17, 75]]</td>\n",
       "      <td>[[39, 20], [14, 78]]</td>\n",
       "      <td>[[23, 36], [5, 87]]</td>\n",
       "      <td>[[44, 15], [18, 74]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[[45, 14], [21, 71]]</td>\n",
       "      <td>[[45, 14], [11, 81]]</td>\n",
       "      <td>[[46, 13], [14, 78]]</td>\n",
       "      <td>[[48, 11], [9, 83]]</td>\n",
       "      <td>[[32, 27], [6, 86]]</td>\n",
       "      <td>[[50, 9], [15, 77]]</td>\n",
       "      <td>[[1, 58], [0, 92]]</td>\n",
       "      <td>[[47, 12], [12, 80]]</td>\n",
       "      <td>[[40, 19], [17, 75]]</td>\n",
       "      <td>[[45, 14], [17, 75]]</td>\n",
       "      <td>[[49, 10], [13, 79]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[[41, 18], [12, 80]]</td>\n",
       "      <td>[[46, 13], [8, 84]]</td>\n",
       "      <td>[[44, 15], [10, 82]]</td>\n",
       "      <td>[[46, 13], [8, 84]]</td>\n",
       "      <td>[[46, 13], [20, 72]]</td>\n",
       "      <td>[[44, 15], [8, 84]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[42, 17], [12, 80]]</td>\n",
       "      <td>[[41, 18], [13, 79]]</td>\n",
       "      <td>[[47, 12], [18, 74]]</td>\n",
       "      <td>[[49, 10], [8, 84]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[[41, 18], [20, 72]]</td>\n",
       "      <td>[[41, 18], [15, 77]]</td>\n",
       "      <td>[[49, 10], [18, 74]]</td>\n",
       "      <td>[[43, 16], [18, 74]]</td>\n",
       "      <td>[[44, 15], [22, 70]]</td>\n",
       "      <td>[[41, 18], [16, 76]]</td>\n",
       "      <td>[[2, 57], [0, 92]]</td>\n",
       "      <td>[[46, 13], [24, 68]]</td>\n",
       "      <td>[[36, 23], [11, 81]]</td>\n",
       "      <td>[[27, 32], [8, 84]]</td>\n",
       "      <td>[[43, 16], [18, 74]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[[36, 23], [19, 73]]</td>\n",
       "      <td>[[47, 12], [18, 74]]</td>\n",
       "      <td>[[49, 10], [12, 80]]</td>\n",
       "      <td>[[52, 7], [15, 77]]</td>\n",
       "      <td>[[42, 17], [22, 70]]</td>\n",
       "      <td>[[49, 10], [21, 71]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[52, 7], [20, 72]]</td>\n",
       "      <td>[[44, 15], [15, 77]]</td>\n",
       "      <td>[[57, 2], [33, 59]]</td>\n",
       "      <td>[[49, 10], [17, 75]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Nearest Neighbors            Linear SVM               RBF SVM  \\\n",
       "0   [[45, 14], [14, 78]]   [[46, 13], [9, 83]]   [[45, 14], [9, 83]]   \n",
       "1   [[43, 16], [20, 72]]  [[39, 20], [10, 82]]  [[46, 13], [14, 78]]   \n",
       "2   [[45, 14], [11, 81]]   [[49, 10], [7, 85]]   [[49, 10], [8, 84]]   \n",
       "3   [[40, 19], [12, 80]]   [[47, 12], [6, 86]]   [[43, 16], [9, 83]]   \n",
       "4   [[35, 24], [18, 74]]  [[36, 23], [13, 79]]  [[35, 24], [11, 81]]   \n",
       "5   [[36, 23], [19, 73]]   [[38, 21], [8, 84]]   [[50, 9], [19, 73]]   \n",
       "6   [[43, 16], [20, 72]]  [[39, 20], [10, 82]]  [[46, 13], [14, 78]]   \n",
       "7   [[43, 16], [13, 79]]   [[46, 13], [9, 83]]  [[46, 13], [11, 81]]   \n",
       "8   [[42, 17], [22, 70]]  [[43, 16], [13, 79]]  [[45, 14], [14, 78]]   \n",
       "9   [[45, 14], [21, 71]]  [[45, 14], [11, 81]]  [[46, 13], [14, 78]]   \n",
       "10  [[41, 18], [12, 80]]   [[46, 13], [8, 84]]  [[44, 15], [10, 82]]   \n",
       "11  [[41, 18], [20, 72]]  [[41, 18], [15, 77]]  [[49, 10], [18, 74]]   \n",
       "12  [[36, 23], [19, 73]]  [[47, 12], [18, 74]]  [[49, 10], [12, 80]]   \n",
       "\n",
       "        Gaussian Process         Decision Tree         Random Forest  \\\n",
       "0    [[46, 13], [8, 84]]   [[53, 6], [29, 63]]   [[50, 9], [15, 77]]   \n",
       "1   [[47, 12], [15, 77]]  [[33, 26], [12, 80]]  [[42, 17], [20, 72]]   \n",
       "2    [[49, 10], [8, 84]]  [[47, 12], [31, 61]]   [[50, 9], [12, 80]]   \n",
       "3    [[44, 15], [6, 86]]  [[40, 19], [25, 67]]  [[46, 13], [13, 79]]   \n",
       "4   [[39, 20], [11, 81]]  [[36, 23], [27, 65]]  [[40, 19], [18, 74]]   \n",
       "5   [[48, 11], [12, 80]]  [[36, 23], [21, 71]]  [[43, 16], [15, 77]]   \n",
       "6   [[47, 12], [15, 77]]  [[33, 26], [12, 80]]  [[42, 17], [20, 72]]   \n",
       "7   [[44, 15], [10, 82]]   [[42, 17], [7, 85]]  [[47, 12], [11, 81]]   \n",
       "8   [[44, 15], [16, 76]]  [[44, 15], [23, 69]]  [[44, 15], [22, 70]]   \n",
       "9    [[48, 11], [9, 83]]   [[32, 27], [6, 86]]   [[50, 9], [15, 77]]   \n",
       "10   [[46, 13], [8, 84]]  [[46, 13], [20, 72]]   [[44, 15], [8, 84]]   \n",
       "11  [[43, 16], [18, 74]]  [[44, 15], [22, 70]]  [[41, 18], [16, 76]]   \n",
       "12   [[52, 7], [15, 77]]  [[42, 17], [22, 70]]  [[49, 10], [21, 71]]   \n",
       "\n",
       "            Neural Net              AdaBoost           Naive Bayes  \\\n",
       "0   [[0, 59], [0, 92]]  [[44, 15], [14, 78]]  [[41, 18], [11, 81]]   \n",
       "1   [[0, 59], [0, 92]]  [[39, 20], [19, 73]]  [[33, 26], [12, 80]]   \n",
       "2   [[0, 59], [0, 92]]  [[39, 20], [15, 77]]  [[41, 18], [11, 81]]   \n",
       "3   [[0, 59], [0, 92]]  [[36, 23], [13, 79]]  [[33, 26], [11, 81]]   \n",
       "4   [[0, 59], [0, 92]]  [[34, 25], [14, 78]]  [[35, 24], [16, 76]]   \n",
       "5   [[0, 59], [0, 92]]  [[44, 15], [19, 73]]  [[37, 22], [12, 80]]   \n",
       "6   [[0, 59], [0, 92]]  [[39, 20], [19, 73]]  [[33, 26], [12, 80]]   \n",
       "7   [[0, 59], [0, 92]]  [[41, 18], [13, 79]]  [[41, 18], [13, 79]]   \n",
       "8   [[1, 58], [0, 92]]  [[41, 18], [17, 75]]  [[39, 20], [14, 78]]   \n",
       "9   [[1, 58], [0, 92]]  [[47, 12], [12, 80]]  [[40, 19], [17, 75]]   \n",
       "10  [[0, 59], [0, 92]]  [[42, 17], [12, 80]]  [[41, 18], [13, 79]]   \n",
       "11  [[2, 57], [0, 92]]  [[46, 13], [24, 68]]  [[36, 23], [11, 81]]   \n",
       "12  [[0, 59], [0, 92]]   [[52, 7], [20, 72]]  [[44, 15], [15, 77]]   \n",
       "\n",
       "                     QDA               XGBoost  \n",
       "0    [[44, 15], [3, 89]]  [[48, 11], [13, 79]]  \n",
       "1   [[49, 10], [41, 51]]  [[44, 15], [18, 74]]  \n",
       "2   [[45, 14], [11, 81]]  [[46, 13], [11, 81]]  \n",
       "3    [[36, 23], [3, 89]]   [[44, 15], [9, 83]]  \n",
       "4    [[34, 25], [4, 88]]  [[36, 23], [15, 77]]  \n",
       "5   [[41, 18], [19, 73]]  [[44, 15], [18, 74]]  \n",
       "6    [[52, 7], [46, 46]]  [[44, 15], [18, 74]]  \n",
       "7    [[39, 20], [7, 85]]  [[46, 13], [15, 77]]  \n",
       "8    [[23, 36], [5, 87]]  [[44, 15], [18, 74]]  \n",
       "9   [[45, 14], [17, 75]]  [[49, 10], [13, 79]]  \n",
       "10  [[47, 12], [18, 74]]   [[49, 10], [8, 84]]  \n",
       "11   [[27, 32], [8, 84]]  [[43, 16], [18, 74]]  \n",
       "12   [[57, 2], [33, 59]]  [[49, 10], [17, 75]]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ 16 pontos - 2 raio ------\n",
      "--- Acuracia ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.821192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.807947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.874172</td>\n",
       "      <td>0.874172</td>\n",
       "      <td>0.887417</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.874172</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.894040</td>\n",
       "      <td>0.894040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.867550</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.860927</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.860927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.649007</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.622517</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.774834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.867550</td>\n",
       "      <td>0.390728</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.821192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.807947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.860927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.741722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.860927</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.821192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.860927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.615894</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.774834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.807947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.821192    0.841060  0.834437          0.847682       0.854305   \n",
       "1            0.741722    0.781457  0.788079          0.807947       0.728477   \n",
       "2            0.814570    0.874172  0.874172          0.887417       0.788079   \n",
       "3            0.781457    0.867550  0.847682          0.860927       0.748344   \n",
       "4            0.649007    0.754967  0.801325          0.788079       0.622517   \n",
       "5            0.768212    0.821192  0.867550          0.390728       0.701987   \n",
       "6            0.741722    0.781457  0.788079          0.807947       0.728477   \n",
       "7            0.774834    0.841060  0.841060          0.847682       0.801325   \n",
       "8            0.761589    0.801325  0.781457          0.768212       0.728477   \n",
       "9            0.774834    0.847682  0.860927          0.834437       0.748344   \n",
       "10           0.781457    0.834437  0.821192          0.847682       0.768212   \n",
       "11           0.735099    0.788079  0.794702          0.774834       0.735099   \n",
       "12           0.774834    0.794702  0.841060          0.827815       0.748344   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.841060    0.609272  0.807947     0.801325  0.841060  0.821192  \n",
       "1        0.801325    0.609272  0.735099     0.754967  0.715232  0.807947  \n",
       "2        0.874172    0.609272  0.834437     0.847682  0.894040  0.894040  \n",
       "3        0.821192    0.609272  0.788079     0.768212  0.788079  0.860927  \n",
       "4        0.788079    0.609272  0.741722     0.748344  0.735099  0.774834  \n",
       "5        0.841060    0.609272  0.761589     0.774834  0.788079  0.821192  \n",
       "6        0.774834    0.609272  0.735099     0.754967  0.748344  0.807947  \n",
       "7        0.821192    0.609272  0.841060     0.794702  0.774834  0.860927  \n",
       "8        0.728477    0.609272  0.768212     0.774834  0.721854  0.741722  \n",
       "9        0.834437    0.609272  0.754967     0.761589  0.774834  0.821192  \n",
       "10       0.827815    0.609272  0.827815     0.801325  0.695364  0.860927  \n",
       "11       0.754967    0.615894  0.748344     0.814570  0.748344  0.774834  \n",
       "12       0.827815    0.609272  0.801325     0.788079  0.814570  0.807947  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- F1 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.822329</td>\n",
       "      <td>0.839962</td>\n",
       "      <td>0.832964</td>\n",
       "      <td>0.845670</td>\n",
       "      <td>0.855947</td>\n",
       "      <td>0.840544</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.806238</td>\n",
       "      <td>0.799140</td>\n",
       "      <td>0.842851</td>\n",
       "      <td>0.820911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.741316</td>\n",
       "      <td>0.773780</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.808229</td>\n",
       "      <td>0.726061</td>\n",
       "      <td>0.802783</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.732186</td>\n",
       "      <td>0.746360</td>\n",
       "      <td>0.718320</td>\n",
       "      <td>0.808229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.811690</td>\n",
       "      <td>0.873540</td>\n",
       "      <td>0.873540</td>\n",
       "      <td>0.887240</td>\n",
       "      <td>0.790341</td>\n",
       "      <td>0.873053</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.832964</td>\n",
       "      <td>0.846327</td>\n",
       "      <td>0.892875</td>\n",
       "      <td>0.892875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.779513</td>\n",
       "      <td>0.865493</td>\n",
       "      <td>0.846917</td>\n",
       "      <td>0.859690</td>\n",
       "      <td>0.741803</td>\n",
       "      <td>0.820911</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.785749</td>\n",
       "      <td>0.760070</td>\n",
       "      <td>0.778449</td>\n",
       "      <td>0.859690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.644371</td>\n",
       "      <td>0.751731</td>\n",
       "      <td>0.798239</td>\n",
       "      <td>0.782571</td>\n",
       "      <td>0.624438</td>\n",
       "      <td>0.786616</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.737081</td>\n",
       "      <td>0.743180</td>\n",
       "      <td>0.733844</td>\n",
       "      <td>0.773280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.764047</td>\n",
       "      <td>0.816023</td>\n",
       "      <td>0.868522</td>\n",
       "      <td>0.219552</td>\n",
       "      <td>0.696632</td>\n",
       "      <td>0.841899</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.763339</td>\n",
       "      <td>0.771338</td>\n",
       "      <td>0.785749</td>\n",
       "      <td>0.822329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.741316</td>\n",
       "      <td>0.773780</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.808229</td>\n",
       "      <td>0.726061</td>\n",
       "      <td>0.776487</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.732186</td>\n",
       "      <td>0.746360</td>\n",
       "      <td>0.750191</td>\n",
       "      <td>0.808229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.774104</td>\n",
       "      <td>0.839962</td>\n",
       "      <td>0.838591</td>\n",
       "      <td>0.846327</td>\n",
       "      <td>0.800680</td>\n",
       "      <td>0.820294</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.841511</td>\n",
       "      <td>0.792876</td>\n",
       "      <td>0.772358</td>\n",
       "      <td>0.859690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.763740</td>\n",
       "      <td>0.801889</td>\n",
       "      <td>0.781778</td>\n",
       "      <td>0.769164</td>\n",
       "      <td>0.722178</td>\n",
       "      <td>0.729593</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.770119</td>\n",
       "      <td>0.774104</td>\n",
       "      <td>0.683555</td>\n",
       "      <td>0.744232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.846917</td>\n",
       "      <td>0.861132</td>\n",
       "      <td>0.833606</td>\n",
       "      <td>0.749059</td>\n",
       "      <td>0.834680</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.755974</td>\n",
       "      <td>0.759943</td>\n",
       "      <td>0.771338</td>\n",
       "      <td>0.820911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.781114</td>\n",
       "      <td>0.832964</td>\n",
       "      <td>0.820294</td>\n",
       "      <td>0.847443</td>\n",
       "      <td>0.770939</td>\n",
       "      <td>0.826626</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.799140</td>\n",
       "      <td>0.692823</td>\n",
       "      <td>0.861132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.787392</td>\n",
       "      <td>0.795546</td>\n",
       "      <td>0.775474</td>\n",
       "      <td>0.737488</td>\n",
       "      <td>0.756983</td>\n",
       "      <td>0.476272</td>\n",
       "      <td>0.751181</td>\n",
       "      <td>0.812530</td>\n",
       "      <td>0.736908</td>\n",
       "      <td>0.775474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.774104</td>\n",
       "      <td>0.796007</td>\n",
       "      <td>0.842493</td>\n",
       "      <td>0.829367</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.829895</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.802374</td>\n",
       "      <td>0.788681</td>\n",
       "      <td>0.816700</td>\n",
       "      <td>0.810254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.822329    0.839962  0.832964          0.845670       0.855947   \n",
       "1            0.741316    0.773780  0.788079          0.808229       0.726061   \n",
       "2            0.811690    0.873540  0.873540          0.887240       0.790341   \n",
       "3            0.779513    0.865493  0.846917          0.859690       0.741803   \n",
       "4            0.644371    0.751731  0.798239          0.782571       0.624438   \n",
       "5            0.764047    0.816023  0.868522          0.219552       0.696632   \n",
       "6            0.741316    0.773780  0.788079          0.808229       0.726061   \n",
       "7            0.774104    0.839962  0.838591          0.846327       0.800680   \n",
       "8            0.763740    0.801889  0.781778          0.769164       0.722178   \n",
       "9            0.774834    0.846917  0.861132          0.833606       0.749059   \n",
       "10           0.781114    0.832964  0.820294          0.847443       0.770939   \n",
       "11           0.735099    0.787392  0.795546          0.775474       0.737488   \n",
       "12           0.774104    0.796007  0.842493          0.829367       0.748344   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.840544    0.461341  0.806238     0.799140  0.842851  0.820911  \n",
       "1        0.802783    0.461341  0.732186     0.746360  0.718320  0.808229  \n",
       "2        0.873053    0.461341  0.832964     0.846327  0.892875  0.892875  \n",
       "3        0.820911    0.461341  0.785749     0.760070  0.778449  0.859690  \n",
       "4        0.786616    0.461341  0.737081     0.743180  0.733844  0.773280  \n",
       "5        0.841899    0.461341  0.763339     0.771338  0.785749  0.822329  \n",
       "6        0.776487    0.461341  0.732186     0.746360  0.750191  0.808229  \n",
       "7        0.820294    0.461341  0.841511     0.792876  0.772358  0.859690  \n",
       "8        0.729593    0.461341  0.770119     0.774104  0.683555  0.744232  \n",
       "9        0.834680    0.461341  0.755974     0.759943  0.771338  0.820911  \n",
       "10       0.826626    0.461341  0.827815     0.799140  0.692823  0.861132  \n",
       "11       0.756983    0.476272  0.751181     0.812530  0.736908  0.775474  \n",
       "12       0.829895    0.461341  0.802374     0.788681  0.816700  0.810254  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Precision Score ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.825284</td>\n",
       "      <td>0.840106</td>\n",
       "      <td>0.833426</td>\n",
       "      <td>0.847574</td>\n",
       "      <td>0.868366</td>\n",
       "      <td>0.840335</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.806392</td>\n",
       "      <td>0.799626</td>\n",
       "      <td>0.855247</td>\n",
       "      <td>0.820705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.740977</td>\n",
       "      <td>0.783419</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.808584</td>\n",
       "      <td>0.725291</td>\n",
       "      <td>0.806784</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.731680</td>\n",
       "      <td>0.754271</td>\n",
       "      <td>0.728941</td>\n",
       "      <td>0.808584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.813718</td>\n",
       "      <td>0.873634</td>\n",
       "      <td>0.873634</td>\n",
       "      <td>0.887145</td>\n",
       "      <td>0.826238</td>\n",
       "      <td>0.873976</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.833426</td>\n",
       "      <td>0.846942</td>\n",
       "      <td>0.894751</td>\n",
       "      <td>0.894751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.779358</td>\n",
       "      <td>0.868734</td>\n",
       "      <td>0.846853</td>\n",
       "      <td>0.860459</td>\n",
       "      <td>0.745467</td>\n",
       "      <td>0.820705</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.786037</td>\n",
       "      <td>0.768845</td>\n",
       "      <td>0.794819</td>\n",
       "      <td>0.860459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.642550</td>\n",
       "      <td>0.751896</td>\n",
       "      <td>0.799964</td>\n",
       "      <td>0.787982</td>\n",
       "      <td>0.673682</td>\n",
       "      <td>0.786303</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.738004</td>\n",
       "      <td>0.745005</td>\n",
       "      <td>0.821949</td>\n",
       "      <td>0.772853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.765698</td>\n",
       "      <td>0.824490</td>\n",
       "      <td>0.872262</td>\n",
       "      <td>0.152669</td>\n",
       "      <td>0.696463</td>\n",
       "      <td>0.843936</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.767496</td>\n",
       "      <td>0.772456</td>\n",
       "      <td>0.786037</td>\n",
       "      <td>0.825284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.740977</td>\n",
       "      <td>0.783419</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.808584</td>\n",
       "      <td>0.725291</td>\n",
       "      <td>0.780592</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.731680</td>\n",
       "      <td>0.754271</td>\n",
       "      <td>0.754401</td>\n",
       "      <td>0.808584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.773653</td>\n",
       "      <td>0.840106</td>\n",
       "      <td>0.841226</td>\n",
       "      <td>0.846942</td>\n",
       "      <td>0.800326</td>\n",
       "      <td>0.820072</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.842263</td>\n",
       "      <td>0.792875</td>\n",
       "      <td>0.772448</td>\n",
       "      <td>0.860459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.770156</td>\n",
       "      <td>0.802738</td>\n",
       "      <td>0.782169</td>\n",
       "      <td>0.770729</td>\n",
       "      <td>0.724101</td>\n",
       "      <td>0.731285</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.775327</td>\n",
       "      <td>0.773653</td>\n",
       "      <td>0.763398</td>\n",
       "      <td>0.751987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.846853</td>\n",
       "      <td>0.861414</td>\n",
       "      <td>0.833462</td>\n",
       "      <td>0.750038</td>\n",
       "      <td>0.834999</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.757581</td>\n",
       "      <td>0.759402</td>\n",
       "      <td>0.772456</td>\n",
       "      <td>0.820705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.780841</td>\n",
       "      <td>0.833426</td>\n",
       "      <td>0.820072</td>\n",
       "      <td>0.847281</td>\n",
       "      <td>0.797978</td>\n",
       "      <td>0.826656</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.799626</td>\n",
       "      <td>0.785687</td>\n",
       "      <td>0.861414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.786989</td>\n",
       "      <td>0.797024</td>\n",
       "      <td>0.776388</td>\n",
       "      <td>0.743986</td>\n",
       "      <td>0.762239</td>\n",
       "      <td>0.764415</td>\n",
       "      <td>0.763413</td>\n",
       "      <td>0.813215</td>\n",
       "      <td>0.749613</td>\n",
       "      <td>0.776388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.773653</td>\n",
       "      <td>0.799067</td>\n",
       "      <td>0.848666</td>\n",
       "      <td>0.835581</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.850512</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.804559</td>\n",
       "      <td>0.789563</td>\n",
       "      <td>0.847449</td>\n",
       "      <td>0.828449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.825284    0.840106  0.833426          0.847574       0.868366   \n",
       "1            0.740977    0.783419  0.788079          0.808584       0.725291   \n",
       "2            0.813718    0.873634  0.873634          0.887145       0.826238   \n",
       "3            0.779358    0.868734  0.846853          0.860459       0.745467   \n",
       "4            0.642550    0.751896  0.799964          0.787982       0.673682   \n",
       "5            0.765698    0.824490  0.872262          0.152669       0.696463   \n",
       "6            0.740977    0.783419  0.788079          0.808584       0.725291   \n",
       "7            0.773653    0.840106  0.841226          0.846942       0.800326   \n",
       "8            0.770156    0.802738  0.782169          0.770729       0.724101   \n",
       "9            0.774834    0.846853  0.861414          0.833462       0.750038   \n",
       "10           0.780841    0.833426  0.820072          0.847281       0.797978   \n",
       "11           0.735099    0.786989  0.797024          0.776388       0.743986   \n",
       "12           0.773653    0.799067  0.848666          0.835581       0.748344   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.840335    0.371212  0.806392     0.799626  0.855247  0.820705  \n",
       "1        0.806784    0.371212  0.731680     0.754271  0.728941  0.808584  \n",
       "2        0.873976    0.371212  0.833426     0.846942  0.894751  0.894751  \n",
       "3        0.820705    0.371212  0.786037     0.768845  0.794819  0.860459  \n",
       "4        0.786303    0.371212  0.738004     0.745005  0.821949  0.772853  \n",
       "5        0.843936    0.371212  0.767496     0.772456  0.786037  0.825284  \n",
       "6        0.780592    0.371212  0.731680     0.754271  0.754401  0.808584  \n",
       "7        0.820072    0.371212  0.842263     0.792875  0.772448  0.860459  \n",
       "8        0.731285    0.371212  0.775327     0.773653  0.763398  0.751987  \n",
       "9        0.834999    0.371212  0.757581     0.759402  0.772456  0.820705  \n",
       "10       0.826656    0.371212  0.827815     0.799626  0.785687  0.861414  \n",
       "11       0.762239    0.764415  0.763413     0.813215  0.749613  0.776388  \n",
       "12       0.850512    0.371212  0.804559     0.789563  0.847449  0.828449  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Recall Score ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.821192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.807947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.874172</td>\n",
       "      <td>0.874172</td>\n",
       "      <td>0.887417</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.874172</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.894040</td>\n",
       "      <td>0.894040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.867550</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.860927</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.860927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.649007</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.622517</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.774834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.867550</td>\n",
       "      <td>0.390728</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.821192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.807947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.860927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.741722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.860927</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.821192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.860927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.615894</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.774834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.807947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.821192    0.841060  0.834437          0.847682       0.854305   \n",
       "1            0.741722    0.781457  0.788079          0.807947       0.728477   \n",
       "2            0.814570    0.874172  0.874172          0.887417       0.788079   \n",
       "3            0.781457    0.867550  0.847682          0.860927       0.748344   \n",
       "4            0.649007    0.754967  0.801325          0.788079       0.622517   \n",
       "5            0.768212    0.821192  0.867550          0.390728       0.701987   \n",
       "6            0.741722    0.781457  0.788079          0.807947       0.728477   \n",
       "7            0.774834    0.841060  0.841060          0.847682       0.801325   \n",
       "8            0.761589    0.801325  0.781457          0.768212       0.728477   \n",
       "9            0.774834    0.847682  0.860927          0.834437       0.748344   \n",
       "10           0.781457    0.834437  0.821192          0.847682       0.768212   \n",
       "11           0.735099    0.788079  0.794702          0.774834       0.735099   \n",
       "12           0.774834    0.794702  0.841060          0.827815       0.748344   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.841060    0.609272  0.807947     0.801325  0.841060  0.821192  \n",
       "1        0.801325    0.609272  0.735099     0.754967  0.715232  0.807947  \n",
       "2        0.874172    0.609272  0.834437     0.847682  0.894040  0.894040  \n",
       "3        0.821192    0.609272  0.788079     0.768212  0.788079  0.860927  \n",
       "4        0.788079    0.609272  0.741722     0.748344  0.735099  0.774834  \n",
       "5        0.841060    0.609272  0.761589     0.774834  0.788079  0.821192  \n",
       "6        0.774834    0.609272  0.735099     0.754967  0.748344  0.807947  \n",
       "7        0.821192    0.609272  0.841060     0.794702  0.774834  0.860927  \n",
       "8        0.728477    0.609272  0.768212     0.774834  0.721854  0.741722  \n",
       "9        0.834437    0.609272  0.754967     0.761589  0.774834  0.821192  \n",
       "10       0.827815    0.609272  0.827815     0.801325  0.695364  0.860927  \n",
       "11       0.754967    0.615894  0.748344     0.814570  0.748344  0.774834  \n",
       "12       0.827815    0.609272  0.801325     0.788079  0.814570  0.807947  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Matriz confusao ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[48, 11], [16, 76]]</td>\n",
       "      <td>[[45, 14], [10, 82]]</td>\n",
       "      <td>[[44, 15], [10, 82]]</td>\n",
       "      <td>[[44, 15], [8, 84]]</td>\n",
       "      <td>[[54, 5], [17, 75]]</td>\n",
       "      <td>[[46, 13], [11, 81]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[42, 17], [12, 80]]</td>\n",
       "      <td>[[41, 18], [12, 80]]</td>\n",
       "      <td>[[53, 6], [18, 74]]</td>\n",
       "      <td>[[45, 14], [13, 79]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[39, 20], [19, 73]]</td>\n",
       "      <td>[[35, 24], [9, 83]]</td>\n",
       "      <td>[[43, 16], [16, 76]]</td>\n",
       "      <td>[[45, 14], [15, 77]]</td>\n",
       "      <td>[[36, 23], [18, 74]]</td>\n",
       "      <td>[[47, 12], [18, 74]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[36, 23], [17, 75]]</td>\n",
       "      <td>[[33, 26], [11, 81]]</td>\n",
       "      <td>[[43, 16], [27, 65]]</td>\n",
       "      <td>[[45, 14], [15, 77]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[41, 18], [10, 82]]</td>\n",
       "      <td>[[48, 11], [8, 84]]</td>\n",
       "      <td>[[48, 11], [8, 84]]</td>\n",
       "      <td>[[50, 9], [8, 84]]</td>\n",
       "      <td>[[54, 5], [27, 65]]</td>\n",
       "      <td>[[47, 12], [7, 85]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[44, 15], [10, 82]]</td>\n",
       "      <td>[[45, 14], [9, 83]]</td>\n",
       "      <td>[[48, 11], [5, 87]]</td>\n",
       "      <td>[[48, 11], [5, 87]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[40, 19], [14, 78]]</td>\n",
       "      <td>[[45, 14], [6, 86]]</td>\n",
       "      <td>[[46, 13], [10, 82]]</td>\n",
       "      <td>[[46, 13], [8, 84]]</td>\n",
       "      <td>[[34, 25], [13, 79]]</td>\n",
       "      <td>[[45, 14], [13, 79]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[40, 19], [13, 79]]</td>\n",
       "      <td>[[34, 25], [10, 82]]</td>\n",
       "      <td>[[34, 25], [7, 85]]</td>\n",
       "      <td>[[46, 13], [8, 84]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[29, 30], [23, 69]]</td>\n",
       "      <td>[[37, 22], [15, 77]]</td>\n",
       "      <td>[[40, 19], [11, 81]]</td>\n",
       "      <td>[[37, 22], [10, 82]]</td>\n",
       "      <td>[[45, 14], [43, 49]]</td>\n",
       "      <td>[[41, 18], [14, 78]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[35, 24], [15, 77]]</td>\n",
       "      <td>[[35, 24], [14, 78]]</td>\n",
       "      <td>[[57, 2], [38, 54]]</td>\n",
       "      <td>[[40, 19], [15, 77]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[[37, 22], [13, 79]]</td>\n",
       "      <td>[[39, 20], [7, 85]]</td>\n",
       "      <td>[[52, 7], [13, 79]]</td>\n",
       "      <td>[[59, 0], [92, 0]]</td>\n",
       "      <td>[[32, 27], [18, 74]]</td>\n",
       "      <td>[[49, 10], [14, 78]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[44, 15], [21, 71]]</td>\n",
       "      <td>[[38, 21], [13, 79]]</td>\n",
       "      <td>[[40, 19], [13, 79]]</td>\n",
       "      <td>[[48, 11], [16, 76]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[[39, 20], [19, 73]]</td>\n",
       "      <td>[[35, 24], [9, 83]]</td>\n",
       "      <td>[[43, 16], [16, 76]]</td>\n",
       "      <td>[[45, 14], [15, 77]]</td>\n",
       "      <td>[[36, 23], [18, 74]]</td>\n",
       "      <td>[[45, 14], [20, 72]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[36, 23], [17, 75]]</td>\n",
       "      <td>[[33, 26], [11, 81]]</td>\n",
       "      <td>[[43, 16], [22, 70]]</td>\n",
       "      <td>[[45, 14], [15, 77]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[[41, 18], [16, 76]]</td>\n",
       "      <td>[[45, 14], [10, 82]]</td>\n",
       "      <td>[[43, 16], [8, 84]]</td>\n",
       "      <td>[[45, 14], [9, 83]]</td>\n",
       "      <td>[[43, 16], [14, 78]]</td>\n",
       "      <td>[[44, 15], [12, 80]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[48, 11], [13, 79]]</td>\n",
       "      <td>[[41, 18], [13, 79]]</td>\n",
       "      <td>[[39, 20], [14, 78]]</td>\n",
       "      <td>[[46, 13], [8, 84]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[[45, 14], [22, 70]]</td>\n",
       "      <td>[[45, 14], [16, 76]]</td>\n",
       "      <td>[[43, 16], [17, 75]]</td>\n",
       "      <td>[[43, 16], [19, 73]]</td>\n",
       "      <td>[[33, 26], [15, 77]]</td>\n",
       "      <td>[[40, 19], [22, 70]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[45, 14], [21, 71]]</td>\n",
       "      <td>[[41, 18], [16, 76]]</td>\n",
       "      <td>[[20, 39], [3, 89]]</td>\n",
       "      <td>[[44, 15], [24, 68]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[[42, 17], [17, 75]]</td>\n",
       "      <td>[[46, 13], [10, 82]]</td>\n",
       "      <td>[[49, 10], [11, 81]]</td>\n",
       "      <td>[[45, 14], [11, 81]]</td>\n",
       "      <td>[[41, 18], [20, 72]]</td>\n",
       "      <td>[[47, 12], [13, 79]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[42, 17], [20, 72]]</td>\n",
       "      <td>[[39, 20], [16, 76]]</td>\n",
       "      <td>[[38, 21], [13, 79]]</td>\n",
       "      <td>[[45, 14], [13, 79]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[[42, 17], [16, 76]]</td>\n",
       "      <td>[[44, 15], [10, 82]]</td>\n",
       "      <td>[[44, 15], [12, 80]]</td>\n",
       "      <td>[[47, 12], [11, 81]]</td>\n",
       "      <td>[[51, 8], [27, 65]]</td>\n",
       "      <td>[[44, 15], [11, 81]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[46, 13], [13, 79]]</td>\n",
       "      <td>[[41, 18], [12, 80]]</td>\n",
       "      <td>[[55, 4], [42, 50]]</td>\n",
       "      <td>[[49, 10], [11, 81]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[[39, 20], [20, 72]]</td>\n",
       "      <td>[[42, 17], [15, 77]]</td>\n",
       "      <td>[[45, 14], [17, 75]]</td>\n",
       "      <td>[[43, 16], [18, 74]]</td>\n",
       "      <td>[[43, 16], [24, 68]]</td>\n",
       "      <td>[[44, 15], [22, 70]]</td>\n",
       "      <td>[[1, 58], [0, 92]]</td>\n",
       "      <td>[[46, 13], [25, 67]]</td>\n",
       "      <td>[[42, 17], [11, 81]]</td>\n",
       "      <td>[[31, 28], [10, 82]]</td>\n",
       "      <td>[[43, 16], [18, 74]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[[41, 18], [16, 76]]</td>\n",
       "      <td>[[46, 13], [18, 74]]</td>\n",
       "      <td>[[51, 8], [16, 76]]</td>\n",
       "      <td>[[50, 9], [17, 75]]</td>\n",
       "      <td>[[40, 19], [19, 73]]</td>\n",
       "      <td>[[54, 5], [21, 71]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[46, 13], [17, 75]]</td>\n",
       "      <td>[[44, 15], [17, 75]]</td>\n",
       "      <td>[[55, 4], [24, 68]]</td>\n",
       "      <td>[[52, 7], [22, 70]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Nearest Neighbors            Linear SVM               RBF SVM  \\\n",
       "0   [[48, 11], [16, 76]]  [[45, 14], [10, 82]]  [[44, 15], [10, 82]]   \n",
       "1   [[39, 20], [19, 73]]   [[35, 24], [9, 83]]  [[43, 16], [16, 76]]   \n",
       "2   [[41, 18], [10, 82]]   [[48, 11], [8, 84]]   [[48, 11], [8, 84]]   \n",
       "3   [[40, 19], [14, 78]]   [[45, 14], [6, 86]]  [[46, 13], [10, 82]]   \n",
       "4   [[29, 30], [23, 69]]  [[37, 22], [15, 77]]  [[40, 19], [11, 81]]   \n",
       "5   [[37, 22], [13, 79]]   [[39, 20], [7, 85]]   [[52, 7], [13, 79]]   \n",
       "6   [[39, 20], [19, 73]]   [[35, 24], [9, 83]]  [[43, 16], [16, 76]]   \n",
       "7   [[41, 18], [16, 76]]  [[45, 14], [10, 82]]   [[43, 16], [8, 84]]   \n",
       "8   [[45, 14], [22, 70]]  [[45, 14], [16, 76]]  [[43, 16], [17, 75]]   \n",
       "9   [[42, 17], [17, 75]]  [[46, 13], [10, 82]]  [[49, 10], [11, 81]]   \n",
       "10  [[42, 17], [16, 76]]  [[44, 15], [10, 82]]  [[44, 15], [12, 80]]   \n",
       "11  [[39, 20], [20, 72]]  [[42, 17], [15, 77]]  [[45, 14], [17, 75]]   \n",
       "12  [[41, 18], [16, 76]]  [[46, 13], [18, 74]]   [[51, 8], [16, 76]]   \n",
       "\n",
       "        Gaussian Process         Decision Tree         Random Forest  \\\n",
       "0    [[44, 15], [8, 84]]   [[54, 5], [17, 75]]  [[46, 13], [11, 81]]   \n",
       "1   [[45, 14], [15, 77]]  [[36, 23], [18, 74]]  [[47, 12], [18, 74]]   \n",
       "2     [[50, 9], [8, 84]]   [[54, 5], [27, 65]]   [[47, 12], [7, 85]]   \n",
       "3    [[46, 13], [8, 84]]  [[34, 25], [13, 79]]  [[45, 14], [13, 79]]   \n",
       "4   [[37, 22], [10, 82]]  [[45, 14], [43, 49]]  [[41, 18], [14, 78]]   \n",
       "5     [[59, 0], [92, 0]]  [[32, 27], [18, 74]]  [[49, 10], [14, 78]]   \n",
       "6   [[45, 14], [15, 77]]  [[36, 23], [18, 74]]  [[45, 14], [20, 72]]   \n",
       "7    [[45, 14], [9, 83]]  [[43, 16], [14, 78]]  [[44, 15], [12, 80]]   \n",
       "8   [[43, 16], [19, 73]]  [[33, 26], [15, 77]]  [[40, 19], [22, 70]]   \n",
       "9   [[45, 14], [11, 81]]  [[41, 18], [20, 72]]  [[47, 12], [13, 79]]   \n",
       "10  [[47, 12], [11, 81]]   [[51, 8], [27, 65]]  [[44, 15], [11, 81]]   \n",
       "11  [[43, 16], [18, 74]]  [[43, 16], [24, 68]]  [[44, 15], [22, 70]]   \n",
       "12   [[50, 9], [17, 75]]  [[40, 19], [19, 73]]   [[54, 5], [21, 71]]   \n",
       "\n",
       "            Neural Net              AdaBoost           Naive Bayes  \\\n",
       "0   [[0, 59], [0, 92]]  [[42, 17], [12, 80]]  [[41, 18], [12, 80]]   \n",
       "1   [[0, 59], [0, 92]]  [[36, 23], [17, 75]]  [[33, 26], [11, 81]]   \n",
       "2   [[0, 59], [0, 92]]  [[44, 15], [10, 82]]   [[45, 14], [9, 83]]   \n",
       "3   [[0, 59], [0, 92]]  [[40, 19], [13, 79]]  [[34, 25], [10, 82]]   \n",
       "4   [[0, 59], [0, 92]]  [[35, 24], [15, 77]]  [[35, 24], [14, 78]]   \n",
       "5   [[0, 59], [0, 92]]  [[44, 15], [21, 71]]  [[38, 21], [13, 79]]   \n",
       "6   [[0, 59], [0, 92]]  [[36, 23], [17, 75]]  [[33, 26], [11, 81]]   \n",
       "7   [[0, 59], [0, 92]]  [[48, 11], [13, 79]]  [[41, 18], [13, 79]]   \n",
       "8   [[0, 59], [0, 92]]  [[45, 14], [21, 71]]  [[41, 18], [16, 76]]   \n",
       "9   [[0, 59], [0, 92]]  [[42, 17], [20, 72]]  [[39, 20], [16, 76]]   \n",
       "10  [[0, 59], [0, 92]]  [[46, 13], [13, 79]]  [[41, 18], [12, 80]]   \n",
       "11  [[1, 58], [0, 92]]  [[46, 13], [25, 67]]  [[42, 17], [11, 81]]   \n",
       "12  [[0, 59], [0, 92]]  [[46, 13], [17, 75]]  [[44, 15], [17, 75]]   \n",
       "\n",
       "                     QDA               XGBoost  \n",
       "0    [[53, 6], [18, 74]]  [[45, 14], [13, 79]]  \n",
       "1   [[43, 16], [27, 65]]  [[45, 14], [15, 77]]  \n",
       "2    [[48, 11], [5, 87]]   [[48, 11], [5, 87]]  \n",
       "3    [[34, 25], [7, 85]]   [[46, 13], [8, 84]]  \n",
       "4    [[57, 2], [38, 54]]  [[40, 19], [15, 77]]  \n",
       "5   [[40, 19], [13, 79]]  [[48, 11], [16, 76]]  \n",
       "6   [[43, 16], [22, 70]]  [[45, 14], [15, 77]]  \n",
       "7   [[39, 20], [14, 78]]   [[46, 13], [8, 84]]  \n",
       "8    [[20, 39], [3, 89]]  [[44, 15], [24, 68]]  \n",
       "9   [[38, 21], [13, 79]]  [[45, 14], [13, 79]]  \n",
       "10   [[55, 4], [42, 50]]  [[49, 10], [11, 81]]  \n",
       "11  [[31, 28], [10, 82]]  [[43, 16], [18, 74]]  \n",
       "12   [[55, 4], [24, 68]]   [[52, 7], [22, 70]]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ 16 pontos - 3 raio ------\n",
      "--- Acuracia ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.860927</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.894040</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.867550</td>\n",
       "      <td>0.821192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.754967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.867550</td>\n",
       "      <td>0.880795</td>\n",
       "      <td>0.867550</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.841060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.794702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.860927</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.801325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.662252</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.735099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.754967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.860927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.768212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.867550</td>\n",
       "      <td>0.874172</td>\n",
       "      <td>0.867550</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.841060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.841060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.774834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.668874</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.788079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.781457    0.841060  0.854305          0.860927       0.788079   \n",
       "1            0.735099    0.728477  0.801325          0.794702       0.715232   \n",
       "2            0.821192    0.867550  0.880795          0.867550       0.735099   \n",
       "3            0.721854    0.788079  0.807947          0.807947       0.701987   \n",
       "4            0.768212    0.854305  0.834437          0.860927       0.768212   \n",
       "5            0.721854    0.841060  0.807947          0.834437       0.662252   \n",
       "6            0.735099    0.728477  0.801325          0.794702       0.715232   \n",
       "7            0.814570    0.847682  0.834437          0.854305       0.768212   \n",
       "8            0.728477    0.807947  0.834437          0.788079       0.754967   \n",
       "9            0.827815    0.867550  0.874172          0.867550       0.768212   \n",
       "10           0.814570    0.814570  0.794702          0.814570       0.781457   \n",
       "11           0.788079    0.794702  0.801325          0.807947       0.715232   \n",
       "12           0.741722    0.827815  0.834437          0.847682       0.668874   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.894040    0.609272  0.841060     0.821192  0.867550  0.821192  \n",
       "1        0.754967    0.609272  0.715232     0.741722  0.728477  0.754967  \n",
       "2        0.854305    0.609272  0.774834     0.827815  0.834437  0.841060  \n",
       "3        0.735099    0.609272  0.768212     0.754967  0.781457  0.794702  \n",
       "4        0.814570    0.609272  0.721854     0.781457  0.807947  0.801325  \n",
       "5        0.708609    0.609272  0.735099     0.754967  0.728477  0.735099  \n",
       "6        0.741722    0.609272  0.715232     0.741722  0.695364  0.754967  \n",
       "7        0.814570    0.609272  0.814570     0.794702  0.814570  0.860927  \n",
       "8        0.754967    0.609272  0.701987     0.807947  0.774834  0.768212  \n",
       "9        0.854305    0.609272  0.768212     0.788079  0.801325  0.841060  \n",
       "10       0.807947    0.609272  0.748344     0.794702  0.754967  0.841060  \n",
       "11       0.781457    0.609272  0.754967     0.814570  0.721854  0.774834  \n",
       "12       0.768212    0.609272  0.761589     0.781457  0.768212  0.788079  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- F1 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.776387</td>\n",
       "      <td>0.837798</td>\n",
       "      <td>0.853299</td>\n",
       "      <td>0.859690</td>\n",
       "      <td>0.790614</td>\n",
       "      <td>0.893308</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.839312</td>\n",
       "      <td>0.820911</td>\n",
       "      <td>0.866093</td>\n",
       "      <td>0.818831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.734240</td>\n",
       "      <td>0.708221</td>\n",
       "      <td>0.799953</td>\n",
       "      <td>0.794380</td>\n",
       "      <td>0.715650</td>\n",
       "      <td>0.755327</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.716402</td>\n",
       "      <td>0.734255</td>\n",
       "      <td>0.731228</td>\n",
       "      <td>0.755327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.816023</td>\n",
       "      <td>0.866635</td>\n",
       "      <td>0.880795</td>\n",
       "      <td>0.867550</td>\n",
       "      <td>0.736499</td>\n",
       "      <td>0.854718</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.776024</td>\n",
       "      <td>0.827256</td>\n",
       "      <td>0.832964</td>\n",
       "      <td>0.841899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.717535</td>\n",
       "      <td>0.776843</td>\n",
       "      <td>0.808229</td>\n",
       "      <td>0.807645</td>\n",
       "      <td>0.662966</td>\n",
       "      <td>0.735851</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.767848</td>\n",
       "      <td>0.746360</td>\n",
       "      <td>0.778571</td>\n",
       "      <td>0.794380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.767848</td>\n",
       "      <td>0.854718</td>\n",
       "      <td>0.833606</td>\n",
       "      <td>0.860709</td>\n",
       "      <td>0.762835</td>\n",
       "      <td>0.815549</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.719934</td>\n",
       "      <td>0.779513</td>\n",
       "      <td>0.806983</td>\n",
       "      <td>0.800680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.719934</td>\n",
       "      <td>0.835981</td>\n",
       "      <td>0.809527</td>\n",
       "      <td>0.834680</td>\n",
       "      <td>0.664655</td>\n",
       "      <td>0.707664</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.736499</td>\n",
       "      <td>0.749283</td>\n",
       "      <td>0.731753</td>\n",
       "      <td>0.735851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.734240</td>\n",
       "      <td>0.708221</td>\n",
       "      <td>0.799953</td>\n",
       "      <td>0.794380</td>\n",
       "      <td>0.715650</td>\n",
       "      <td>0.741316</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.716402</td>\n",
       "      <td>0.734255</td>\n",
       "      <td>0.697237</td>\n",
       "      <td>0.755327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.811690</td>\n",
       "      <td>0.842332</td>\n",
       "      <td>0.832964</td>\n",
       "      <td>0.852042</td>\n",
       "      <td>0.771008</td>\n",
       "      <td>0.815096</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.813968</td>\n",
       "      <td>0.794380</td>\n",
       "      <td>0.810764</td>\n",
       "      <td>0.859090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.726061</td>\n",
       "      <td>0.808229</td>\n",
       "      <td>0.834177</td>\n",
       "      <td>0.789199</td>\n",
       "      <td>0.742921</td>\n",
       "      <td>0.754582</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.704883</td>\n",
       "      <td>0.807645</td>\n",
       "      <td>0.770213</td>\n",
       "      <td>0.767848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.828303</td>\n",
       "      <td>0.867120</td>\n",
       "      <td>0.874357</td>\n",
       "      <td>0.867926</td>\n",
       "      <td>0.770119</td>\n",
       "      <td>0.855074</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.769686</td>\n",
       "      <td>0.786616</td>\n",
       "      <td>0.792296</td>\n",
       "      <td>0.841060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.810764</td>\n",
       "      <td>0.809750</td>\n",
       "      <td>0.789940</td>\n",
       "      <td>0.810764</td>\n",
       "      <td>0.782847</td>\n",
       "      <td>0.808229</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.746607</td>\n",
       "      <td>0.794380</td>\n",
       "      <td>0.734293</td>\n",
       "      <td>0.840544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.787392</td>\n",
       "      <td>0.791991</td>\n",
       "      <td>0.803116</td>\n",
       "      <td>0.809168</td>\n",
       "      <td>0.716402</td>\n",
       "      <td>0.783581</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.757811</td>\n",
       "      <td>0.813289</td>\n",
       "      <td>0.696955</td>\n",
       "      <td>0.776487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.741316</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.835117</td>\n",
       "      <td>0.848935</td>\n",
       "      <td>0.660268</td>\n",
       "      <td>0.770119</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.762849</td>\n",
       "      <td>0.782355</td>\n",
       "      <td>0.753030</td>\n",
       "      <td>0.790268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.776387    0.837798  0.853299          0.859690       0.790614   \n",
       "1            0.734240    0.708221  0.799953          0.794380       0.715650   \n",
       "2            0.816023    0.866635  0.880795          0.867550       0.736499   \n",
       "3            0.717535    0.776843  0.808229          0.807645       0.662966   \n",
       "4            0.767848    0.854718  0.833606          0.860709       0.762835   \n",
       "5            0.719934    0.835981  0.809527          0.834680       0.664655   \n",
       "6            0.734240    0.708221  0.799953          0.794380       0.715650   \n",
       "7            0.811690    0.842332  0.832964          0.852042       0.771008   \n",
       "8            0.726061    0.808229  0.834177          0.789199       0.742921   \n",
       "9            0.828303    0.867120  0.874357          0.867926       0.770119   \n",
       "10           0.810764    0.809750  0.789940          0.810764       0.782847   \n",
       "11           0.787392    0.791991  0.803116          0.809168       0.716402   \n",
       "12           0.741316    0.827815  0.835117          0.848935       0.660268   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.893308    0.461341  0.839312     0.820911  0.866093  0.818831  \n",
       "1        0.755327    0.461341  0.716402     0.734255  0.731228  0.755327  \n",
       "2        0.854718    0.461341  0.776024     0.827256  0.832964  0.841899  \n",
       "3        0.735851    0.461341  0.767848     0.746360  0.778571  0.794380  \n",
       "4        0.815549    0.461341  0.719934     0.779513  0.806983  0.800680  \n",
       "5        0.707664    0.461341  0.736499     0.749283  0.731753  0.735851  \n",
       "6        0.741316    0.461341  0.716402     0.734255  0.697237  0.755327  \n",
       "7        0.815096    0.461341  0.813968     0.794380  0.810764  0.859090  \n",
       "8        0.754582    0.461341  0.704883     0.807645  0.770213  0.767848  \n",
       "9        0.855074    0.461341  0.769686     0.786616  0.792296  0.841060  \n",
       "10       0.808229    0.461341  0.746607     0.794380  0.734293  0.840544  \n",
       "11       0.783581    0.461341  0.757811     0.813289  0.696955  0.776487  \n",
       "12       0.770119    0.461341  0.762849     0.782355  0.753030  0.790268  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Precision Score ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.780322</td>\n",
       "      <td>0.842636</td>\n",
       "      <td>0.853557</td>\n",
       "      <td>0.860459</td>\n",
       "      <td>0.815506</td>\n",
       "      <td>0.893909</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.840394</td>\n",
       "      <td>0.820705</td>\n",
       "      <td>0.867573</td>\n",
       "      <td>0.820238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.733643</td>\n",
       "      <td>0.736218</td>\n",
       "      <td>0.799754</td>\n",
       "      <td>0.794129</td>\n",
       "      <td>0.716132</td>\n",
       "      <td>0.755754</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.718137</td>\n",
       "      <td>0.738710</td>\n",
       "      <td>0.768050</td>\n",
       "      <td>0.755754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.824490</td>\n",
       "      <td>0.867008</td>\n",
       "      <td>0.880795</td>\n",
       "      <td>0.867550</td>\n",
       "      <td>0.738931</td>\n",
       "      <td>0.855439</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.778308</td>\n",
       "      <td>0.826999</td>\n",
       "      <td>0.833426</td>\n",
       "      <td>0.843936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.717439</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.808584</td>\n",
       "      <td>0.807417</td>\n",
       "      <td>0.726702</td>\n",
       "      <td>0.736863</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.767553</td>\n",
       "      <td>0.754271</td>\n",
       "      <td>0.779233</td>\n",
       "      <td>0.794129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.767553</td>\n",
       "      <td>0.855439</td>\n",
       "      <td>0.833462</td>\n",
       "      <td>0.860569</td>\n",
       "      <td>0.766267</td>\n",
       "      <td>0.817685</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.719050</td>\n",
       "      <td>0.779358</td>\n",
       "      <td>0.806681</td>\n",
       "      <td>0.800326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.719050</td>\n",
       "      <td>0.847377</td>\n",
       "      <td>0.814591</td>\n",
       "      <td>0.834999</td>\n",
       "      <td>0.710328</td>\n",
       "      <td>0.706970</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.738931</td>\n",
       "      <td>0.752212</td>\n",
       "      <td>0.753423</td>\n",
       "      <td>0.736863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.733643</td>\n",
       "      <td>0.736218</td>\n",
       "      <td>0.799754</td>\n",
       "      <td>0.794129</td>\n",
       "      <td>0.716132</td>\n",
       "      <td>0.740977</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.718137</td>\n",
       "      <td>0.738710</td>\n",
       "      <td>0.748149</td>\n",
       "      <td>0.755754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.813718</td>\n",
       "      <td>0.856291</td>\n",
       "      <td>0.833426</td>\n",
       "      <td>0.854980</td>\n",
       "      <td>0.793217</td>\n",
       "      <td>0.815913</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.813662</td>\n",
       "      <td>0.794129</td>\n",
       "      <td>0.814742</td>\n",
       "      <td>0.861242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.725291</td>\n",
       "      <td>0.808584</td>\n",
       "      <td>0.833993</td>\n",
       "      <td>0.791434</td>\n",
       "      <td>0.758396</td>\n",
       "      <td>0.754265</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.712727</td>\n",
       "      <td>0.807417</td>\n",
       "      <td>0.772900</td>\n",
       "      <td>0.767553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.829088</td>\n",
       "      <td>0.867008</td>\n",
       "      <td>0.874621</td>\n",
       "      <td>0.868614</td>\n",
       "      <td>0.775327</td>\n",
       "      <td>0.857062</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.772851</td>\n",
       "      <td>0.786303</td>\n",
       "      <td>0.809888</td>\n",
       "      <td>0.841060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.814742</td>\n",
       "      <td>0.816325</td>\n",
       "      <td>0.794378</td>\n",
       "      <td>0.814742</td>\n",
       "      <td>0.785959</td>\n",
       "      <td>0.808584</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.745951</td>\n",
       "      <td>0.794129</td>\n",
       "      <td>0.775111</td>\n",
       "      <td>0.840335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.786989</td>\n",
       "      <td>0.792901</td>\n",
       "      <td>0.809411</td>\n",
       "      <td>0.812175</td>\n",
       "      <td>0.718137</td>\n",
       "      <td>0.791246</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.771783</td>\n",
       "      <td>0.813205</td>\n",
       "      <td>0.734067</td>\n",
       "      <td>0.780592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.740977</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.836468</td>\n",
       "      <td>0.853855</td>\n",
       "      <td>0.660436</td>\n",
       "      <td>0.775327</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.765183</td>\n",
       "      <td>0.783876</td>\n",
       "      <td>0.781236</td>\n",
       "      <td>0.799351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.780322    0.842636  0.853557          0.860459       0.815506   \n",
       "1            0.733643    0.736218  0.799754          0.794129       0.716132   \n",
       "2            0.824490    0.867008  0.880795          0.867550       0.738931   \n",
       "3            0.717439    0.798450  0.808584          0.807417       0.726702   \n",
       "4            0.767553    0.855439  0.833462          0.860569       0.766267   \n",
       "5            0.719050    0.847377  0.814591          0.834999       0.710328   \n",
       "6            0.733643    0.736218  0.799754          0.794129       0.716132   \n",
       "7            0.813718    0.856291  0.833426          0.854980       0.793217   \n",
       "8            0.725291    0.808584  0.833993          0.791434       0.758396   \n",
       "9            0.829088    0.867008  0.874621          0.868614       0.775327   \n",
       "10           0.814742    0.816325  0.794378          0.814742       0.785959   \n",
       "11           0.786989    0.792901  0.809411          0.812175       0.718137   \n",
       "12           0.740977    0.827815  0.836468          0.853855       0.660436   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.893909    0.371212  0.840394     0.820705  0.867573  0.820238  \n",
       "1        0.755754    0.371212  0.718137     0.738710  0.768050  0.755754  \n",
       "2        0.855439    0.371212  0.778308     0.826999  0.833426  0.843936  \n",
       "3        0.736863    0.371212  0.767553     0.754271  0.779233  0.794129  \n",
       "4        0.817685    0.371212  0.719050     0.779358  0.806681  0.800326  \n",
       "5        0.706970    0.371212  0.738931     0.752212  0.753423  0.736863  \n",
       "6        0.740977    0.371212  0.718137     0.738710  0.748149  0.755754  \n",
       "7        0.815913    0.371212  0.813662     0.794129  0.814742  0.861242  \n",
       "8        0.754265    0.371212  0.712727     0.807417  0.772900  0.767553  \n",
       "9        0.857062    0.371212  0.772851     0.786303  0.809888  0.841060  \n",
       "10       0.808584    0.371212  0.745951     0.794129  0.775111  0.840335  \n",
       "11       0.791246    0.371212  0.771783     0.813205  0.734067  0.780592  \n",
       "12       0.775327    0.371212  0.765183     0.783876  0.781236  0.799351  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Recall Score ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.860927</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.894040</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.867550</td>\n",
       "      <td>0.821192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.754967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.867550</td>\n",
       "      <td>0.880795</td>\n",
       "      <td>0.867550</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.841060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.794702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.860927</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.801325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.662252</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.735099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.754967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.860927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.768212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.867550</td>\n",
       "      <td>0.874172</td>\n",
       "      <td>0.867550</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.841060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.841060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.774834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.668874</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.788079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.781457    0.841060  0.854305          0.860927       0.788079   \n",
       "1            0.735099    0.728477  0.801325          0.794702       0.715232   \n",
       "2            0.821192    0.867550  0.880795          0.867550       0.735099   \n",
       "3            0.721854    0.788079  0.807947          0.807947       0.701987   \n",
       "4            0.768212    0.854305  0.834437          0.860927       0.768212   \n",
       "5            0.721854    0.841060  0.807947          0.834437       0.662252   \n",
       "6            0.735099    0.728477  0.801325          0.794702       0.715232   \n",
       "7            0.814570    0.847682  0.834437          0.854305       0.768212   \n",
       "8            0.728477    0.807947  0.834437          0.788079       0.754967   \n",
       "9            0.827815    0.867550  0.874172          0.867550       0.768212   \n",
       "10           0.814570    0.814570  0.794702          0.814570       0.781457   \n",
       "11           0.788079    0.794702  0.801325          0.807947       0.715232   \n",
       "12           0.741722    0.827815  0.834437          0.847682       0.668874   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.894040    0.609272  0.841060     0.821192  0.867550  0.821192  \n",
       "1        0.754967    0.609272  0.715232     0.741722  0.728477  0.754967  \n",
       "2        0.854305    0.609272  0.774834     0.827815  0.834437  0.841060  \n",
       "3        0.735099    0.609272  0.768212     0.754967  0.781457  0.794702  \n",
       "4        0.814570    0.609272  0.721854     0.781457  0.807947  0.801325  \n",
       "5        0.708609    0.609272  0.735099     0.754967  0.728477  0.735099  \n",
       "6        0.741722    0.609272  0.715232     0.741722  0.695364  0.754967  \n",
       "7        0.814570    0.609272  0.814570     0.794702  0.814570  0.860927  \n",
       "8        0.754967    0.609272  0.701987     0.807947  0.774834  0.768212  \n",
       "9        0.854305    0.609272  0.768212     0.788079  0.801325  0.841060  \n",
       "10       0.807947    0.609272  0.748344     0.794702  0.754967  0.841060  \n",
       "11       0.781457    0.609272  0.754967     0.814570  0.721854  0.774834  \n",
       "12       0.768212    0.609272  0.761589     0.781457  0.768212  0.788079  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Matriz confusao ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[37, 22], [11, 81]]</td>\n",
       "      <td>[[42, 17], [7, 85]]</td>\n",
       "      <td>[[46, 13], [9, 83]]</td>\n",
       "      <td>[[46, 13], [8, 84]]</td>\n",
       "      <td>[[52, 7], [25, 67]]</td>\n",
       "      <td>[[49, 10], [6, 86]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[44, 15], [9, 83]]</td>\n",
       "      <td>[[45, 14], [13, 79]]</td>\n",
       "      <td>[[46, 13], [7, 85]]</td>\n",
       "      <td>[[42, 17], [10, 82]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[38, 21], [19, 73]]</td>\n",
       "      <td>[[26, 33], [8, 84]]</td>\n",
       "      <td>[[42, 17], [13, 79]]</td>\n",
       "      <td>[[43, 16], [15, 77]]</td>\n",
       "      <td>[[38, 21], [22, 70]]</td>\n",
       "      <td>[[41, 18], [19, 73]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[39, 20], [23, 69]]</td>\n",
       "      <td>[[33, 26], [13, 79]]</td>\n",
       "      <td>[[50, 9], [32, 60]]</td>\n",
       "      <td>[[41, 18], [19, 73]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[39, 20], [7, 85]]</td>\n",
       "      <td>[[47, 12], [8, 84]]</td>\n",
       "      <td>[[50, 9], [9, 83]]</td>\n",
       "      <td>[[49, 10], [10, 82]]</td>\n",
       "      <td>[[41, 18], [22, 70]]</td>\n",
       "      <td>[[49, 10], [12, 80]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[44, 15], [19, 73]]</td>\n",
       "      <td>[[45, 14], [12, 80]]</td>\n",
       "      <td>[[44, 15], [10, 82]]</td>\n",
       "      <td>[[49, 10], [14, 78]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[34, 25], [17, 75]]</td>\n",
       "      <td>[[33, 26], [6, 86]]</td>\n",
       "      <td>[[45, 14], [15, 77]]</td>\n",
       "      <td>[[44, 15], [14, 78]]</td>\n",
       "      <td>[[19, 40], [5, 87]]</td>\n",
       "      <td>[[40, 19], [21, 71]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[41, 18], [17, 75]]</td>\n",
       "      <td>[[33, 26], [11, 81]]</td>\n",
       "      <td>[[39, 20], [13, 79]]</td>\n",
       "      <td>[[43, 16], [15, 77]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[41, 18], [17, 75]]</td>\n",
       "      <td>[[49, 10], [12, 80]]</td>\n",
       "      <td>[[45, 14], [11, 81]]</td>\n",
       "      <td>[[48, 11], [10, 82]]</td>\n",
       "      <td>[[36, 23], [12, 80]]</td>\n",
       "      <td>[[47, 12], [16, 76]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[36, 23], [19, 73]]</td>\n",
       "      <td>[[40, 19], [14, 78]]</td>\n",
       "      <td>[[43, 16], [13, 79]]</td>\n",
       "      <td>[[43, 16], [14, 78]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[[36, 23], [19, 73]]</td>\n",
       "      <td>[[40, 19], [5, 87]]</td>\n",
       "      <td>[[48, 11], [18, 74]]</td>\n",
       "      <td>[[47, 12], [13, 79]]</td>\n",
       "      <td>[[47, 12], [39, 53]]</td>\n",
       "      <td>[[36, 23], [21, 71]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[41, 18], [22, 70]]</td>\n",
       "      <td>[[35, 24], [13, 79]]</td>\n",
       "      <td>[[47, 12], [29, 63]]</td>\n",
       "      <td>[[40, 19], [21, 71]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[[38, 21], [19, 73]]</td>\n",
       "      <td>[[26, 33], [8, 84]]</td>\n",
       "      <td>[[42, 17], [13, 79]]</td>\n",
       "      <td>[[43, 16], [15, 77]]</td>\n",
       "      <td>[[38, 21], [22, 70]]</td>\n",
       "      <td>[[39, 20], [19, 73]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[39, 20], [23, 69]]</td>\n",
       "      <td>[[33, 26], [13, 79]]</td>\n",
       "      <td>[[50, 9], [37, 55]]</td>\n",
       "      <td>[[41, 18], [19, 73]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[[41, 18], [10, 82]]</td>\n",
       "      <td>[[40, 19], [4, 88]]</td>\n",
       "      <td>[[44, 15], [10, 82]]</td>\n",
       "      <td>[[44, 15], [7, 85]]</td>\n",
       "      <td>[[50, 9], [26, 66]]</td>\n",
       "      <td>[[46, 13], [15, 77]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[44, 15], [13, 79]]</td>\n",
       "      <td>[[43, 16], [15, 77]]</td>\n",
       "      <td>[[40, 19], [9, 83]]</td>\n",
       "      <td>[[45, 14], [7, 85]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[[36, 23], [18, 74]]</td>\n",
       "      <td>[[45, 14], [15, 77]]</td>\n",
       "      <td>[[46, 13], [12, 80]]</td>\n",
       "      <td>[[45, 14], [18, 74]]</td>\n",
       "      <td>[[31, 28], [9, 83]]</td>\n",
       "      <td>[[40, 19], [18, 74]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[41, 18], [27, 65]]</td>\n",
       "      <td>[[44, 15], [14, 78]]</td>\n",
       "      <td>[[37, 22], [12, 80]]</td>\n",
       "      <td>[[41, 18], [17, 75]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[[47, 12], [14, 78]]</td>\n",
       "      <td>[[48, 11], [9, 83]]</td>\n",
       "      <td>[[50, 9], [10, 82]]</td>\n",
       "      <td>[[50, 9], [11, 81]]</td>\n",
       "      <td>[[45, 14], [21, 71]]</td>\n",
       "      <td>[[50, 9], [13, 79]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[44, 15], [20, 72]]</td>\n",
       "      <td>[[41, 18], [14, 78]]</td>\n",
       "      <td>[[35, 24], [6, 86]]</td>\n",
       "      <td>[[47, 12], [12, 80]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[[40, 19], [9, 83]]</td>\n",
       "      <td>[[39, 20], [8, 84]]</td>\n",
       "      <td>[[38, 21], [10, 82]]</td>\n",
       "      <td>[[40, 19], [9, 83]]</td>\n",
       "      <td>[[45, 14], [19, 73]]</td>\n",
       "      <td>[[45, 14], [15, 77]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[38, 21], [17, 75]]</td>\n",
       "      <td>[[43, 16], [15, 77]]</td>\n",
       "      <td>[[27, 32], [5, 87]]</td>\n",
       "      <td>[[46, 13], [11, 81]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[[42, 17], [15, 77]]</td>\n",
       "      <td>[[40, 19], [12, 80]]</td>\n",
       "      <td>[[48, 11], [19, 73]]</td>\n",
       "      <td>[[47, 12], [17, 75]]</td>\n",
       "      <td>[[39, 20], [23, 69]]</td>\n",
       "      <td>[[47, 12], [21, 71]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[47, 12], [25, 67]]</td>\n",
       "      <td>[[43, 16], [12, 80]]</td>\n",
       "      <td>[[24, 35], [7, 85]]</td>\n",
       "      <td>[[45, 14], [20, 72]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[[39, 20], [19, 73]]</td>\n",
       "      <td>[[46, 13], [13, 79]]</td>\n",
       "      <td>[[48, 11], [14, 78]]</td>\n",
       "      <td>[[51, 8], [15, 77]]</td>\n",
       "      <td>[[28, 31], [19, 73]]</td>\n",
       "      <td>[[45, 14], [21, 71]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[43, 16], [20, 72]]</td>\n",
       "      <td>[[44, 15], [18, 74]]</td>\n",
       "      <td>[[30, 29], [6, 86]]</td>\n",
       "      <td>[[48, 11], [21, 71]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Nearest Neighbors            Linear SVM               RBF SVM  \\\n",
       "0   [[37, 22], [11, 81]]   [[42, 17], [7, 85]]   [[46, 13], [9, 83]]   \n",
       "1   [[38, 21], [19, 73]]   [[26, 33], [8, 84]]  [[42, 17], [13, 79]]   \n",
       "2    [[39, 20], [7, 85]]   [[47, 12], [8, 84]]    [[50, 9], [9, 83]]   \n",
       "3   [[34, 25], [17, 75]]   [[33, 26], [6, 86]]  [[45, 14], [15, 77]]   \n",
       "4   [[41, 18], [17, 75]]  [[49, 10], [12, 80]]  [[45, 14], [11, 81]]   \n",
       "5   [[36, 23], [19, 73]]   [[40, 19], [5, 87]]  [[48, 11], [18, 74]]   \n",
       "6   [[38, 21], [19, 73]]   [[26, 33], [8, 84]]  [[42, 17], [13, 79]]   \n",
       "7   [[41, 18], [10, 82]]   [[40, 19], [4, 88]]  [[44, 15], [10, 82]]   \n",
       "8   [[36, 23], [18, 74]]  [[45, 14], [15, 77]]  [[46, 13], [12, 80]]   \n",
       "9   [[47, 12], [14, 78]]   [[48, 11], [9, 83]]   [[50, 9], [10, 82]]   \n",
       "10   [[40, 19], [9, 83]]   [[39, 20], [8, 84]]  [[38, 21], [10, 82]]   \n",
       "11  [[42, 17], [15, 77]]  [[40, 19], [12, 80]]  [[48, 11], [19, 73]]   \n",
       "12  [[39, 20], [19, 73]]  [[46, 13], [13, 79]]  [[48, 11], [14, 78]]   \n",
       "\n",
       "        Gaussian Process         Decision Tree         Random Forest  \\\n",
       "0    [[46, 13], [8, 84]]   [[52, 7], [25, 67]]   [[49, 10], [6, 86]]   \n",
       "1   [[43, 16], [15, 77]]  [[38, 21], [22, 70]]  [[41, 18], [19, 73]]   \n",
       "2   [[49, 10], [10, 82]]  [[41, 18], [22, 70]]  [[49, 10], [12, 80]]   \n",
       "3   [[44, 15], [14, 78]]   [[19, 40], [5, 87]]  [[40, 19], [21, 71]]   \n",
       "4   [[48, 11], [10, 82]]  [[36, 23], [12, 80]]  [[47, 12], [16, 76]]   \n",
       "5   [[47, 12], [13, 79]]  [[47, 12], [39, 53]]  [[36, 23], [21, 71]]   \n",
       "6   [[43, 16], [15, 77]]  [[38, 21], [22, 70]]  [[39, 20], [19, 73]]   \n",
       "7    [[44, 15], [7, 85]]   [[50, 9], [26, 66]]  [[46, 13], [15, 77]]   \n",
       "8   [[45, 14], [18, 74]]   [[31, 28], [9, 83]]  [[40, 19], [18, 74]]   \n",
       "9    [[50, 9], [11, 81]]  [[45, 14], [21, 71]]   [[50, 9], [13, 79]]   \n",
       "10   [[40, 19], [9, 83]]  [[45, 14], [19, 73]]  [[45, 14], [15, 77]]   \n",
       "11  [[47, 12], [17, 75]]  [[39, 20], [23, 69]]  [[47, 12], [21, 71]]   \n",
       "12   [[51, 8], [15, 77]]  [[28, 31], [19, 73]]  [[45, 14], [21, 71]]   \n",
       "\n",
       "            Neural Net              AdaBoost           Naive Bayes  \\\n",
       "0   [[0, 59], [0, 92]]   [[44, 15], [9, 83]]  [[45, 14], [13, 79]]   \n",
       "1   [[0, 59], [0, 92]]  [[39, 20], [23, 69]]  [[33, 26], [13, 79]]   \n",
       "2   [[0, 59], [0, 92]]  [[44, 15], [19, 73]]  [[45, 14], [12, 80]]   \n",
       "3   [[0, 59], [0, 92]]  [[41, 18], [17, 75]]  [[33, 26], [11, 81]]   \n",
       "4   [[0, 59], [0, 92]]  [[36, 23], [19, 73]]  [[40, 19], [14, 78]]   \n",
       "5   [[0, 59], [0, 92]]  [[41, 18], [22, 70]]  [[35, 24], [13, 79]]   \n",
       "6   [[0, 59], [0, 92]]  [[39, 20], [23, 69]]  [[33, 26], [13, 79]]   \n",
       "7   [[0, 59], [0, 92]]  [[44, 15], [13, 79]]  [[43, 16], [15, 77]]   \n",
       "8   [[0, 59], [0, 92]]  [[41, 18], [27, 65]]  [[44, 15], [14, 78]]   \n",
       "9   [[0, 59], [0, 92]]  [[44, 15], [20, 72]]  [[41, 18], [14, 78]]   \n",
       "10  [[0, 59], [0, 92]]  [[38, 21], [17, 75]]  [[43, 16], [15, 77]]   \n",
       "11  [[0, 59], [0, 92]]  [[47, 12], [25, 67]]  [[43, 16], [12, 80]]   \n",
       "12  [[0, 59], [0, 92]]  [[43, 16], [20, 72]]  [[44, 15], [18, 74]]   \n",
       "\n",
       "                     QDA               XGBoost  \n",
       "0    [[46, 13], [7, 85]]  [[42, 17], [10, 82]]  \n",
       "1    [[50, 9], [32, 60]]  [[41, 18], [19, 73]]  \n",
       "2   [[44, 15], [10, 82]]  [[49, 10], [14, 78]]  \n",
       "3   [[39, 20], [13, 79]]  [[43, 16], [15, 77]]  \n",
       "4   [[43, 16], [13, 79]]  [[43, 16], [14, 78]]  \n",
       "5   [[47, 12], [29, 63]]  [[40, 19], [21, 71]]  \n",
       "6    [[50, 9], [37, 55]]  [[41, 18], [19, 73]]  \n",
       "7    [[40, 19], [9, 83]]   [[45, 14], [7, 85]]  \n",
       "8   [[37, 22], [12, 80]]  [[41, 18], [17, 75]]  \n",
       "9    [[35, 24], [6, 86]]  [[47, 12], [12, 80]]  \n",
       "10   [[27, 32], [5, 87]]  [[46, 13], [11, 81]]  \n",
       "11   [[24, 35], [7, 85]]  [[45, 14], [20, 72]]  \n",
       "12   [[30, 29], [6, 86]]  [[48, 11], [21, 71]]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ 24 pontos - 3 raio ------\n",
      "--- Acuracia ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.847682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.781457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.867550</td>\n",
       "      <td>0.880795</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.907285</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.900662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.662252</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.768212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.774834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.622517</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.629139</td>\n",
       "      <td>0.801325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.781457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.860927</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.854305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.774834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.860927</td>\n",
       "      <td>0.860927</td>\n",
       "      <td>0.860927</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.821192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.854305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.768212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.841060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.821192    0.827815  0.847682          0.834437       0.788079   \n",
       "1            0.701987    0.708609  0.781457          0.774834       0.708609   \n",
       "2            0.788079    0.854305  0.867550          0.880795       0.807947   \n",
       "3            0.708609    0.794702  0.827815          0.814570       0.662252   \n",
       "4            0.735099    0.788079  0.807947          0.801325       0.735099   \n",
       "5            0.728477    0.827815  0.841060          0.847682       0.622517   \n",
       "6            0.701987    0.708609  0.781457          0.774834       0.708609   \n",
       "7            0.794702    0.821192  0.860927          0.854305       0.728477   \n",
       "8            0.701987    0.788079  0.827815          0.801325       0.761589   \n",
       "9            0.807947    0.860927  0.860927          0.860927       0.754967   \n",
       "10           0.788079    0.827815  0.827815          0.847682       0.735099   \n",
       "11           0.774834    0.774834  0.794702          0.788079       0.794702   \n",
       "12           0.728477    0.827815  0.847682          0.841060       0.807947   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.854305    0.609272  0.768212     0.827815  0.807947  0.847682  \n",
       "1        0.788079    0.609272  0.715232     0.735099  0.708609  0.781457  \n",
       "2        0.907285    0.609272  0.827815     0.841060  0.728477  0.900662  \n",
       "3        0.774834    0.609272  0.721854     0.754967  0.735099  0.768212  \n",
       "4        0.774834    0.609272  0.781457     0.768212  0.788079  0.774834  \n",
       "5        0.774834    0.609272  0.735099     0.748344  0.629139  0.801325  \n",
       "6        0.781457    0.609272  0.715232     0.735099  0.728477  0.781457  \n",
       "7        0.814570    0.609272  0.827815     0.801325  0.754967  0.854305  \n",
       "8        0.794702    0.609272  0.774834     0.801325  0.748344  0.774834  \n",
       "9        0.827815    0.609272  0.841060     0.781457  0.788079  0.821192  \n",
       "10       0.841060    0.609272  0.788079     0.788079  0.788079  0.854305  \n",
       "11       0.761589    0.609272  0.728477     0.807947  0.735099  0.768212  \n",
       "12       0.827815    0.609272  0.834437     0.807947  0.781457  0.841060  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- F1 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.817044</td>\n",
       "      <td>0.819990</td>\n",
       "      <td>0.845670</td>\n",
       "      <td>0.832964</td>\n",
       "      <td>0.784788</td>\n",
       "      <td>0.853832</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.765151</td>\n",
       "      <td>0.826626</td>\n",
       "      <td>0.804496</td>\n",
       "      <td>0.846327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.702425</td>\n",
       "      <td>0.690780</td>\n",
       "      <td>0.778571</td>\n",
       "      <td>0.773280</td>\n",
       "      <td>0.685473</td>\n",
       "      <td>0.788681</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.710115</td>\n",
       "      <td>0.726635</td>\n",
       "      <td>0.709436</td>\n",
       "      <td>0.779513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.779935</td>\n",
       "      <td>0.852042</td>\n",
       "      <td>0.867120</td>\n",
       "      <td>0.879972</td>\n",
       "      <td>0.809168</td>\n",
       "      <td>0.906645</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.828724</td>\n",
       "      <td>0.840544</td>\n",
       "      <td>0.731497</td>\n",
       "      <td>0.900808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.704084</td>\n",
       "      <td>0.782994</td>\n",
       "      <td>0.827256</td>\n",
       "      <td>0.813968</td>\n",
       "      <td>0.666008</td>\n",
       "      <td>0.776024</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.717535</td>\n",
       "      <td>0.746360</td>\n",
       "      <td>0.737835</td>\n",
       "      <td>0.768553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.787392</td>\n",
       "      <td>0.806238</td>\n",
       "      <td>0.798239</td>\n",
       "      <td>0.738267</td>\n",
       "      <td>0.775474</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.780359</td>\n",
       "      <td>0.767048</td>\n",
       "      <td>0.773252</td>\n",
       "      <td>0.772358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.724891</td>\n",
       "      <td>0.821197</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.848651</td>\n",
       "      <td>0.623543</td>\n",
       "      <td>0.773280</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.735851</td>\n",
       "      <td>0.743180</td>\n",
       "      <td>0.632665</td>\n",
       "      <td>0.801325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.702425</td>\n",
       "      <td>0.690780</td>\n",
       "      <td>0.778571</td>\n",
       "      <td>0.773280</td>\n",
       "      <td>0.685473</td>\n",
       "      <td>0.781778</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.710115</td>\n",
       "      <td>0.726635</td>\n",
       "      <td>0.724891</td>\n",
       "      <td>0.779513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.791991</td>\n",
       "      <td>0.813705</td>\n",
       "      <td>0.859090</td>\n",
       "      <td>0.852042</td>\n",
       "      <td>0.731421</td>\n",
       "      <td>0.812530</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.824281</td>\n",
       "      <td>0.800680</td>\n",
       "      <td>0.747883</td>\n",
       "      <td>0.852703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.702425</td>\n",
       "      <td>0.787392</td>\n",
       "      <td>0.828303</td>\n",
       "      <td>0.802783</td>\n",
       "      <td>0.759943</td>\n",
       "      <td>0.796391</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.746607</td>\n",
       "      <td>0.775474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.809168</td>\n",
       "      <td>0.860709</td>\n",
       "      <td>0.861132</td>\n",
       "      <td>0.861132</td>\n",
       "      <td>0.757122</td>\n",
       "      <td>0.827256</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.839962</td>\n",
       "      <td>0.779513</td>\n",
       "      <td>0.779935</td>\n",
       "      <td>0.822329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.784788</td>\n",
       "      <td>0.819990</td>\n",
       "      <td>0.825921</td>\n",
       "      <td>0.844945</td>\n",
       "      <td>0.734240</td>\n",
       "      <td>0.838591</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.786616</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.779935</td>\n",
       "      <td>0.853299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.771338</td>\n",
       "      <td>0.771338</td>\n",
       "      <td>0.796007</td>\n",
       "      <td>0.789199</td>\n",
       "      <td>0.796391</td>\n",
       "      <td>0.764051</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.730203</td>\n",
       "      <td>0.806983</td>\n",
       "      <td>0.728214</td>\n",
       "      <td>0.770996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.727113</td>\n",
       "      <td>0.828724</td>\n",
       "      <td>0.848651</td>\n",
       "      <td>0.842493</td>\n",
       "      <td>0.806238</td>\n",
       "      <td>0.829593</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.835799</td>\n",
       "      <td>0.808736</td>\n",
       "      <td>0.782355</td>\n",
       "      <td>0.842493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.817044    0.819990  0.845670          0.832964       0.784788   \n",
       "1            0.702425    0.690780  0.778571          0.773280       0.685473   \n",
       "2            0.779935    0.852042  0.867120          0.879972       0.809168   \n",
       "3            0.704084    0.782994  0.827256          0.813968       0.666008   \n",
       "4            0.735099    0.787392  0.806238          0.798239       0.738267   \n",
       "5            0.724891    0.821197  0.841060          0.848651       0.623543   \n",
       "6            0.702425    0.690780  0.778571          0.773280       0.685473   \n",
       "7            0.791991    0.813705  0.859090          0.852042       0.731421   \n",
       "8            0.702425    0.787392  0.828303          0.802783       0.759943   \n",
       "9            0.809168    0.860709  0.861132          0.861132       0.757122   \n",
       "10           0.784788    0.819990  0.825921          0.844945       0.734240   \n",
       "11           0.771338    0.771338  0.796007          0.789199       0.796391   \n",
       "12           0.727113    0.828724  0.848651          0.842493       0.806238   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.853832    0.461341  0.765151     0.826626  0.804496  0.846327  \n",
       "1        0.788681    0.461341  0.710115     0.726635  0.709436  0.779513  \n",
       "2        0.906645    0.461341  0.828724     0.840544  0.731497  0.900808  \n",
       "3        0.776024    0.461341  0.717535     0.746360  0.737835  0.768553  \n",
       "4        0.775474    0.461341  0.780359     0.767048  0.773252  0.772358  \n",
       "5        0.773280    0.461341  0.735851     0.743180  0.632665  0.801325  \n",
       "6        0.781778    0.461341  0.710115     0.726635  0.724891  0.779513  \n",
       "7        0.812530    0.461341  0.824281     0.800680  0.747883  0.852703  \n",
       "8        0.796391    0.461341  0.774834     0.801325  0.746607  0.775474  \n",
       "9        0.827256    0.461341  0.839962     0.779513  0.779935  0.822329  \n",
       "10       0.838591    0.461341  0.786616     0.788079  0.779935  0.853299  \n",
       "11       0.764051    0.461341  0.730203     0.806983  0.728214  0.770996  \n",
       "12       0.829593    0.461341  0.835799     0.808736  0.782355  0.842493  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Precision Score ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.822489</td>\n",
       "      <td>0.840026</td>\n",
       "      <td>0.847574</td>\n",
       "      <td>0.833426</td>\n",
       "      <td>0.786210</td>\n",
       "      <td>0.853672</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.765564</td>\n",
       "      <td>0.826656</td>\n",
       "      <td>0.807239</td>\n",
       "      <td>0.846942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.702924</td>\n",
       "      <td>0.707469</td>\n",
       "      <td>0.779233</td>\n",
       "      <td>0.772853</td>\n",
       "      <td>0.712722</td>\n",
       "      <td>0.789563</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.710310</td>\n",
       "      <td>0.731931</td>\n",
       "      <td>0.710513</td>\n",
       "      <td>0.779358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.791913</td>\n",
       "      <td>0.854980</td>\n",
       "      <td>0.867008</td>\n",
       "      <td>0.880459</td>\n",
       "      <td>0.812175</td>\n",
       "      <td>0.907360</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.830810</td>\n",
       "      <td>0.840335</td>\n",
       "      <td>0.762780</td>\n",
       "      <td>0.901036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.703685</td>\n",
       "      <td>0.808402</td>\n",
       "      <td>0.826999</td>\n",
       "      <td>0.813662</td>\n",
       "      <td>0.695453</td>\n",
       "      <td>0.778308</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.717439</td>\n",
       "      <td>0.754271</td>\n",
       "      <td>0.746980</td>\n",
       "      <td>0.768962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.786989</td>\n",
       "      <td>0.806392</td>\n",
       "      <td>0.799964</td>\n",
       "      <td>0.762275</td>\n",
       "      <td>0.776388</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.779900</td>\n",
       "      <td>0.766509</td>\n",
       "      <td>0.808280</td>\n",
       "      <td>0.772448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.724560</td>\n",
       "      <td>0.836097</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.851500</td>\n",
       "      <td>0.679132</td>\n",
       "      <td>0.772853</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.736863</td>\n",
       "      <td>0.745005</td>\n",
       "      <td>0.668339</td>\n",
       "      <td>0.801325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.702924</td>\n",
       "      <td>0.707469</td>\n",
       "      <td>0.779233</td>\n",
       "      <td>0.772853</td>\n",
       "      <td>0.712722</td>\n",
       "      <td>0.782169</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.710310</td>\n",
       "      <td>0.731931</td>\n",
       "      <td>0.724560</td>\n",
       "      <td>0.779358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.792901</td>\n",
       "      <td>0.830512</td>\n",
       "      <td>0.861242</td>\n",
       "      <td>0.854980</td>\n",
       "      <td>0.742044</td>\n",
       "      <td>0.813215</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.828689</td>\n",
       "      <td>0.800326</td>\n",
       "      <td>0.753006</td>\n",
       "      <td>0.853983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.702924</td>\n",
       "      <td>0.786989</td>\n",
       "      <td>0.829088</td>\n",
       "      <td>0.806784</td>\n",
       "      <td>0.759402</td>\n",
       "      <td>0.801503</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.745951</td>\n",
       "      <td>0.776388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.812175</td>\n",
       "      <td>0.860569</td>\n",
       "      <td>0.861414</td>\n",
       "      <td>0.861414</td>\n",
       "      <td>0.801241</td>\n",
       "      <td>0.826999</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.840106</td>\n",
       "      <td>0.779358</td>\n",
       "      <td>0.791913</td>\n",
       "      <td>0.825284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.786210</td>\n",
       "      <td>0.840026</td>\n",
       "      <td>0.826805</td>\n",
       "      <td>0.848780</td>\n",
       "      <td>0.733643</td>\n",
       "      <td>0.841226</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.786303</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.791913</td>\n",
       "      <td>0.853557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.772456</td>\n",
       "      <td>0.772456</td>\n",
       "      <td>0.799067</td>\n",
       "      <td>0.791434</td>\n",
       "      <td>0.801503</td>\n",
       "      <td>0.773165</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.733526</td>\n",
       "      <td>0.806681</td>\n",
       "      <td>0.731295</td>\n",
       "      <td>0.788871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.726337</td>\n",
       "      <td>0.830810</td>\n",
       "      <td>0.851500</td>\n",
       "      <td>0.848666</td>\n",
       "      <td>0.806392</td>\n",
       "      <td>0.838630</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.840767</td>\n",
       "      <td>0.810172</td>\n",
       "      <td>0.783876</td>\n",
       "      <td>0.848666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.822489    0.840026  0.847574          0.833426       0.786210   \n",
       "1            0.702924    0.707469  0.779233          0.772853       0.712722   \n",
       "2            0.791913    0.854980  0.867008          0.880459       0.812175   \n",
       "3            0.703685    0.808402  0.826999          0.813662       0.695453   \n",
       "4            0.735099    0.786989  0.806392          0.799964       0.762275   \n",
       "5            0.724560    0.836097  0.841060          0.851500       0.679132   \n",
       "6            0.702924    0.707469  0.779233          0.772853       0.712722   \n",
       "7            0.792901    0.830512  0.861242          0.854980       0.742044   \n",
       "8            0.702924    0.786989  0.829088          0.806784       0.759402   \n",
       "9            0.812175    0.860569  0.861414          0.861414       0.801241   \n",
       "10           0.786210    0.840026  0.826805          0.848780       0.733643   \n",
       "11           0.772456    0.772456  0.799067          0.791434       0.801503   \n",
       "12           0.726337    0.830810  0.851500          0.848666       0.806392   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.853672    0.371212  0.765564     0.826656  0.807239  0.846942  \n",
       "1        0.789563    0.371212  0.710310     0.731931  0.710513  0.779358  \n",
       "2        0.907360    0.371212  0.830810     0.840335  0.762780  0.901036  \n",
       "3        0.778308    0.371212  0.717439     0.754271  0.746980  0.768962  \n",
       "4        0.776388    0.371212  0.779900     0.766509  0.808280  0.772448  \n",
       "5        0.772853    0.371212  0.736863     0.745005  0.668339  0.801325  \n",
       "6        0.782169    0.371212  0.710310     0.731931  0.724560  0.779358  \n",
       "7        0.813215    0.371212  0.828689     0.800326  0.753006  0.853983  \n",
       "8        0.801503    0.371212  0.774834     0.801325  0.745951  0.776388  \n",
       "9        0.826999    0.371212  0.840106     0.779358  0.791913  0.825284  \n",
       "10       0.841226    0.371212  0.786303     0.788079  0.791913  0.853557  \n",
       "11       0.773165    0.371212  0.733526     0.806681  0.731295  0.788871  \n",
       "12       0.838630    0.371212  0.840767     0.810172  0.783876  0.848666  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Recall Score ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.847682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.781457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.867550</td>\n",
       "      <td>0.880795</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.907285</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.900662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.662252</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.768212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.774834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.622517</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.629139</td>\n",
       "      <td>0.801325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.781457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.860927</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.854305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.774834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.860927</td>\n",
       "      <td>0.860927</td>\n",
       "      <td>0.860927</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.821192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.854305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.768212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.841060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.821192    0.827815  0.847682          0.834437       0.788079   \n",
       "1            0.701987    0.708609  0.781457          0.774834       0.708609   \n",
       "2            0.788079    0.854305  0.867550          0.880795       0.807947   \n",
       "3            0.708609    0.794702  0.827815          0.814570       0.662252   \n",
       "4            0.735099    0.788079  0.807947          0.801325       0.735099   \n",
       "5            0.728477    0.827815  0.841060          0.847682       0.622517   \n",
       "6            0.701987    0.708609  0.781457          0.774834       0.708609   \n",
       "7            0.794702    0.821192  0.860927          0.854305       0.728477   \n",
       "8            0.701987    0.788079  0.827815          0.801325       0.761589   \n",
       "9            0.807947    0.860927  0.860927          0.860927       0.754967   \n",
       "10           0.788079    0.827815  0.827815          0.847682       0.735099   \n",
       "11           0.774834    0.774834  0.794702          0.788079       0.794702   \n",
       "12           0.728477    0.827815  0.847682          0.841060       0.807947   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.854305    0.609272  0.768212     0.827815  0.807947  0.847682  \n",
       "1        0.788079    0.609272  0.715232     0.735099  0.708609  0.781457  \n",
       "2        0.907285    0.609272  0.827815     0.841060  0.728477  0.900662  \n",
       "3        0.774834    0.609272  0.721854     0.754967  0.735099  0.768212  \n",
       "4        0.774834    0.609272  0.781457     0.768212  0.788079  0.774834  \n",
       "5        0.774834    0.609272  0.735099     0.748344  0.629139  0.801325  \n",
       "6        0.781457    0.609272  0.715232     0.735099  0.728477  0.781457  \n",
       "7        0.814570    0.609272  0.827815     0.801325  0.754967  0.854305  \n",
       "8        0.794702    0.609272  0.774834     0.801325  0.748344  0.774834  \n",
       "9        0.827815    0.609272  0.841060     0.781457  0.788079  0.821192  \n",
       "10       0.841060    0.609272  0.788079     0.788079  0.788079  0.854305  \n",
       "11       0.761589    0.609272  0.728477     0.807947  0.735099  0.768212  \n",
       "12       0.827815    0.609272  0.834437     0.807947  0.781457  0.841060  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Matriz confusao ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[40, 19], [8, 84]]</td>\n",
       "      <td>[[37, 22], [4, 88]]</td>\n",
       "      <td>[[44, 15], [8, 84]]</td>\n",
       "      <td>[[44, 15], [10, 82]]</td>\n",
       "      <td>[[39, 20], [12, 80]]</td>\n",
       "      <td>[[47, 12], [10, 82]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[38, 21], [14, 78]]</td>\n",
       "      <td>[[44, 15], [11, 81]]</td>\n",
       "      <td>[[40, 19], [10, 82]]</td>\n",
       "      <td>[[45, 14], [9, 83]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[37, 22], [23, 69]]</td>\n",
       "      <td>[[26, 33], [11, 81]]</td>\n",
       "      <td>[[39, 20], [13, 79]]</td>\n",
       "      <td>[[40, 19], [15, 77]]</td>\n",
       "      <td>[[24, 35], [9, 83]]</td>\n",
       "      <td>[[44, 15], [17, 75]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[33, 26], [17, 75]]</td>\n",
       "      <td>[[32, 27], [13, 79]]</td>\n",
       "      <td>[[38, 21], [23, 69]]</td>\n",
       "      <td>[[40, 19], [14, 78]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[35, 24], [8, 84]]</td>\n",
       "      <td>[[44, 15], [7, 85]]</td>\n",
       "      <td>[[48, 11], [9, 83]]</td>\n",
       "      <td>[[48, 11], [7, 85]]</td>\n",
       "      <td>[[47, 12], [17, 75]]</td>\n",
       "      <td>[[50, 9], [5, 87]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[48, 11], [15, 77]]</td>\n",
       "      <td>[[46, 13], [11, 81]]</td>\n",
       "      <td>[[49, 10], [31, 61]]</td>\n",
       "      <td>[[52, 7], [8, 84]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[33, 26], [18, 74]]</td>\n",
       "      <td>[[33, 26], [5, 87]]</td>\n",
       "      <td>[[45, 14], [12, 80]]</td>\n",
       "      <td>[[44, 15], [13, 79]]</td>\n",
       "      <td>[[44, 15], [36, 56]]</td>\n",
       "      <td>[[44, 15], [19, 73]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[34, 25], [17, 75]]</td>\n",
       "      <td>[[33, 26], [11, 81]]</td>\n",
       "      <td>[[44, 15], [25, 67]]</td>\n",
       "      <td>[[42, 17], [18, 74]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[39, 20], [20, 72]]</td>\n",
       "      <td>[[42, 17], [15, 77]]</td>\n",
       "      <td>[[42, 17], [12, 80]]</td>\n",
       "      <td>[[40, 19], [11, 81]]</td>\n",
       "      <td>[[48, 11], [29, 63]]</td>\n",
       "      <td>[[43, 16], [18, 74]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[41, 18], [15, 77]]</td>\n",
       "      <td>[[40, 19], [16, 76]]</td>\n",
       "      <td>[[31, 28], [4, 88]]</td>\n",
       "      <td>[[39, 20], [14, 78]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[[35, 24], [17, 75]]</td>\n",
       "      <td>[[38, 21], [5, 87]]</td>\n",
       "      <td>[[47, 12], [12, 80]]</td>\n",
       "      <td>[[50, 9], [14, 78]]</td>\n",
       "      <td>[[46, 13], [44, 48]]</td>\n",
       "      <td>[[40, 19], [15, 77]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[40, 19], [21, 71]]</td>\n",
       "      <td>[[35, 24], [14, 78]]</td>\n",
       "      <td>[[43, 16], [40, 52]]</td>\n",
       "      <td>[[44, 15], [15, 77]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[[37, 22], [23, 69]]</td>\n",
       "      <td>[[26, 33], [11, 81]]</td>\n",
       "      <td>[[39, 20], [13, 79]]</td>\n",
       "      <td>[[40, 19], [15, 77]]</td>\n",
       "      <td>[[24, 35], [9, 83]]</td>\n",
       "      <td>[[43, 16], [17, 75]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[33, 26], [17, 75]]</td>\n",
       "      <td>[[32, 27], [13, 79]]</td>\n",
       "      <td>[[35, 24], [17, 75]]</td>\n",
       "      <td>[[40, 19], [14, 78]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[[40, 19], [12, 80]]</td>\n",
       "      <td>[[37, 22], [5, 87]]</td>\n",
       "      <td>[[45, 14], [7, 85]]</td>\n",
       "      <td>[[44, 15], [7, 85]]</td>\n",
       "      <td>[[44, 15], [26, 66]]</td>\n",
       "      <td>[[42, 17], [11, 81]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[41, 18], [8, 84]]</td>\n",
       "      <td>[[43, 16], [14, 78]]</td>\n",
       "      <td>[[34, 25], [12, 80]]</td>\n",
       "      <td>[[45, 14], [8, 84]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[[37, 22], [23, 69]]</td>\n",
       "      <td>[[42, 17], [15, 77]]</td>\n",
       "      <td>[[47, 12], [14, 78]]</td>\n",
       "      <td>[[47, 12], [18, 74]]</td>\n",
       "      <td>[[39, 20], [16, 76]]</td>\n",
       "      <td>[[47, 12], [19, 73]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[42, 17], [17, 75]]</td>\n",
       "      <td>[[44, 15], [15, 77]]</td>\n",
       "      <td>[[38, 21], [17, 75]]</td>\n",
       "      <td>[[43, 16], [18, 74]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[[47, 12], [17, 75]]</td>\n",
       "      <td>[[48, 11], [10, 82]]</td>\n",
       "      <td>[[49, 10], [11, 81]]</td>\n",
       "      <td>[[49, 10], [11, 81]]</td>\n",
       "      <td>[[53, 6], [31, 61]]</td>\n",
       "      <td>[[45, 14], [12, 80]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[45, 14], [10, 82]]</td>\n",
       "      <td>[[40, 19], [14, 78]]</td>\n",
       "      <td>[[35, 24], [8, 84]]</td>\n",
       "      <td>[[48, 11], [16, 76]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[[39, 20], [12, 80]]</td>\n",
       "      <td>[[37, 22], [4, 88]]</td>\n",
       "      <td>[[43, 16], [10, 82]]</td>\n",
       "      <td>[[43, 16], [7, 85]]</td>\n",
       "      <td>[[38, 21], [19, 73]]</td>\n",
       "      <td>[[43, 16], [8, 84]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[41, 18], [14, 78]]</td>\n",
       "      <td>[[43, 16], [16, 76]]</td>\n",
       "      <td>[[35, 24], [8, 84]]</td>\n",
       "      <td>[[46, 13], [9, 83]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[[38, 21], [13, 79]]</td>\n",
       "      <td>[[38, 21], [13, 79]]</td>\n",
       "      <td>[[46, 13], [18, 74]]</td>\n",
       "      <td>[[45, 14], [18, 74]]</td>\n",
       "      <td>[[47, 12], [19, 73]]</td>\n",
       "      <td>[[46, 13], [23, 69]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[41, 18], [23, 69]]</td>\n",
       "      <td>[[43, 16], [13, 79]]</td>\n",
       "      <td>[[33, 26], [14, 78]]</td>\n",
       "      <td>[[49, 10], [25, 67]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[[37, 22], [19, 73]]</td>\n",
       "      <td>[[48, 11], [15, 77]]</td>\n",
       "      <td>[[50, 9], [14, 78]]</td>\n",
       "      <td>[[51, 8], [16, 76]]</td>\n",
       "      <td>[[42, 17], [12, 80]]</td>\n",
       "      <td>[[51, 8], [18, 74]]</td>\n",
       "      <td>[[0, 59], [0, 92]]</td>\n",
       "      <td>[[50, 9], [16, 76]]</td>\n",
       "      <td>[[46, 13], [16, 76]]</td>\n",
       "      <td>[[44, 15], [18, 74]]</td>\n",
       "      <td>[[51, 8], [16, 76]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Nearest Neighbors            Linear SVM               RBF SVM  \\\n",
       "0    [[40, 19], [8, 84]]   [[37, 22], [4, 88]]   [[44, 15], [8, 84]]   \n",
       "1   [[37, 22], [23, 69]]  [[26, 33], [11, 81]]  [[39, 20], [13, 79]]   \n",
       "2    [[35, 24], [8, 84]]   [[44, 15], [7, 85]]   [[48, 11], [9, 83]]   \n",
       "3   [[33, 26], [18, 74]]   [[33, 26], [5, 87]]  [[45, 14], [12, 80]]   \n",
       "4   [[39, 20], [20, 72]]  [[42, 17], [15, 77]]  [[42, 17], [12, 80]]   \n",
       "5   [[35, 24], [17, 75]]   [[38, 21], [5, 87]]  [[47, 12], [12, 80]]   \n",
       "6   [[37, 22], [23, 69]]  [[26, 33], [11, 81]]  [[39, 20], [13, 79]]   \n",
       "7   [[40, 19], [12, 80]]   [[37, 22], [5, 87]]   [[45, 14], [7, 85]]   \n",
       "8   [[37, 22], [23, 69]]  [[42, 17], [15, 77]]  [[47, 12], [14, 78]]   \n",
       "9   [[47, 12], [17, 75]]  [[48, 11], [10, 82]]  [[49, 10], [11, 81]]   \n",
       "10  [[39, 20], [12, 80]]   [[37, 22], [4, 88]]  [[43, 16], [10, 82]]   \n",
       "11  [[38, 21], [13, 79]]  [[38, 21], [13, 79]]  [[46, 13], [18, 74]]   \n",
       "12  [[37, 22], [19, 73]]  [[48, 11], [15, 77]]   [[50, 9], [14, 78]]   \n",
       "\n",
       "        Gaussian Process         Decision Tree         Random Forest  \\\n",
       "0   [[44, 15], [10, 82]]  [[39, 20], [12, 80]]  [[47, 12], [10, 82]]   \n",
       "1   [[40, 19], [15, 77]]   [[24, 35], [9, 83]]  [[44, 15], [17, 75]]   \n",
       "2    [[48, 11], [7, 85]]  [[47, 12], [17, 75]]    [[50, 9], [5, 87]]   \n",
       "3   [[44, 15], [13, 79]]  [[44, 15], [36, 56]]  [[44, 15], [19, 73]]   \n",
       "4   [[40, 19], [11, 81]]  [[48, 11], [29, 63]]  [[43, 16], [18, 74]]   \n",
       "5    [[50, 9], [14, 78]]  [[46, 13], [44, 48]]  [[40, 19], [15, 77]]   \n",
       "6   [[40, 19], [15, 77]]   [[24, 35], [9, 83]]  [[43, 16], [17, 75]]   \n",
       "7    [[44, 15], [7, 85]]  [[44, 15], [26, 66]]  [[42, 17], [11, 81]]   \n",
       "8   [[47, 12], [18, 74]]  [[39, 20], [16, 76]]  [[47, 12], [19, 73]]   \n",
       "9   [[49, 10], [11, 81]]   [[53, 6], [31, 61]]  [[45, 14], [12, 80]]   \n",
       "10   [[43, 16], [7, 85]]  [[38, 21], [19, 73]]   [[43, 16], [8, 84]]   \n",
       "11  [[45, 14], [18, 74]]  [[47, 12], [19, 73]]  [[46, 13], [23, 69]]   \n",
       "12   [[51, 8], [16, 76]]  [[42, 17], [12, 80]]   [[51, 8], [18, 74]]   \n",
       "\n",
       "            Neural Net              AdaBoost           Naive Bayes  \\\n",
       "0   [[0, 59], [0, 92]]  [[38, 21], [14, 78]]  [[44, 15], [11, 81]]   \n",
       "1   [[0, 59], [0, 92]]  [[33, 26], [17, 75]]  [[32, 27], [13, 79]]   \n",
       "2   [[0, 59], [0, 92]]  [[48, 11], [15, 77]]  [[46, 13], [11, 81]]   \n",
       "3   [[0, 59], [0, 92]]  [[34, 25], [17, 75]]  [[33, 26], [11, 81]]   \n",
       "4   [[0, 59], [0, 92]]  [[41, 18], [15, 77]]  [[40, 19], [16, 76]]   \n",
       "5   [[0, 59], [0, 92]]  [[40, 19], [21, 71]]  [[35, 24], [14, 78]]   \n",
       "6   [[0, 59], [0, 92]]  [[33, 26], [17, 75]]  [[32, 27], [13, 79]]   \n",
       "7   [[0, 59], [0, 92]]   [[41, 18], [8, 84]]  [[43, 16], [14, 78]]   \n",
       "8   [[0, 59], [0, 92]]  [[42, 17], [17, 75]]  [[44, 15], [15, 77]]   \n",
       "9   [[0, 59], [0, 92]]  [[45, 14], [10, 82]]  [[40, 19], [14, 78]]   \n",
       "10  [[0, 59], [0, 92]]  [[41, 18], [14, 78]]  [[43, 16], [16, 76]]   \n",
       "11  [[0, 59], [0, 92]]  [[41, 18], [23, 69]]  [[43, 16], [13, 79]]   \n",
       "12  [[0, 59], [0, 92]]   [[50, 9], [16, 76]]  [[46, 13], [16, 76]]   \n",
       "\n",
       "                     QDA               XGBoost  \n",
       "0   [[40, 19], [10, 82]]   [[45, 14], [9, 83]]  \n",
       "1   [[38, 21], [23, 69]]  [[40, 19], [14, 78]]  \n",
       "2   [[49, 10], [31, 61]]    [[52, 7], [8, 84]]  \n",
       "3   [[44, 15], [25, 67]]  [[42, 17], [18, 74]]  \n",
       "4    [[31, 28], [4, 88]]  [[39, 20], [14, 78]]  \n",
       "5   [[43, 16], [40, 52]]  [[44, 15], [15, 77]]  \n",
       "6   [[35, 24], [17, 75]]  [[40, 19], [14, 78]]  \n",
       "7   [[34, 25], [12, 80]]   [[45, 14], [8, 84]]  \n",
       "8   [[38, 21], [17, 75]]  [[43, 16], [18, 74]]  \n",
       "9    [[35, 24], [8, 84]]  [[48, 11], [16, 76]]  \n",
       "10   [[35, 24], [8, 84]]   [[46, 13], [9, 83]]  \n",
       "11  [[33, 26], [14, 78]]  [[49, 10], [25, 67]]  \n",
       "12  [[44, 15], [18, 74]]   [[51, 8], [16, 76]]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ 24 pontos - 8 raio ------\n",
      "--- Acuracia ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.781457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.655629</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.761589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.682119</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.615894</td>\n",
       "      <td>0.794702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.642384</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.622517</td>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.668874</td>\n",
       "      <td>0.748344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.682119</td>\n",
       "      <td>0.735099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.596026</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.768212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.655629</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.761589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.662252</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.629139</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.768212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.860927</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.834437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.860927</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.834437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.682119</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.748344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.860927</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.682119</td>\n",
       "      <td>0.794702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.741722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.708609    0.807947  0.794702          0.821192       0.754967   \n",
       "1            0.675497    0.781457  0.794702          0.827815       0.655629   \n",
       "2            0.682119    0.821192  0.801325          0.827815       0.761589   \n",
       "3            0.642384    0.708609  0.728477          0.622517       0.675497   \n",
       "4            0.735099    0.807947  0.781457          0.834437       0.701987   \n",
       "5            0.708609    0.728477  0.735099          0.774834       0.596026   \n",
       "6            0.675497    0.781457  0.794702          0.827815       0.655629   \n",
       "7            0.662252    0.781457  0.807947          0.814570       0.629139   \n",
       "8            0.754967    0.860927  0.834437          0.834437       0.768212   \n",
       "9            0.854305    0.847682  0.814570          0.860927       0.768212   \n",
       "10           0.675497    0.801325  0.794702          0.807947       0.682119   \n",
       "11           0.774834    0.847682  0.841060          0.860927       0.788079   \n",
       "12           0.735099    0.794702  0.834437          0.841060       0.675497   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.821192    0.609272  0.715232     0.781457  0.748344  0.781457  \n",
       "1        0.728477    0.609272  0.761589     0.728477  0.735099  0.761589  \n",
       "2        0.834437    0.609272  0.781457     0.807947  0.615894  0.794702  \n",
       "3        0.715232    0.609272  0.741722     0.735099  0.668874  0.748344  \n",
       "4        0.774834    0.609272  0.708609     0.735099  0.682119  0.735099  \n",
       "5        0.748344    0.609272  0.708609     0.721854  0.721854  0.768212  \n",
       "6        0.728477    0.609272  0.761589     0.728477  0.728477  0.761589  \n",
       "7        0.781457    0.609272  0.741722     0.768212  0.688742  0.768212  \n",
       "8        0.814570    0.609272  0.761589     0.814570  0.735099  0.834437  \n",
       "9        0.841060    0.609272  0.768212     0.841060  0.768212  0.834437  \n",
       "10       0.768212    0.609272  0.728477     0.754967  0.708609  0.748344  \n",
       "11       0.788079    0.609272  0.794702     0.814570  0.682119  0.794702  \n",
       "12       0.801325    0.609272  0.768212     0.748344  0.721854  0.741722  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- F1 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.706597</td>\n",
       "      <td>0.806983</td>\n",
       "      <td>0.791991</td>\n",
       "      <td>0.819601</td>\n",
       "      <td>0.755974</td>\n",
       "      <td>0.818831</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.714784</td>\n",
       "      <td>0.777530</td>\n",
       "      <td>0.751181</td>\n",
       "      <td>0.780359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.672610</td>\n",
       "      <td>0.776387</td>\n",
       "      <td>0.791991</td>\n",
       "      <td>0.826626</td>\n",
       "      <td>0.608211</td>\n",
       "      <td>0.728876</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.758968</td>\n",
       "      <td>0.723598</td>\n",
       "      <td>0.729663</td>\n",
       "      <td>0.756696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.682119</td>\n",
       "      <td>0.820911</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.826626</td>\n",
       "      <td>0.763339</td>\n",
       "      <td>0.835117</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.781114</td>\n",
       "      <td>0.806238</td>\n",
       "      <td>0.596414</td>\n",
       "      <td>0.795546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.645009</td>\n",
       "      <td>0.672360</td>\n",
       "      <td>0.726061</td>\n",
       "      <td>0.624917</td>\n",
       "      <td>0.679016</td>\n",
       "      <td>0.717043</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.738311</td>\n",
       "      <td>0.730985</td>\n",
       "      <td>0.672294</td>\n",
       "      <td>0.750614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.803492</td>\n",
       "      <td>0.780359</td>\n",
       "      <td>0.832251</td>\n",
       "      <td>0.705218</td>\n",
       "      <td>0.771338</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.706597</td>\n",
       "      <td>0.732186</td>\n",
       "      <td>0.679924</td>\n",
       "      <td>0.732186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.710148</td>\n",
       "      <td>0.724891</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.773280</td>\n",
       "      <td>0.572989</td>\n",
       "      <td>0.749059</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.705405</td>\n",
       "      <td>0.712966</td>\n",
       "      <td>0.709214</td>\n",
       "      <td>0.767848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.672610</td>\n",
       "      <td>0.776387</td>\n",
       "      <td>0.791991</td>\n",
       "      <td>0.826626</td>\n",
       "      <td>0.608211</td>\n",
       "      <td>0.728876</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.758968</td>\n",
       "      <td>0.723598</td>\n",
       "      <td>0.723598</td>\n",
       "      <td>0.756696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.661721</td>\n",
       "      <td>0.779513</td>\n",
       "      <td>0.807645</td>\n",
       "      <td>0.813968</td>\n",
       "      <td>0.633574</td>\n",
       "      <td>0.780359</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.742783</td>\n",
       "      <td>0.765151</td>\n",
       "      <td>0.692354</td>\n",
       "      <td>0.764047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.754582</td>\n",
       "      <td>0.859690</td>\n",
       "      <td>0.834177</td>\n",
       "      <td>0.833606</td>\n",
       "      <td>0.770939</td>\n",
       "      <td>0.813968</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.759943</td>\n",
       "      <td>0.812530</td>\n",
       "      <td>0.737835</td>\n",
       "      <td>0.832964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.853299</td>\n",
       "      <td>0.846917</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.859690</td>\n",
       "      <td>0.766150</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.767048</td>\n",
       "      <td>0.840544</td>\n",
       "      <td>0.770902</td>\n",
       "      <td>0.834177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.674987</td>\n",
       "      <td>0.799953</td>\n",
       "      <td>0.791013</td>\n",
       "      <td>0.806983</td>\n",
       "      <td>0.685960</td>\n",
       "      <td>0.766150</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.726061</td>\n",
       "      <td>0.752787</td>\n",
       "      <td>0.705405</td>\n",
       "      <td>0.747528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.776487</td>\n",
       "      <td>0.847443</td>\n",
       "      <td>0.841899</td>\n",
       "      <td>0.861132</td>\n",
       "      <td>0.778449</td>\n",
       "      <td>0.788681</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.795004</td>\n",
       "      <td>0.815096</td>\n",
       "      <td>0.685921</td>\n",
       "      <td>0.795004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.736499</td>\n",
       "      <td>0.791991</td>\n",
       "      <td>0.832964</td>\n",
       "      <td>0.839312</td>\n",
       "      <td>0.679016</td>\n",
       "      <td>0.799953</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.769686</td>\n",
       "      <td>0.741803</td>\n",
       "      <td>0.704836</td>\n",
       "      <td>0.742783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.706597    0.806983  0.791991          0.819601       0.755974   \n",
       "1            0.672610    0.776387  0.791991          0.826626       0.608211   \n",
       "2            0.682119    0.820911  0.801325          0.826626       0.763339   \n",
       "3            0.645009    0.672360  0.726061          0.624917       0.679016   \n",
       "4            0.735099    0.803492  0.780359          0.832251       0.705218   \n",
       "5            0.710148    0.724891  0.735099          0.773280       0.572989   \n",
       "6            0.672610    0.776387  0.791991          0.826626       0.608211   \n",
       "7            0.661721    0.779513  0.807645          0.813968       0.633574   \n",
       "8            0.754582    0.859690  0.834177          0.833606       0.770939   \n",
       "9            0.853299    0.846917  0.814570          0.859690       0.766150   \n",
       "10           0.674987    0.799953  0.791013          0.806983       0.685960   \n",
       "11           0.776487    0.847443  0.841899          0.861132       0.778449   \n",
       "12           0.736499    0.791991  0.832964          0.839312       0.679016   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.818831    0.461341  0.714784     0.777530  0.751181  0.780359  \n",
       "1        0.728876    0.461341  0.758968     0.723598  0.729663  0.756696  \n",
       "2        0.835117    0.461341  0.781114     0.806238  0.596414  0.795546  \n",
       "3        0.717043    0.461341  0.738311     0.730985  0.672294  0.750614  \n",
       "4        0.771338    0.461341  0.706597     0.732186  0.679924  0.732186  \n",
       "5        0.749059    0.461341  0.705405     0.712966  0.709214  0.767848  \n",
       "6        0.728876    0.461341  0.758968     0.723598  0.723598  0.756696  \n",
       "7        0.780359    0.461341  0.742783     0.765151  0.692354  0.764047  \n",
       "8        0.813968    0.461341  0.759943     0.812530  0.737835  0.832964  \n",
       "9        0.841060    0.461341  0.767048     0.840544  0.770902  0.834177  \n",
       "10       0.766150    0.461341  0.726061     0.752787  0.705405  0.747528  \n",
       "11       0.788681    0.461341  0.795004     0.815096  0.685921  0.795004  \n",
       "12       0.799953    0.461341  0.769686     0.741803  0.704836  0.742783  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Precision Score ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.705599</td>\n",
       "      <td>0.806681</td>\n",
       "      <td>0.792901</td>\n",
       "      <td>0.819909</td>\n",
       "      <td>0.757581</td>\n",
       "      <td>0.820238</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.714401</td>\n",
       "      <td>0.779545</td>\n",
       "      <td>0.763413</td>\n",
       "      <td>0.779900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.671223</td>\n",
       "      <td>0.780322</td>\n",
       "      <td>0.792901</td>\n",
       "      <td>0.826656</td>\n",
       "      <td>0.654657</td>\n",
       "      <td>0.729339</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.758858</td>\n",
       "      <td>0.724157</td>\n",
       "      <td>0.731058</td>\n",
       "      <td>0.758953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.682119</td>\n",
       "      <td>0.820705</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.826656</td>\n",
       "      <td>0.767496</td>\n",
       "      <td>0.836468</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.780841</td>\n",
       "      <td>0.806392</td>\n",
       "      <td>0.774298</td>\n",
       "      <td>0.797024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.649635</td>\n",
       "      <td>0.733270</td>\n",
       "      <td>0.725291</td>\n",
       "      <td>0.628660</td>\n",
       "      <td>0.689629</td>\n",
       "      <td>0.720418</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.738228</td>\n",
       "      <td>0.731193</td>\n",
       "      <td>0.681515</td>\n",
       "      <td>0.757071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.808433</td>\n",
       "      <td>0.779900</td>\n",
       "      <td>0.833906</td>\n",
       "      <td>0.715837</td>\n",
       "      <td>0.772456</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.705599</td>\n",
       "      <td>0.731680</td>\n",
       "      <td>0.678698</td>\n",
       "      <td>0.731680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.712680</td>\n",
       "      <td>0.724560</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.772853</td>\n",
       "      <td>0.573290</td>\n",
       "      <td>0.750038</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.704501</td>\n",
       "      <td>0.717500</td>\n",
       "      <td>0.719475</td>\n",
       "      <td>0.767553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.671223</td>\n",
       "      <td>0.780322</td>\n",
       "      <td>0.792901</td>\n",
       "      <td>0.826656</td>\n",
       "      <td>0.654657</td>\n",
       "      <td>0.729339</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.758858</td>\n",
       "      <td>0.724157</td>\n",
       "      <td>0.724157</td>\n",
       "      <td>0.758953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.661249</td>\n",
       "      <td>0.779358</td>\n",
       "      <td>0.807417</td>\n",
       "      <td>0.813662</td>\n",
       "      <td>0.655813</td>\n",
       "      <td>0.779900</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.744433</td>\n",
       "      <td>0.765564</td>\n",
       "      <td>0.706087</td>\n",
       "      <td>0.765698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.754265</td>\n",
       "      <td>0.860459</td>\n",
       "      <td>0.833993</td>\n",
       "      <td>0.833462</td>\n",
       "      <td>0.797978</td>\n",
       "      <td>0.813662</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.759402</td>\n",
       "      <td>0.813215</td>\n",
       "      <td>0.746980</td>\n",
       "      <td>0.833426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.853557</td>\n",
       "      <td>0.846853</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.860459</td>\n",
       "      <td>0.765841</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.766509</td>\n",
       "      <td>0.840335</td>\n",
       "      <td>0.784922</td>\n",
       "      <td>0.833993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.674537</td>\n",
       "      <td>0.799754</td>\n",
       "      <td>0.793392</td>\n",
       "      <td>0.806681</td>\n",
       "      <td>0.705021</td>\n",
       "      <td>0.765841</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.725291</td>\n",
       "      <td>0.752324</td>\n",
       "      <td>0.704501</td>\n",
       "      <td>0.746980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.780592</td>\n",
       "      <td>0.847281</td>\n",
       "      <td>0.843936</td>\n",
       "      <td>0.861414</td>\n",
       "      <td>0.794819</td>\n",
       "      <td>0.789563</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.795376</td>\n",
       "      <td>0.815913</td>\n",
       "      <td>0.709044</td>\n",
       "      <td>0.795376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.738931</td>\n",
       "      <td>0.792901</td>\n",
       "      <td>0.833426</td>\n",
       "      <td>0.840394</td>\n",
       "      <td>0.689629</td>\n",
       "      <td>0.799754</td>\n",
       "      <td>0.371212</td>\n",
       "      <td>0.772851</td>\n",
       "      <td>0.745467</td>\n",
       "      <td>0.723374</td>\n",
       "      <td>0.744433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.705599    0.806681  0.792901          0.819909       0.757581   \n",
       "1            0.671223    0.780322  0.792901          0.826656       0.654657   \n",
       "2            0.682119    0.820705  0.801325          0.826656       0.767496   \n",
       "3            0.649635    0.733270  0.725291          0.628660       0.689629   \n",
       "4            0.735099    0.808433  0.779900          0.833906       0.715837   \n",
       "5            0.712680    0.724560  0.735099          0.772853       0.573290   \n",
       "6            0.671223    0.780322  0.792901          0.826656       0.654657   \n",
       "7            0.661249    0.779358  0.807417          0.813662       0.655813   \n",
       "8            0.754265    0.860459  0.833993          0.833462       0.797978   \n",
       "9            0.853557    0.846853  0.814570          0.860459       0.765841   \n",
       "10           0.674537    0.799754  0.793392          0.806681       0.705021   \n",
       "11           0.780592    0.847281  0.843936          0.861414       0.794819   \n",
       "12           0.738931    0.792901  0.833426          0.840394       0.689629   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.820238    0.371212  0.714401     0.779545  0.763413  0.779900  \n",
       "1        0.729339    0.371212  0.758858     0.724157  0.731058  0.758953  \n",
       "2        0.836468    0.371212  0.780841     0.806392  0.774298  0.797024  \n",
       "3        0.720418    0.371212  0.738228     0.731193  0.681515  0.757071  \n",
       "4        0.772456    0.371212  0.705599     0.731680  0.678698  0.731680  \n",
       "5        0.750038    0.371212  0.704501     0.717500  0.719475  0.767553  \n",
       "6        0.729339    0.371212  0.758858     0.724157  0.724157  0.758953  \n",
       "7        0.779900    0.371212  0.744433     0.765564  0.706087  0.765698  \n",
       "8        0.813662    0.371212  0.759402     0.813215  0.746980  0.833426  \n",
       "9        0.841060    0.371212  0.766509     0.840335  0.784922  0.833993  \n",
       "10       0.765841    0.371212  0.725291     0.752324  0.704501  0.746980  \n",
       "11       0.789563    0.371212  0.795376     0.815913  0.709044  0.795376  \n",
       "12       0.799754    0.371212  0.772851     0.745467  0.723374  0.744433  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Recall Score ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.781457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.655629</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.761589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.682119</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.615894</td>\n",
       "      <td>0.794702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.642384</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.622517</td>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.668874</td>\n",
       "      <td>0.748344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.682119</td>\n",
       "      <td>0.735099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.596026</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.768212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.655629</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.761589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.662252</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.629139</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.768212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.860927</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.834437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.860927</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.834437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.682119</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.748344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.860927</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.682119</td>\n",
       "      <td>0.794702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.609272</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.741722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.708609    0.807947  0.794702          0.821192       0.754967   \n",
       "1            0.675497    0.781457  0.794702          0.827815       0.655629   \n",
       "2            0.682119    0.821192  0.801325          0.827815       0.761589   \n",
       "3            0.642384    0.708609  0.728477          0.622517       0.675497   \n",
       "4            0.735099    0.807947  0.781457          0.834437       0.701987   \n",
       "5            0.708609    0.728477  0.735099          0.774834       0.596026   \n",
       "6            0.675497    0.781457  0.794702          0.827815       0.655629   \n",
       "7            0.662252    0.781457  0.807947          0.814570       0.629139   \n",
       "8            0.754967    0.860927  0.834437          0.834437       0.768212   \n",
       "9            0.854305    0.847682  0.814570          0.860927       0.768212   \n",
       "10           0.675497    0.801325  0.794702          0.807947       0.682119   \n",
       "11           0.774834    0.847682  0.841060          0.860927       0.788079   \n",
       "12           0.735099    0.794702  0.834437          0.841060       0.675497   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.821192    0.609272  0.715232     0.781457  0.748344  0.781457  \n",
       "1        0.728477    0.609272  0.761589     0.728477  0.735099  0.761589  \n",
       "2        0.834437    0.609272  0.781457     0.807947  0.615894  0.794702  \n",
       "3        0.715232    0.609272  0.741722     0.735099  0.668874  0.748344  \n",
       "4        0.774834    0.609272  0.708609     0.735099  0.682119  0.735099  \n",
       "5        0.748344    0.609272  0.708609     0.721854  0.721854  0.768212  \n",
       "6        0.728477    0.609272  0.761589     0.728477  0.728477  0.761589  \n",
       "7        0.781457    0.609272  0.741722     0.768212  0.688742  0.768212  \n",
       "8        0.814570    0.609272  0.761589     0.814570  0.735099  0.834437  \n",
       "9        0.841060    0.609272  0.768212     0.841060  0.768212  0.834437  \n",
       "10       0.768212    0.609272  0.728477     0.754967  0.708609  0.748344  \n",
       "11       0.788079    0.609272  0.794702     0.814570  0.682119  0.794702  \n",
       "12       0.801325    0.609272  0.768212     0.748344  0.721854  0.741722  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Matriz confusao ---\n"
     ]
    }
   ],
   "source": [
    "obterResultados(4,1)\n",
    "obterResultados(8,1)\n",
    "obterResultados(8,2)\n",
    "obterResultados(12,2)\n",
    "obterResultados(16,2)\n",
    "obterResultados(16,3)\n",
    "obterResultados(24,3)\n",
    "obterResultados(24,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
