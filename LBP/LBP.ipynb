{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from skimage import feature\n",
    "from sklearn.metrics import (f1_score, precision_score, recall_score, \n",
    "accuracy_score, confusion_matrix)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import (RBF, Matern)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criarListaImagens(path, img_size):\n",
    "    lista = []\n",
    "    for img in os.listdir(path):\n",
    "        try:\n",
    "            img_array = cv2.imread(os.path.join(path, img))\n",
    "            new_array = cv2.resize(img_array, (img_size, img_size))\n",
    "            lista.append([new_array, int(img[2:5])%2])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass\n",
    "    return lista\n",
    "\n",
    "#----------------------------------------------------------------------#\n",
    "\n",
    "def criaListaTreinoTeste(lista):\n",
    "  classes = []\n",
    "  imagens = []\n",
    "  for imagem in lista:\n",
    "    imagens.append(imagem[0])\n",
    "    classes.append(imagem[1])\n",
    "  return imagens, classes\n",
    "\n",
    "#----------------------------------------------------------------------#\n",
    "\n",
    "def obtemCanaisCoresRGB(listaOrigem):\n",
    "  listaDestino = []\n",
    "  for imagem in listaOrigem:\n",
    "    aux = cv2.split(imagem)\n",
    "    aux.append(cv2.cvtColor(imagem, cv2.COLOR_BGR2GRAY))\n",
    "    listaDestino.append(aux)\n",
    "\n",
    "  return listaDestino\n",
    "\n",
    "#----------------------------------------------------------------------#\n",
    "\n",
    "def obterCanaisCores(listaOrigem, cvt):\n",
    "  listaDestino = []\n",
    "  for imagem in listaOrigem:    \n",
    "    i = cv2.cvtColor(imagem, cvt)\n",
    "    aux = cv2.split(i)\n",
    "    aux = cv2.split(i)\n",
    "    aux.append(cv2.cvtColor(i, cv2.COLOR_BGR2GRAY))\n",
    "    listaDestino.append(aux)\n",
    "\n",
    "  return listaDestino\n",
    "\n",
    "#----------------------------------------------------------------------#\n",
    "\n",
    "class LocalBinaryPatterns:\n",
    "    def __init__(self, numPoints, radius):\n",
    "        self.numPoints = numPoints\n",
    "        self.radius = radius\n",
    "    def describe(self, image, eps=1e-7):\n",
    "        lbp = feature.local_binary_pattern(image, self.numPoints,\n",
    "            self.radius, method=\"uniform\")\n",
    "        (hist, _) = np.histogram(lbp.ravel(),\n",
    "            bins=np.arange(0, self.numPoints + 3),\n",
    "            range=(0, self.numPoints + 2))\n",
    "        hist = hist.astype(\"float\")\n",
    "        hist /= (hist.sum() + eps)\n",
    "        return hist\n",
    "\n",
    "#----------------------------------------------------------------------#\n",
    "\n",
    "def obtemHistogramaCanais(listaImagens, lbp):\n",
    "  canal_1 = []\n",
    "  canal_2 = []\n",
    "  canal_3 = []\n",
    "  canal_cinza = []\n",
    "  for imagem in listaImagens:\n",
    "    canal_1.append(lbp.describe(imagem[0]))\n",
    "    canal_2.append(lbp.describe(imagem[1]))\n",
    "    canal_3.append(lbp.describe(imagem[2]))\n",
    "    canal_cinza.append(lbp.describe(imagem[3]))\n",
    "  return canal_1, canal_2, canal_3, canal_cinza\n",
    "\n",
    "#----------------------------------------------------------------------#\n",
    "\n",
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\", \"QDA\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
    "        decision_function_shape='ovo', degree=3, gamma='scale', kernel='linear',\n",
    "        max_iter=-1, probability=False, random_state=109, shrinking=True, tol=0.001,\n",
    "        verbose=False),\n",
    "    SVC(C=10000, cache_size=200, class_weight=None, coef0=0.0,\n",
    "        decision_function_shape='ovo', degree=3, gamma=1, kernel='rbf', max_iter=-1,\n",
    "        probability=False, random_state=109, shrinking=True, tol=0.001,verbose=False),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(class_weight=None, criterion='entropy',\n",
    "        max_depth=3, max_features=None, max_leaf_nodes=None,\n",
    "        min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "        min_samples_leaf=50, min_samples_split=2,\n",
    "        min_weight_fraction_leaf=0.0,\n",
    "        random_state=None, splitter='best'),\n",
    "    RandomForestClassifier (bootstrap=False, class_weight=None,\n",
    "        criterion='gini', max_depth=50, max_features='sqrt',\n",
    "        max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "        min_samples_leaf=1, min_samples_split=2,\n",
    "        min_weight_fraction_leaf=0.0, n_estimators=550,\n",
    "        n_jobs=None, oob_score=False, random_state=None,\n",
    "        verbose=0, warm_start=False),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()\n",
    "]\n",
    "\n",
    "#----------------------------------------------------------------------#\n",
    "\n",
    "def xgboost(listaTreino, listaTeste, classesTreino, classesTeste):\n",
    "    m = XGBClassifier(colsample_bytree= 0.6, \n",
    "        gamma= 5, learning_rate= 0.15, max_depth= 5, \n",
    "        min_child_weight= 1, n_estimators= 100, subsample=0.8, eta= 0.3 ).fit(listaTreino, classesTreino)\n",
    "    preds = m.predict(listaTeste)\n",
    "    y_pred = m.predict(listaTeste)     \n",
    "    acc = accuracy_score(classesTeste, y_pred)\n",
    "    f1  = f1_score(classesTeste, y_pred, average='weighted')\n",
    "    cm  = confusion_matrix(classesTeste, y_pred)\n",
    "    ps  = precision_score(classesTeste, y_pred, average='weighted')\n",
    "    rs  = recall_score(classesTeste, y_pred, average='weighted')\n",
    "    return acc, f1, cm, ps, rs\n",
    "\n",
    "#----------------------------------------------------------------------#\n",
    "\n",
    "def utilizarClassificadores(listaTreino, classesTreino, listaTeste, classesTeste, namesClassifiers, classifiers):\n",
    "    listaAccuracy = {}\n",
    "    listaCM = {}\n",
    "    listaF1Score = {}\n",
    "    listaPS = {}\n",
    "    listaRS = {}\n",
    "    for i, c in enumerate(classifiers):\n",
    "        m = c.fit(listaTreino, classesTreino)\n",
    "        y_pred = m.predict(listaTeste)         \n",
    "        listaAccuracy[namesClassifiers[i]] = accuracy_score(classesTeste, y_pred)\n",
    "        listaF1Score[namesClassifiers[i]]  = f1_score(classesTeste, y_pred, average='weighted')\n",
    "        listaCM[namesClassifiers[i]]       = confusion_matrix(classesTeste, y_pred)\n",
    "        listaPS[namesClassifiers[i]]       = precision_score(classesTeste, y_pred, average='weighted')\n",
    "        listaRS[namesClassifiers[i]]       = recall_score(classesTeste, y_pred, average='weighted')\n",
    "    listaAccuracy[\"XGBoost\"], listaF1Score[\"XGBoost\"], listaCM[\"XGBoost\"], listaPS[\"XGBoost\"], listaRS[\"XGBoost\"] = xgboost(np.asarray(listaTreino), np.asarray(listaTeste), np.asarray(classesTreino), np.asarray(classesTeste))\n",
    "    return listaAccuracy , listaF1Score, listaCM, listaPS, listaRS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r\"C:\\Users\\Rosana\\Documents\\Mestrado\\DataSets\\RIM_ONE_v2_\\imagens\"\n",
    "img_size = 200\n",
    "listaImagens = criarListaImagens(data_dir, img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagens, classes = criaListaTreinoTeste(listaImagens)\n",
    "#imagens_treino, imagens_teste, classes_treino, classes_teste = train_test_split(imagens, classes, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177\n",
      "127\n"
     ]
    }
   ],
   "source": [
    "normal = 0\n",
    "glaucoma = 0\n",
    "for i in classes_treino:\n",
    "    if (i == 0):\n",
    "        glaucoma += 1\n",
    "    else:\n",
    "        normal += 1\n",
    "        \n",
    "print(normal)\n",
    "print(glaucoma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "listaRgbTreino = obtemCanaisCoresRGB(imagens_treino)\n",
    "listaHsvTreino = obterCanaisCores(imagens_treino, cv2.COLOR_BGR2HSV)\n",
    "listaLabTreino = obterCanaisCores(imagens_treino, cv2.COLOR_BGR2LAB)\n",
    "listaLuvTreino = obterCanaisCores(imagens_treino, cv2.COLOR_BGR2LUV)\n",
    "\n",
    "listaRgbTeste = obtemCanaisCoresRGB(imagens_teste)\n",
    "listaHsvTeste = obterCanaisCores(imagens_teste, cv2.COLOR_BGR2HSV)\n",
    "listaLabTeste = obterCanaisCores(imagens_teste, cv2.COLOR_BGR2LAB)\n",
    "listaLuvTeste = obterCanaisCores(imagens_teste, cv2.COLOR_BGR2LUV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classificarImagens(pontos, raio):\n",
    "    _lbp = LocalBinaryPatterns(pontos, raio)\n",
    "\n",
    "    lista_treino_rgb_b, lista_treino_rgb_g, lista_treino_rgb_r, lista_treino_rgb_gray = obtemHistogramaCanais(listaRgbTreino, _lbp)\n",
    "    lista_treino_hsv_h, lista_treino_hsv_s, lista_treino_hsv_v, _ = obtemHistogramaCanais(listaHsvTreino, _lbp)\n",
    "    lista_treino_lab_l, lista_treino_lab_a, lista_treino_lab_b, _ = obtemHistogramaCanais(listaLabTreino, _lbp)\n",
    "    lista_treino_luv_l, lista_treino_luv_u, lista_treino_luv_v, _ = obtemHistogramaCanais(listaLuvTreino, _lbp)\n",
    "\n",
    "    lista_teste_rgb_b, lista_teste_rgb_g, lista_teste_rgb_r, lista_teste_rgb_gray = obtemHistogramaCanais(listaRgbTeste, _lbp)\n",
    "    lista_teste_hsv_h, lista_teste_hsv_s, lista_teste_hsv_v, _ = obtemHistogramaCanais(listaHsvTeste, _lbp)\n",
    "    lista_teste_lab_l, lista_teste_lab_a, lista_teste_lab_b, _ = obtemHistogramaCanais(listaLabTeste, _lbp)\n",
    "    lista_teste_luv_l, lista_teste_luv_u, lista_teste_luv_v, _ = obtemHistogramaCanais(listaLuvTeste, _lbp)\n",
    "\n",
    "    linha = []\n",
    "    listaF1Score = []\n",
    "    listaCM = [] \n",
    "    conf_matrix = []\n",
    "    listaPS = []\n",
    "    listaRS = []\n",
    "\n",
    "    #('------------------ RGB ----------------')\n",
    "    l, f1, cm, ps, rs = pd.Series(utilizarClassificadores(lista_treino_rgb_gray, classes_treino, lista_teste_rgb_gray, classes_teste, names, classifiers))\n",
    "    linha.append(l)\n",
    "    listaF1Score.append(f1)\n",
    "    listaCM.append(cm)\n",
    "    listaPS.append(ps)\n",
    "    listaRS.append(rs)\n",
    "    #('------------------ RGB - R ------------')\n",
    "    l, f1, cm, ps, rs = pd.Series(utilizarClassificadores(lista_treino_rgb_r, classes_treino, lista_teste_rgb_r, classes_teste, names, classifiers))\n",
    "    linha.append(l)\n",
    "    listaF1Score.append(f1)\n",
    "    listaCM.append(cm)\n",
    "    listaPS.append(ps)\n",
    "    listaRS.append(rs)\n",
    "    #('------------------ RGB - G ------------')\n",
    "    l, f1, cm, ps, rs = pd.Series(utilizarClassificadores(lista_treino_rgb_g, classes_treino, lista_teste_rgb_g, classes_teste, names, classifiers))\n",
    "    linha.append(l)\n",
    "    listaF1Score.append(f1)\n",
    "    listaCM.append(cm)\n",
    "    listaPS.append(ps)\n",
    "    listaRS.append(rs)\n",
    "    #('------------------ RGB - B ------------')\n",
    "    l, f1, cm, ps, rs = pd.Series(utilizarClassificadores(lista_treino_rgb_b, classes_treino, lista_teste_rgb_b, classes_teste, names, classifiers))\n",
    "    linha.append(l)\n",
    "    listaF1Score.append(f1)\n",
    "    listaCM.append(cm)\n",
    "    listaPS.append(ps)\n",
    "    listaRS.append(rs)\n",
    "\n",
    "    #('------------------ HSV - H ------------')\n",
    "    l, f1, cm, ps, rs = pd.Series(utilizarClassificadores(lista_treino_hsv_h, classes_treino, lista_teste_hsv_h, classes_teste, names, classifiers))\n",
    "    linha.append(l)\n",
    "    listaF1Score.append(f1)\n",
    "    listaCM.append(cm)\n",
    "    listaPS.append(ps)\n",
    "    listaRS.append(rs)\n",
    "    #('------------------ HSV - S ------------')\n",
    "    l, f1, cm, ps, rs = pd.Series(utilizarClassificadores(lista_treino_hsv_s, classes_treino, lista_teste_hsv_s, classes_teste, names, classifiers))\n",
    "    linha.append(l)\n",
    "    listaF1Score.append(f1)\n",
    "    listaCM.append(cm)\n",
    "    listaPS.append(ps)\n",
    "    listaRS.append(rs)\n",
    "    #('------------------ HSV - V ------------')\n",
    "    l, f1, cm, ps, rs = pd.Series(utilizarClassificadores(lista_treino_hsv_v, classes_treino, lista_teste_hsv_v, classes_teste, names, classifiers))\n",
    "    linha.append(l)\n",
    "    listaF1Score.append(f1)\n",
    "    listaCM.append(cm)\n",
    "    listaPS.append(ps)\n",
    "    listaRS.append(rs)\n",
    "\n",
    "\n",
    "    #('------------------ LAB - L ------------')\n",
    "    l, f1, cm, ps, rs = pd.Series(utilizarClassificadores(lista_treino_lab_l, classes_treino, lista_teste_lab_l, classes_teste, names, classifiers))\n",
    "    linha.append(l)\n",
    "    listaF1Score.append(f1)\n",
    "    listaCM.append(cm)\n",
    "    listaPS.append(ps)\n",
    "    listaRS.append(rs)\n",
    "    #('------------------ LAB - A ------------')\n",
    "    l, f1, cm, ps, rs = pd.Series(utilizarClassificadores(lista_treino_lab_a, classes_treino, lista_teste_lab_a, classes_teste, names, classifiers))\n",
    "    linha.append(l)\n",
    "    listaF1Score.append(f1)\n",
    "    listaCM.append(cm)\n",
    "    listaPS.append(ps)\n",
    "    listaRS.append(rs)\n",
    "    #('------------------ LAB - B ------------')\n",
    "    l, f1, cm, ps, rs = pd.Series(utilizarClassificadores(lista_treino_lab_b, classes_treino, lista_teste_lab_b, classes_teste, names, classifiers))\n",
    "    linha.append(l)\n",
    "    listaF1Score.append(f1)\n",
    "    listaCM.append(cm)\n",
    "    listaPS.append(ps)\n",
    "    listaRS.append(rs)\n",
    "    \n",
    "    #('------------------ LUV - L ------------')\n",
    "    l, f1, cm, ps, rs = pd.Series(utilizarClassificadores(lista_treino_luv_l, classes_treino, lista_teste_luv_l, classes_teste, names, classifiers))\n",
    "    linha.append(l)\n",
    "    listaF1Score.append(f1)\n",
    "    listaCM.append(cm)\n",
    "    listaPS.append(ps)\n",
    "    listaRS.append(rs)    \n",
    "    \n",
    "    #('------------------ LUV - U ------------')\n",
    "    l, f1, cm, ps, rs = pd.Series(utilizarClassificadores(lista_treino_luv_u, classes_treino, lista_teste_luv_u, classes_teste, names, classifiers))\n",
    "    linha.append(l)\n",
    "    listaF1Score.append(f1)\n",
    "    listaCM.append(cm)\n",
    "    listaPS.append(ps)\n",
    "    listaRS.append(rs)    \n",
    "    \n",
    "    #('------------------ LUV - V ------------')\n",
    "    l, f1, cm, ps, rs = pd.Series(utilizarClassificadores(lista_treino_luv_v, classes_treino, lista_teste_luv_v, classes_teste, names, classifiers))\n",
    "    linha.append(l)\n",
    "    listaF1Score.append(f1)\n",
    "    listaCM.append(cm)\n",
    "    listaPS.append(ps)\n",
    "    listaRS.append(rs)    \n",
    "    \n",
    "    return linha, listaF1Score, listaCM, listaPS, listaRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obterResultados (pontos, raio):\n",
    "    linhas, listaF1Score, listaCM, listaPS, listaRS = classificarImagens(pontos, raio)\n",
    "    print('------ %s pontos - %s raio ------' % (pontos, raio))\n",
    "    print('--- Acuracia ---')\n",
    "    display(pd.DataFrame(linhas))\n",
    "    print('--- F1 ---')\n",
    "    display(pd.DataFrame(listaF1Score))\n",
    "    print('--- Precision Score ---')\n",
    "    display(pd.DataFrame(listaPS))\n",
    "    print('--- Recall Score ---')\n",
    "    display(pd.DataFrame(listaRS))\n",
    "    print('--- Matriz confusao ---')\n",
    "    display(pd.DataFrame(listaCM))\n",
    "    print('---------------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ 4 pontos - 1 raio ------\n",
      "--- Acuracia ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.807947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.781457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.649007</td>\n",
       "      <td>0.807947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.682119</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.788079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.642384</td>\n",
       "      <td>0.642384</td>\n",
       "      <td>0.635762</td>\n",
       "      <td>0.615894</td>\n",
       "      <td>0.642384</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.562914</td>\n",
       "      <td>0.622517</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.668874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.794702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.781457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.655629</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.788079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.523179</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.615894</td>\n",
       "      <td>0.721854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.622517</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.629139</td>\n",
       "      <td>0.748344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.642384</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.682119</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.768212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.543046</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.741722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.642384</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.668874</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.741722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.728477    0.701987  0.761589          0.807947       0.741722   \n",
       "1            0.768212    0.675497  0.748344          0.774834       0.761589   \n",
       "2            0.768212    0.728477  0.827815          0.814570       0.728477   \n",
       "3            0.748344    0.728477  0.794702          0.794702       0.735099   \n",
       "4            0.675497    0.642384  0.642384          0.635762       0.615894   \n",
       "5            0.741722    0.701987  0.801325          0.741722       0.814570   \n",
       "6            0.768212    0.675497  0.748344          0.774834       0.761589   \n",
       "7            0.754967    0.655629  0.748344          0.788079       0.728477   \n",
       "8            0.761589    0.688742  0.715232          0.715232       0.715232   \n",
       "9            0.622517    0.748344  0.774834          0.768212       0.721854   \n",
       "10           0.735099    0.642384  0.721854          0.761589       0.682119   \n",
       "11           0.695364    0.708609  0.721854          0.741722       0.735099   \n",
       "12           0.688742    0.695364  0.735099          0.761589       0.642384   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.768212    0.516556  0.741722     0.728477  0.708609  0.807947  \n",
       "1        0.774834    0.516556  0.748344     0.695364  0.708609  0.781457  \n",
       "2        0.754967    0.516556  0.781457     0.715232  0.649007  0.807947  \n",
       "3        0.741722    0.516556  0.701987     0.682119  0.715232  0.788079  \n",
       "4        0.642384    0.516556  0.562914     0.622517  0.516556  0.668874  \n",
       "5        0.735099    0.516556  0.754967     0.675497  0.748344  0.794702  \n",
       "6        0.781457    0.516556  0.748344     0.695364  0.721854  0.781457  \n",
       "7        0.768212    0.516556  0.761589     0.708609  0.774834  0.788079  \n",
       "8        0.741722    0.523179  0.695364     0.715232  0.615894  0.721854  \n",
       "9        0.721854    0.516556  0.688742     0.741722  0.629139  0.748344  \n",
       "10       0.741722    0.516556  0.754967     0.708609  0.741722  0.768212  \n",
       "11       0.688742    0.543046  0.728477     0.708609  0.721854  0.741722  \n",
       "12       0.728477    0.516556  0.668874     0.754967  0.748344  0.741722  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- F1 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.722906</td>\n",
       "      <td>0.684489</td>\n",
       "      <td>0.755173</td>\n",
       "      <td>0.805375</td>\n",
       "      <td>0.741449</td>\n",
       "      <td>0.766402</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.740764</td>\n",
       "      <td>0.720535</td>\n",
       "      <td>0.692512</td>\n",
       "      <td>0.806877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.767701</td>\n",
       "      <td>0.648809</td>\n",
       "      <td>0.744563</td>\n",
       "      <td>0.773800</td>\n",
       "      <td>0.759429</td>\n",
       "      <td>0.773338</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.684122</td>\n",
       "      <td>0.697856</td>\n",
       "      <td>0.781399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.765108</td>\n",
       "      <td>0.714386</td>\n",
       "      <td>0.827023</td>\n",
       "      <td>0.812371</td>\n",
       "      <td>0.726963</td>\n",
       "      <td>0.751685</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.780239</td>\n",
       "      <td>0.706902</td>\n",
       "      <td>0.617004</td>\n",
       "      <td>0.807235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.744563</td>\n",
       "      <td>0.720535</td>\n",
       "      <td>0.792565</td>\n",
       "      <td>0.792565</td>\n",
       "      <td>0.732699</td>\n",
       "      <td>0.740764</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.699660</td>\n",
       "      <td>0.668591</td>\n",
       "      <td>0.702260</td>\n",
       "      <td>0.787744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.667489</td>\n",
       "      <td>0.614494</td>\n",
       "      <td>0.604589</td>\n",
       "      <td>0.616859</td>\n",
       "      <td>0.613342</td>\n",
       "      <td>0.641343</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.556346</td>\n",
       "      <td>0.613201</td>\n",
       "      <td>0.432577</td>\n",
       "      <td>0.659963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.737393</td>\n",
       "      <td>0.690163</td>\n",
       "      <td>0.799524</td>\n",
       "      <td>0.738263</td>\n",
       "      <td>0.814602</td>\n",
       "      <td>0.731119</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.751685</td>\n",
       "      <td>0.660715</td>\n",
       "      <td>0.743667</td>\n",
       "      <td>0.793941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.767701</td>\n",
       "      <td>0.648809</td>\n",
       "      <td>0.744563</td>\n",
       "      <td>0.773800</td>\n",
       "      <td>0.759429</td>\n",
       "      <td>0.779751</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.684122</td>\n",
       "      <td>0.711589</td>\n",
       "      <td>0.781399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.750860</td>\n",
       "      <td>0.631562</td>\n",
       "      <td>0.744563</td>\n",
       "      <td>0.784140</td>\n",
       "      <td>0.726963</td>\n",
       "      <td>0.765799</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.761443</td>\n",
       "      <td>0.697856</td>\n",
       "      <td>0.771451</td>\n",
       "      <td>0.787463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.757158</td>\n",
       "      <td>0.670466</td>\n",
       "      <td>0.698511</td>\n",
       "      <td>0.702260</td>\n",
       "      <td>0.714406</td>\n",
       "      <td>0.738263</td>\n",
       "      <td>0.366499</td>\n",
       "      <td>0.691753</td>\n",
       "      <td>0.702260</td>\n",
       "      <td>0.575299</td>\n",
       "      <td>0.716684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.616190</td>\n",
       "      <td>0.743667</td>\n",
       "      <td>0.773800</td>\n",
       "      <td>0.767967</td>\n",
       "      <td>0.721928</td>\n",
       "      <td>0.720576</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.688056</td>\n",
       "      <td>0.737393</td>\n",
       "      <td>0.586068</td>\n",
       "      <td>0.748190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.731119</td>\n",
       "      <td>0.614494</td>\n",
       "      <td>0.715583</td>\n",
       "      <td>0.758763</td>\n",
       "      <td>0.674952</td>\n",
       "      <td>0.740764</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.751685</td>\n",
       "      <td>0.697856</td>\n",
       "      <td>0.734167</td>\n",
       "      <td>0.767353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.691753</td>\n",
       "      <td>0.700767</td>\n",
       "      <td>0.713039</td>\n",
       "      <td>0.739033</td>\n",
       "      <td>0.731119</td>\n",
       "      <td>0.688413</td>\n",
       "      <td>0.408374</td>\n",
       "      <td>0.727470</td>\n",
       "      <td>0.699374</td>\n",
       "      <td>0.720312</td>\n",
       "      <td>0.740764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.683525</td>\n",
       "      <td>0.676382</td>\n",
       "      <td>0.723826</td>\n",
       "      <td>0.758763</td>\n",
       "      <td>0.600851</td>\n",
       "      <td>0.724841</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.665874</td>\n",
       "      <td>0.749939</td>\n",
       "      <td>0.747415</td>\n",
       "      <td>0.738263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.722906    0.684489  0.755173          0.805375       0.741449   \n",
       "1            0.767701    0.648809  0.744563          0.773800       0.759429   \n",
       "2            0.765108    0.714386  0.827023          0.812371       0.726963   \n",
       "3            0.744563    0.720535  0.792565          0.792565       0.732699   \n",
       "4            0.667489    0.614494  0.604589          0.616859       0.613342   \n",
       "5            0.737393    0.690163  0.799524          0.738263       0.814602   \n",
       "6            0.767701    0.648809  0.744563          0.773800       0.759429   \n",
       "7            0.750860    0.631562  0.744563          0.784140       0.726963   \n",
       "8            0.757158    0.670466  0.698511          0.702260       0.714406   \n",
       "9            0.616190    0.743667  0.773800          0.767967       0.721928   \n",
       "10           0.731119    0.614494  0.715583          0.758763       0.674952   \n",
       "11           0.691753    0.700767  0.713039          0.739033       0.731119   \n",
       "12           0.683525    0.676382  0.723826          0.758763       0.600851   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.766402    0.351890  0.740764     0.720535  0.692512  0.806877  \n",
       "1        0.773338    0.351890  0.748344     0.684122  0.697856  0.781399  \n",
       "2        0.751685    0.351890  0.780239     0.706902  0.617004  0.807235  \n",
       "3        0.740764    0.351890  0.699660     0.668591  0.702260  0.787744  \n",
       "4        0.641343    0.351890  0.556346     0.613201  0.432577  0.659963  \n",
       "5        0.731119    0.351890  0.751685     0.660715  0.743667  0.793941  \n",
       "6        0.779751    0.351890  0.748344     0.684122  0.711589  0.781399  \n",
       "7        0.765799    0.351890  0.761443     0.697856  0.771451  0.787463  \n",
       "8        0.738263    0.366499  0.691753     0.702260  0.575299  0.716684  \n",
       "9        0.720576    0.351890  0.688056     0.737393  0.586068  0.748190  \n",
       "10       0.740764    0.351890  0.751685     0.697856  0.734167  0.767353  \n",
       "11       0.688413    0.408374  0.727470     0.699374  0.720312  0.740764  \n",
       "12       0.724841    0.351890  0.665874     0.749939  0.747415  0.738263  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Precision Score ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.741761</td>\n",
       "      <td>0.745991</td>\n",
       "      <td>0.783844</td>\n",
       "      <td>0.819457</td>\n",
       "      <td>0.741764</td>\n",
       "      <td>0.772938</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.743027</td>\n",
       "      <td>0.749319</td>\n",
       "      <td>0.750805</td>\n",
       "      <td>0.811651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.768887</td>\n",
       "      <td>0.734645</td>\n",
       "      <td>0.758331</td>\n",
       "      <td>0.777175</td>\n",
       "      <td>0.767148</td>\n",
       "      <td>0.778776</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.718332</td>\n",
       "      <td>0.733585</td>\n",
       "      <td>0.781410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.777788</td>\n",
       "      <td>0.771841</td>\n",
       "      <td>0.830952</td>\n",
       "      <td>0.824733</td>\n",
       "      <td>0.730703</td>\n",
       "      <td>0.763899</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.784668</td>\n",
       "      <td>0.734535</td>\n",
       "      <td>0.705336</td>\n",
       "      <td>0.810038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.758331</td>\n",
       "      <td>0.749319</td>\n",
       "      <td>0.802602</td>\n",
       "      <td>0.802602</td>\n",
       "      <td>0.739818</td>\n",
       "      <td>0.743027</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.704931</td>\n",
       "      <td>0.707388</td>\n",
       "      <td>0.749294</td>\n",
       "      <td>0.788520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.687221</td>\n",
       "      <td>0.684657</td>\n",
       "      <td>0.709178</td>\n",
       "      <td>0.658094</td>\n",
       "      <td>0.616252</td>\n",
       "      <td>0.642342</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.562657</td>\n",
       "      <td>0.629162</td>\n",
       "      <td>0.575964</td>\n",
       "      <td>0.681330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.752790</td>\n",
       "      <td>0.728308</td>\n",
       "      <td>0.808142</td>\n",
       "      <td>0.750009</td>\n",
       "      <td>0.815778</td>\n",
       "      <td>0.744355</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.763899</td>\n",
       "      <td>0.701849</td>\n",
       "      <td>0.761439</td>\n",
       "      <td>0.796636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.768887</td>\n",
       "      <td>0.734645</td>\n",
       "      <td>0.758331</td>\n",
       "      <td>0.777175</td>\n",
       "      <td>0.767148</td>\n",
       "      <td>0.786540</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.718332</td>\n",
       "      <td>0.748838</td>\n",
       "      <td>0.781410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.766860</td>\n",
       "      <td>0.696099</td>\n",
       "      <td>0.758331</td>\n",
       "      <td>0.803951</td>\n",
       "      <td>0.730703</td>\n",
       "      <td>0.775134</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.761564</td>\n",
       "      <td>0.733585</td>\n",
       "      <td>0.786285</td>\n",
       "      <td>0.789357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.775610</td>\n",
       "      <td>0.729251</td>\n",
       "      <td>0.762730</td>\n",
       "      <td>0.749294</td>\n",
       "      <td>0.721251</td>\n",
       "      <td>0.750009</td>\n",
       "      <td>0.752053</td>\n",
       "      <td>0.700454</td>\n",
       "      <td>0.749294</td>\n",
       "      <td>0.667369</td>\n",
       "      <td>0.733098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.626156</td>\n",
       "      <td>0.761439</td>\n",
       "      <td>0.777175</td>\n",
       "      <td>0.768331</td>\n",
       "      <td>0.722254</td>\n",
       "      <td>0.723399</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.688888</td>\n",
       "      <td>0.752790</td>\n",
       "      <td>0.698019</td>\n",
       "      <td>0.748298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.744355</td>\n",
       "      <td>0.684657</td>\n",
       "      <td>0.736262</td>\n",
       "      <td>0.769498</td>\n",
       "      <td>0.693084</td>\n",
       "      <td>0.743027</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.763899</td>\n",
       "      <td>0.733585</td>\n",
       "      <td>0.764102</td>\n",
       "      <td>0.769832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.700454</td>\n",
       "      <td>0.725264</td>\n",
       "      <td>0.744083</td>\n",
       "      <td>0.747666</td>\n",
       "      <td>0.744355</td>\n",
       "      <td>0.688630</td>\n",
       "      <td>0.757535</td>\n",
       "      <td>0.729625</td>\n",
       "      <td>0.729153</td>\n",
       "      <td>0.731412</td>\n",
       "      <td>0.743027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.696508</td>\n",
       "      <td>0.741140</td>\n",
       "      <td>0.769853</td>\n",
       "      <td>0.769498</td>\n",
       "      <td>0.720090</td>\n",
       "      <td>0.736120</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.671494</td>\n",
       "      <td>0.770317</td>\n",
       "      <td>0.756065</td>\n",
       "      <td>0.750009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.741761    0.745991  0.783844          0.819457       0.741764   \n",
       "1            0.768887    0.734645  0.758331          0.777175       0.767148   \n",
       "2            0.777788    0.771841  0.830952          0.824733       0.730703   \n",
       "3            0.758331    0.749319  0.802602          0.802602       0.739818   \n",
       "4            0.687221    0.684657  0.709178          0.658094       0.616252   \n",
       "5            0.752790    0.728308  0.808142          0.750009       0.815778   \n",
       "6            0.768887    0.734645  0.758331          0.777175       0.767148   \n",
       "7            0.766860    0.696099  0.758331          0.803951       0.730703   \n",
       "8            0.775610    0.729251  0.762730          0.749294       0.721251   \n",
       "9            0.626156    0.761439  0.777175          0.768331       0.722254   \n",
       "10           0.744355    0.684657  0.736262          0.769498       0.693084   \n",
       "11           0.700454    0.725264  0.744083          0.747666       0.744355   \n",
       "12           0.696508    0.741140  0.769853          0.769498       0.720090   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.772938    0.266830  0.743027     0.749319  0.750805  0.811651  \n",
       "1        0.778776    0.266830  0.748344     0.718332  0.733585  0.781410  \n",
       "2        0.763899    0.266830  0.784668     0.734535  0.705336  0.810038  \n",
       "3        0.743027    0.266830  0.704931     0.707388  0.749294  0.788520  \n",
       "4        0.642342    0.266830  0.562657     0.629162  0.575964  0.681330  \n",
       "5        0.744355    0.266830  0.763899     0.701849  0.761439  0.796636  \n",
       "6        0.786540    0.266830  0.748344     0.718332  0.748838  0.781410  \n",
       "7        0.775134    0.266830  0.761564     0.733585  0.786285  0.789357  \n",
       "8        0.750009    0.752053  0.700454     0.749294  0.667369  0.733098  \n",
       "9        0.723399    0.266830  0.688888     0.752790  0.698019  0.748298  \n",
       "10       0.743027    0.266830  0.763899     0.733585  0.764102  0.769832  \n",
       "11       0.688630    0.757535  0.729625     0.729153  0.731412  0.743027  \n",
       "12       0.736120    0.266830  0.671494     0.770317  0.756065  0.750009  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Recall Score ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.807947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.781457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.649007</td>\n",
       "      <td>0.807947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.682119</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.788079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.642384</td>\n",
       "      <td>0.642384</td>\n",
       "      <td>0.635762</td>\n",
       "      <td>0.615894</td>\n",
       "      <td>0.642384</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.562914</td>\n",
       "      <td>0.622517</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.668874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.794702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.781457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.655629</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.788079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.523179</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.615894</td>\n",
       "      <td>0.721854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.622517</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.629139</td>\n",
       "      <td>0.748344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.642384</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.682119</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.768212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.543046</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.741722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.642384</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.668874</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.741722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.728477    0.701987  0.761589          0.807947       0.741722   \n",
       "1            0.768212    0.675497  0.748344          0.774834       0.761589   \n",
       "2            0.768212    0.728477  0.827815          0.814570       0.728477   \n",
       "3            0.748344    0.728477  0.794702          0.794702       0.735099   \n",
       "4            0.675497    0.642384  0.642384          0.635762       0.615894   \n",
       "5            0.741722    0.701987  0.801325          0.741722       0.814570   \n",
       "6            0.768212    0.675497  0.748344          0.774834       0.761589   \n",
       "7            0.754967    0.655629  0.748344          0.788079       0.728477   \n",
       "8            0.761589    0.688742  0.715232          0.715232       0.715232   \n",
       "9            0.622517    0.748344  0.774834          0.768212       0.721854   \n",
       "10           0.735099    0.642384  0.721854          0.761589       0.682119   \n",
       "11           0.695364    0.708609  0.721854          0.741722       0.735099   \n",
       "12           0.688742    0.695364  0.735099          0.761589       0.642384   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.768212    0.516556  0.741722     0.728477  0.708609  0.807947  \n",
       "1        0.774834    0.516556  0.748344     0.695364  0.708609  0.781457  \n",
       "2        0.754967    0.516556  0.781457     0.715232  0.649007  0.807947  \n",
       "3        0.741722    0.516556  0.701987     0.682119  0.715232  0.788079  \n",
       "4        0.642384    0.516556  0.562914     0.622517  0.516556  0.668874  \n",
       "5        0.735099    0.516556  0.754967     0.675497  0.748344  0.794702  \n",
       "6        0.781457    0.516556  0.748344     0.695364  0.721854  0.781457  \n",
       "7        0.768212    0.516556  0.761589     0.708609  0.774834  0.788079  \n",
       "8        0.741722    0.523179  0.695364     0.715232  0.615894  0.721854  \n",
       "9        0.721854    0.516556  0.688742     0.741722  0.629139  0.748344  \n",
       "10       0.741722    0.516556  0.754967     0.708609  0.741722  0.768212  \n",
       "11       0.688742    0.543046  0.728477     0.708609  0.721854  0.741722  \n",
       "12       0.728477    0.516556  0.668874     0.754967  0.748344  0.741722  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Matriz confusao ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[43, 30], [11, 67]]</td>\n",
       "      <td>[[34, 39], [6, 72]]</td>\n",
       "      <td>[[44, 29], [7, 71]]</td>\n",
       "      <td>[[51, 22], [7, 71]]</td>\n",
       "      <td>[[52, 21], [18, 60]]</td>\n",
       "      <td>[[50, 23], [12, 66]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[50, 23], [16, 62]]</td>\n",
       "      <td>[[41, 32], [9, 69]]</td>\n",
       "      <td>[[35, 38], [6, 72]]</td>\n",
       "      <td>[[54, 19], [10, 68]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[53, 20], [15, 63]]</td>\n",
       "      <td>[[29, 44], [5, 73]]</td>\n",
       "      <td>[[46, 27], [11, 67]]</td>\n",
       "      <td>[[52, 21], [13, 65]]</td>\n",
       "      <td>[[49, 24], [12, 66]]</td>\n",
       "      <td>[[51, 22], [12, 66]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[54, 19], [19, 59]]</td>\n",
       "      <td>[[37, 36], [10, 68]]</td>\n",
       "      <td>[[38, 35], [9, 69]]</td>\n",
       "      <td>[[56, 17], [16, 62]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[48, 25], [10, 68]]</td>\n",
       "      <td>[[37, 36], [5, 73]]</td>\n",
       "      <td>[[56, 17], [9, 69]]</td>\n",
       "      <td>[[52, 21], [7, 71]]</td>\n",
       "      <td>[[48, 25], [16, 62]]</td>\n",
       "      <td>[[47, 26], [11, 67]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[52, 21], [12, 66]]</td>\n",
       "      <td>[[40, 33], [10, 68]]</td>\n",
       "      <td>[[26, 47], [6, 72]]</td>\n",
       "      <td>[[55, 18], [11, 67]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[46, 27], [11, 67]]</td>\n",
       "      <td>[[41, 32], [9, 69]]</td>\n",
       "      <td>[[51, 22], [9, 69]]</td>\n",
       "      <td>[[51, 22], [9, 69]]</td>\n",
       "      <td>[[47, 26], [14, 64]]</td>\n",
       "      <td>[[50, 23], [16, 62]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[45, 28], [17, 61]]</td>\n",
       "      <td>[[35, 38], [10, 68]]</td>\n",
       "      <td>[[37, 36], [7, 71]]</td>\n",
       "      <td>[[55, 18], [14, 64]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[38, 35], [14, 64]]</td>\n",
       "      <td>[[27, 46], [8, 70]]</td>\n",
       "      <td>[[24, 49], [5, 73]]</td>\n",
       "      <td>[[30, 43], [12, 66]]</td>\n",
       "      <td>[[39, 34], [24, 54]]</td>\n",
       "      <td>[[43, 30], [24, 54]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[32, 41], [25, 53]]</td>\n",
       "      <td>[[34, 39], [18, 60]]</td>\n",
       "      <td>[[67, 6], [67, 11]]</td>\n",
       "      <td>[[37, 36], [14, 64]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[[45, 28], [11, 67]]</td>\n",
       "      <td>[[37, 36], [9, 69]]</td>\n",
       "      <td>[[52, 21], [9, 69]]</td>\n",
       "      <td>[[46, 27], [12, 66]]</td>\n",
       "      <td>[[61, 12], [16, 62]]</td>\n",
       "      <td>[[45, 28], [12, 66]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[47, 26], [11, 67]]</td>\n",
       "      <td>[[34, 39], [10, 68]]</td>\n",
       "      <td>[[45, 28], [10, 68]]</td>\n",
       "      <td>[[54, 19], [12, 66]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[[53, 20], [15, 63]]</td>\n",
       "      <td>[[29, 44], [5, 73]]</td>\n",
       "      <td>[[46, 27], [11, 67]]</td>\n",
       "      <td>[[52, 21], [13, 65]]</td>\n",
       "      <td>[[49, 24], [12, 66]]</td>\n",
       "      <td>[[51, 22], [11, 67]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[54, 19], [19, 59]]</td>\n",
       "      <td>[[37, 36], [10, 68]]</td>\n",
       "      <td>[[39, 34], [8, 70]]</td>\n",
       "      <td>[[56, 17], [16, 62]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[[46, 27], [10, 68]]</td>\n",
       "      <td>[[29, 44], [8, 70]]</td>\n",
       "      <td>[[46, 27], [11, 67]]</td>\n",
       "      <td>[[48, 25], [7, 71]]</td>\n",
       "      <td>[[48, 25], [16, 62]]</td>\n",
       "      <td>[[49, 24], [11, 67]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[54, 19], [17, 61]]</td>\n",
       "      <td>[[38, 35], [9, 69]]</td>\n",
       "      <td>[[48, 25], [9, 69]]</td>\n",
       "      <td>[[54, 19], [13, 65]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[[46, 27], [9, 69]]</td>\n",
       "      <td>[[33, 40], [7, 71]]</td>\n",
       "      <td>[[35, 38], [5, 73]]</td>\n",
       "      <td>[[37, 36], [7, 71]]</td>\n",
       "      <td>[[57, 16], [27, 51]]</td>\n",
       "      <td>[[46, 27], [12, 66]]</td>\n",
       "      <td>[[1, 72], [0, 78]]</td>\n",
       "      <td>[[43, 30], [16, 62]]</td>\n",
       "      <td>[[37, 36], [7, 71]]</td>\n",
       "      <td>[[22, 51], [7, 71]]</td>\n",
       "      <td>[[43, 30], [12, 66]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[[36, 37], [20, 58]]</td>\n",
       "      <td>[[45, 28], [10, 68]]</td>\n",
       "      <td>[[52, 21], [13, 65]]</td>\n",
       "      <td>[[54, 19], [16, 62]]</td>\n",
       "      <td>[[53, 20], [22, 56]]</td>\n",
       "      <td>[[48, 25], [17, 61]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[47, 26], [21, 57]]</td>\n",
       "      <td>[[45, 28], [11, 67]]</td>\n",
       "      <td>[[22, 51], [5, 73]]</td>\n",
       "      <td>[[53, 20], [18, 60]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[[45, 28], [12, 66]]</td>\n",
       "      <td>[[27, 46], [8, 70]]</td>\n",
       "      <td>[[42, 31], [11, 67]]</td>\n",
       "      <td>[[48, 25], [11, 67]]</td>\n",
       "      <td>[[39, 34], [14, 64]]</td>\n",
       "      <td>[[50, 23], [16, 62]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[47, 26], [11, 67]]</td>\n",
       "      <td>[[38, 35], [9, 69]]</td>\n",
       "      <td>[[42, 31], [8, 70]]</td>\n",
       "      <td>[[52, 21], [14, 64]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[[43, 30], [16, 62]]</td>\n",
       "      <td>[[40, 33], [11, 67]]</td>\n",
       "      <td>[[40, 33], [9, 69]]</td>\n",
       "      <td>[[47, 26], [13, 65]]</td>\n",
       "      <td>[[45, 28], [12, 66]]</td>\n",
       "      <td>[[48, 25], [22, 56]]</td>\n",
       "      <td>[[4, 69], [0, 78]]</td>\n",
       "      <td>[[49, 24], [17, 61]]</td>\n",
       "      <td>[[39, 34], [10, 68]]</td>\n",
       "      <td>[[59, 14], [28, 50]]</td>\n",
       "      <td>[[50, 23], [16, 62]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[[41, 32], [15, 63]]</td>\n",
       "      <td>[[33, 40], [6, 72]]</td>\n",
       "      <td>[[39, 34], [6, 72]]</td>\n",
       "      <td>[[48, 25], [11, 67]]</td>\n",
       "      <td>[[23, 50], [4, 74]]</td>\n",
       "      <td>[[45, 28], [13, 65]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[42, 31], [19, 59]]</td>\n",
       "      <td>[[45, 28], [9, 69]]</td>\n",
       "      <td>[[60, 13], [25, 53]]</td>\n",
       "      <td>[[46, 27], [12, 66]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Nearest Neighbors            Linear SVM               RBF SVM  \\\n",
       "0   [[43, 30], [11, 67]]   [[34, 39], [6, 72]]   [[44, 29], [7, 71]]   \n",
       "1   [[53, 20], [15, 63]]   [[29, 44], [5, 73]]  [[46, 27], [11, 67]]   \n",
       "2   [[48, 25], [10, 68]]   [[37, 36], [5, 73]]   [[56, 17], [9, 69]]   \n",
       "3   [[46, 27], [11, 67]]   [[41, 32], [9, 69]]   [[51, 22], [9, 69]]   \n",
       "4   [[38, 35], [14, 64]]   [[27, 46], [8, 70]]   [[24, 49], [5, 73]]   \n",
       "5   [[45, 28], [11, 67]]   [[37, 36], [9, 69]]   [[52, 21], [9, 69]]   \n",
       "6   [[53, 20], [15, 63]]   [[29, 44], [5, 73]]  [[46, 27], [11, 67]]   \n",
       "7   [[46, 27], [10, 68]]   [[29, 44], [8, 70]]  [[46, 27], [11, 67]]   \n",
       "8    [[46, 27], [9, 69]]   [[33, 40], [7, 71]]   [[35, 38], [5, 73]]   \n",
       "9   [[36, 37], [20, 58]]  [[45, 28], [10, 68]]  [[52, 21], [13, 65]]   \n",
       "10  [[45, 28], [12, 66]]   [[27, 46], [8, 70]]  [[42, 31], [11, 67]]   \n",
       "11  [[43, 30], [16, 62]]  [[40, 33], [11, 67]]   [[40, 33], [9, 69]]   \n",
       "12  [[41, 32], [15, 63]]   [[33, 40], [6, 72]]   [[39, 34], [6, 72]]   \n",
       "\n",
       "        Gaussian Process         Decision Tree         Random Forest  \\\n",
       "0    [[51, 22], [7, 71]]  [[52, 21], [18, 60]]  [[50, 23], [12, 66]]   \n",
       "1   [[52, 21], [13, 65]]  [[49, 24], [12, 66]]  [[51, 22], [12, 66]]   \n",
       "2    [[52, 21], [7, 71]]  [[48, 25], [16, 62]]  [[47, 26], [11, 67]]   \n",
       "3    [[51, 22], [9, 69]]  [[47, 26], [14, 64]]  [[50, 23], [16, 62]]   \n",
       "4   [[30, 43], [12, 66]]  [[39, 34], [24, 54]]  [[43, 30], [24, 54]]   \n",
       "5   [[46, 27], [12, 66]]  [[61, 12], [16, 62]]  [[45, 28], [12, 66]]   \n",
       "6   [[52, 21], [13, 65]]  [[49, 24], [12, 66]]  [[51, 22], [11, 67]]   \n",
       "7    [[48, 25], [7, 71]]  [[48, 25], [16, 62]]  [[49, 24], [11, 67]]   \n",
       "8    [[37, 36], [7, 71]]  [[57, 16], [27, 51]]  [[46, 27], [12, 66]]   \n",
       "9   [[54, 19], [16, 62]]  [[53, 20], [22, 56]]  [[48, 25], [17, 61]]   \n",
       "10  [[48, 25], [11, 67]]  [[39, 34], [14, 64]]  [[50, 23], [16, 62]]   \n",
       "11  [[47, 26], [13, 65]]  [[45, 28], [12, 66]]  [[48, 25], [22, 56]]   \n",
       "12  [[48, 25], [11, 67]]   [[23, 50], [4, 74]]  [[45, 28], [13, 65]]   \n",
       "\n",
       "            Neural Net              AdaBoost           Naive Bayes  \\\n",
       "0   [[0, 73], [0, 78]]  [[50, 23], [16, 62]]   [[41, 32], [9, 69]]   \n",
       "1   [[0, 73], [0, 78]]  [[54, 19], [19, 59]]  [[37, 36], [10, 68]]   \n",
       "2   [[0, 73], [0, 78]]  [[52, 21], [12, 66]]  [[40, 33], [10, 68]]   \n",
       "3   [[0, 73], [0, 78]]  [[45, 28], [17, 61]]  [[35, 38], [10, 68]]   \n",
       "4   [[0, 73], [0, 78]]  [[32, 41], [25, 53]]  [[34, 39], [18, 60]]   \n",
       "5   [[0, 73], [0, 78]]  [[47, 26], [11, 67]]  [[34, 39], [10, 68]]   \n",
       "6   [[0, 73], [0, 78]]  [[54, 19], [19, 59]]  [[37, 36], [10, 68]]   \n",
       "7   [[0, 73], [0, 78]]  [[54, 19], [17, 61]]   [[38, 35], [9, 69]]   \n",
       "8   [[1, 72], [0, 78]]  [[43, 30], [16, 62]]   [[37, 36], [7, 71]]   \n",
       "9   [[0, 73], [0, 78]]  [[47, 26], [21, 57]]  [[45, 28], [11, 67]]   \n",
       "10  [[0, 73], [0, 78]]  [[47, 26], [11, 67]]   [[38, 35], [9, 69]]   \n",
       "11  [[4, 69], [0, 78]]  [[49, 24], [17, 61]]  [[39, 34], [10, 68]]   \n",
       "12  [[0, 73], [0, 78]]  [[42, 31], [19, 59]]   [[45, 28], [9, 69]]   \n",
       "\n",
       "                     QDA               XGBoost  \n",
       "0    [[35, 38], [6, 72]]  [[54, 19], [10, 68]]  \n",
       "1    [[38, 35], [9, 69]]  [[56, 17], [16, 62]]  \n",
       "2    [[26, 47], [6, 72]]  [[55, 18], [11, 67]]  \n",
       "3    [[37, 36], [7, 71]]  [[55, 18], [14, 64]]  \n",
       "4    [[67, 6], [67, 11]]  [[37, 36], [14, 64]]  \n",
       "5   [[45, 28], [10, 68]]  [[54, 19], [12, 66]]  \n",
       "6    [[39, 34], [8, 70]]  [[56, 17], [16, 62]]  \n",
       "7    [[48, 25], [9, 69]]  [[54, 19], [13, 65]]  \n",
       "8    [[22, 51], [7, 71]]  [[43, 30], [12, 66]]  \n",
       "9    [[22, 51], [5, 73]]  [[53, 20], [18, 60]]  \n",
       "10   [[42, 31], [8, 70]]  [[52, 21], [14, 64]]  \n",
       "11  [[59, 14], [28, 50]]  [[50, 23], [16, 62]]  \n",
       "12  [[60, 13], [25, 53]]  [[46, 27], [12, 66]]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ 8 pontos - 1 raio ------\n",
      "--- Acuracia ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.655629</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.768212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.668874</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.596026</td>\n",
       "      <td>0.748344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.761589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.741722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.668874</td>\n",
       "      <td>0.589404</td>\n",
       "      <td>0.655629</td>\n",
       "      <td>0.629139</td>\n",
       "      <td>0.682119</td>\n",
       "      <td>0.642384</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.615894</td>\n",
       "      <td>0.655629</td>\n",
       "      <td>0.629139</td>\n",
       "      <td>0.655629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.781457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.668874</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.615894</td>\n",
       "      <td>0.748344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.635762</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.682119</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.754967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.523179</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.748344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.629139</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.735099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.629139</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.596026</td>\n",
       "      <td>0.754967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.549669</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.754967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.682119</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.602649</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.668874</td>\n",
       "      <td>0.741722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.741722    0.655629  0.788079          0.794702       0.728477   \n",
       "1            0.668874    0.735099  0.748344          0.788079       0.728477   \n",
       "2            0.741722    0.728477  0.741722          0.827815       0.774834   \n",
       "3            0.695364    0.748344  0.788079          0.794702       0.794702   \n",
       "4            0.668874    0.589404  0.655629          0.629139       0.682119   \n",
       "5            0.761589    0.708609  0.768212          0.748344       0.814570   \n",
       "6            0.668874    0.735099  0.748344          0.788079       0.728477   \n",
       "7            0.708609    0.635762  0.741722          0.748344       0.754967   \n",
       "8            0.741722    0.708609  0.735099          0.774834       0.695364   \n",
       "9            0.629139    0.695364  0.768212          0.754967       0.728477   \n",
       "10           0.715232    0.629139  0.741722          0.715232       0.708609   \n",
       "11           0.728477    0.774834  0.774834          0.788079       0.801325   \n",
       "12           0.708609    0.682119  0.708609          0.754967       0.602649   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.794702    0.516556  0.715232     0.721854  0.768212  0.768212  \n",
       "1        0.748344    0.516556  0.728477     0.695364  0.596026  0.748344  \n",
       "2        0.735099    0.516556  0.741722     0.708609  0.708609  0.761589  \n",
       "3        0.748344    0.516556  0.748344     0.688742  0.768212  0.741722  \n",
       "4        0.642384    0.516556  0.615894     0.655629  0.629139  0.655629  \n",
       "5        0.807947    0.516556  0.754967     0.688742  0.701987  0.781457  \n",
       "6        0.748344    0.516556  0.728477     0.695364  0.615894  0.748344  \n",
       "7        0.748344    0.516556  0.682119     0.708609  0.794702  0.754967  \n",
       "8        0.774834    0.523179  0.748344     0.735099  0.695364  0.748344  \n",
       "9        0.735099    0.516556  0.688742     0.708609  0.735099  0.735099  \n",
       "10       0.788079    0.516556  0.761589     0.715232  0.596026  0.754967  \n",
       "11       0.774834    0.549669  0.774834     0.754967  0.715232  0.754967  \n",
       "12       0.754967    0.516556  0.748344     0.761589  0.668874  0.741722  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- F1 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.734167</td>\n",
       "      <td>0.625793</td>\n",
       "      <td>0.782376</td>\n",
       "      <td>0.789636</td>\n",
       "      <td>0.726357</td>\n",
       "      <td>0.793558</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.709389</td>\n",
       "      <td>0.713039</td>\n",
       "      <td>0.762492</td>\n",
       "      <td>0.766402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.666674</td>\n",
       "      <td>0.722208</td>\n",
       "      <td>0.745361</td>\n",
       "      <td>0.786671</td>\n",
       "      <td>0.727879</td>\n",
       "      <td>0.744563</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.726357</td>\n",
       "      <td>0.682400</td>\n",
       "      <td>0.526597</td>\n",
       "      <td>0.747188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.735348</td>\n",
       "      <td>0.717704</td>\n",
       "      <td>0.737393</td>\n",
       "      <td>0.827023</td>\n",
       "      <td>0.773338</td>\n",
       "      <td>0.731959</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.738263</td>\n",
       "      <td>0.699374</td>\n",
       "      <td>0.685884</td>\n",
       "      <td>0.758763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.684122</td>\n",
       "      <td>0.744563</td>\n",
       "      <td>0.785567</td>\n",
       "      <td>0.790490</td>\n",
       "      <td>0.794756</td>\n",
       "      <td>0.742670</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.742670</td>\n",
       "      <td>0.678083</td>\n",
       "      <td>0.765108</td>\n",
       "      <td>0.737393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.658379</td>\n",
       "      <td>0.521694</td>\n",
       "      <td>0.634171</td>\n",
       "      <td>0.608651</td>\n",
       "      <td>0.676210</td>\n",
       "      <td>0.640741</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.608754</td>\n",
       "      <td>0.646361</td>\n",
       "      <td>0.627770</td>\n",
       "      <td>0.646361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.756214</td>\n",
       "      <td>0.697856</td>\n",
       "      <td>0.765108</td>\n",
       "      <td>0.746672</td>\n",
       "      <td>0.814602</td>\n",
       "      <td>0.805375</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.751685</td>\n",
       "      <td>0.679637</td>\n",
       "      <td>0.682308</td>\n",
       "      <td>0.780239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.666674</td>\n",
       "      <td>0.722208</td>\n",
       "      <td>0.745361</td>\n",
       "      <td>0.786671</td>\n",
       "      <td>0.727879</td>\n",
       "      <td>0.746672</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.726357</td>\n",
       "      <td>0.682400</td>\n",
       "      <td>0.557665</td>\n",
       "      <td>0.747188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.697856</td>\n",
       "      <td>0.605806</td>\n",
       "      <td>0.737393</td>\n",
       "      <td>0.740368</td>\n",
       "      <td>0.750860</td>\n",
       "      <td>0.744563</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.677342</td>\n",
       "      <td>0.697856</td>\n",
       "      <td>0.793558</td>\n",
       "      <td>0.750860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.740282</td>\n",
       "      <td>0.694429</td>\n",
       "      <td>0.727970</td>\n",
       "      <td>0.772794</td>\n",
       "      <td>0.688496</td>\n",
       "      <td>0.774696</td>\n",
       "      <td>0.366499</td>\n",
       "      <td>0.747612</td>\n",
       "      <td>0.725323</td>\n",
       "      <td>0.688496</td>\n",
       "      <td>0.746672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.613356</td>\n",
       "      <td>0.684122</td>\n",
       "      <td>0.767967</td>\n",
       "      <td>0.754427</td>\n",
       "      <td>0.725650</td>\n",
       "      <td>0.733882</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.688796</td>\n",
       "      <td>0.702039</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.734680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.706902</td>\n",
       "      <td>0.597008</td>\n",
       "      <td>0.735348</td>\n",
       "      <td>0.708204</td>\n",
       "      <td>0.705155</td>\n",
       "      <td>0.786671</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.756214</td>\n",
       "      <td>0.705480</td>\n",
       "      <td>0.542272</td>\n",
       "      <td>0.750860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.726357</td>\n",
       "      <td>0.771451</td>\n",
       "      <td>0.771451</td>\n",
       "      <td>0.787463</td>\n",
       "      <td>0.801272</td>\n",
       "      <td>0.774775</td>\n",
       "      <td>0.430848</td>\n",
       "      <td>0.774478</td>\n",
       "      <td>0.748920</td>\n",
       "      <td>0.714782</td>\n",
       "      <td>0.754902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.700767</td>\n",
       "      <td>0.659904</td>\n",
       "      <td>0.692512</td>\n",
       "      <td>0.751685</td>\n",
       "      <td>0.602019</td>\n",
       "      <td>0.751685</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.743667</td>\n",
       "      <td>0.756214</td>\n",
       "      <td>0.637132</td>\n",
       "      <td>0.739033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.734167    0.625793  0.782376          0.789636       0.726357   \n",
       "1            0.666674    0.722208  0.745361          0.786671       0.727879   \n",
       "2            0.735348    0.717704  0.737393          0.827023       0.773338   \n",
       "3            0.684122    0.744563  0.785567          0.790490       0.794756   \n",
       "4            0.658379    0.521694  0.634171          0.608651       0.676210   \n",
       "5            0.756214    0.697856  0.765108          0.746672       0.814602   \n",
       "6            0.666674    0.722208  0.745361          0.786671       0.727879   \n",
       "7            0.697856    0.605806  0.737393          0.740368       0.750860   \n",
       "8            0.740282    0.694429  0.727970          0.772794       0.688496   \n",
       "9            0.613356    0.684122  0.767967          0.754427       0.725650   \n",
       "10           0.706902    0.597008  0.735348          0.708204       0.705155   \n",
       "11           0.726357    0.771451  0.771451          0.787463       0.801272   \n",
       "12           0.700767    0.659904  0.692512          0.751685       0.602019   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.793558    0.351890  0.709389     0.713039  0.762492  0.766402  \n",
       "1        0.744563    0.351890  0.726357     0.682400  0.526597  0.747188  \n",
       "2        0.731959    0.351890  0.738263     0.699374  0.685884  0.758763  \n",
       "3        0.742670    0.351890  0.742670     0.678083  0.765108  0.737393  \n",
       "4        0.640741    0.351890  0.608754     0.646361  0.627770  0.646361  \n",
       "5        0.805375    0.351890  0.751685     0.679637  0.682308  0.780239  \n",
       "6        0.746672    0.351890  0.726357     0.682400  0.557665  0.747188  \n",
       "7        0.744563    0.351890  0.677342     0.697856  0.793558  0.750860  \n",
       "8        0.774696    0.366499  0.747612     0.725323  0.688496  0.746672  \n",
       "9        0.733882    0.351890  0.688796     0.702039  0.735099  0.734680  \n",
       "10       0.786671    0.351890  0.756214     0.705480  0.542272  0.750860  \n",
       "11       0.774775    0.430848  0.774478     0.748920  0.714782  0.754902  \n",
       "12       0.751685    0.351890  0.743667     0.756214  0.637132  0.739033  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Precision Score ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.764102</td>\n",
       "      <td>0.710732</td>\n",
       "      <td>0.813133</td>\n",
       "      <td>0.817854</td>\n",
       "      <td>0.732134</td>\n",
       "      <td>0.798160</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.727483</td>\n",
       "      <td>0.744083</td>\n",
       "      <td>0.788824</td>\n",
       "      <td>0.772938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.670427</td>\n",
       "      <td>0.776383</td>\n",
       "      <td>0.755689</td>\n",
       "      <td>0.792320</td>\n",
       "      <td>0.728888</td>\n",
       "      <td>0.758331</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.732134</td>\n",
       "      <td>0.723004</td>\n",
       "      <td>0.694161</td>\n",
       "      <td>0.750287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.759795</td>\n",
       "      <td>0.759167</td>\n",
       "      <td>0.752790</td>\n",
       "      <td>0.830952</td>\n",
       "      <td>0.778776</td>\n",
       "      <td>0.741880</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.750009</td>\n",
       "      <td>0.729153</td>\n",
       "      <td>0.775986</td>\n",
       "      <td>0.769498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.718332</td>\n",
       "      <td>0.758331</td>\n",
       "      <td>0.797115</td>\n",
       "      <td>0.813151</td>\n",
       "      <td>0.795437</td>\n",
       "      <td>0.765047</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.765047</td>\n",
       "      <td>0.708667</td>\n",
       "      <td>0.777788</td>\n",
       "      <td>0.752790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.684361</td>\n",
       "      <td>0.671251</td>\n",
       "      <td>0.690115</td>\n",
       "      <td>0.651882</td>\n",
       "      <td>0.690585</td>\n",
       "      <td>0.642735</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.619732</td>\n",
       "      <td>0.666685</td>\n",
       "      <td>0.634437</td>\n",
       "      <td>0.666685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.779440</td>\n",
       "      <td>0.733585</td>\n",
       "      <td>0.777788</td>\n",
       "      <td>0.751689</td>\n",
       "      <td>0.815778</td>\n",
       "      <td>0.819457</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.763899</td>\n",
       "      <td>0.704969</td>\n",
       "      <td>0.753537</td>\n",
       "      <td>0.784668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.670427</td>\n",
       "      <td>0.776383</td>\n",
       "      <td>0.755689</td>\n",
       "      <td>0.792320</td>\n",
       "      <td>0.728888</td>\n",
       "      <td>0.751689</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.732134</td>\n",
       "      <td>0.723004</td>\n",
       "      <td>0.712394</td>\n",
       "      <td>0.750287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.733585</td>\n",
       "      <td>0.678743</td>\n",
       "      <td>0.752790</td>\n",
       "      <td>0.773944</td>\n",
       "      <td>0.766860</td>\n",
       "      <td>0.758331</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.688448</td>\n",
       "      <td>0.733585</td>\n",
       "      <td>0.798160</td>\n",
       "      <td>0.766860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.744195</td>\n",
       "      <td>0.744332</td>\n",
       "      <td>0.754554</td>\n",
       "      <td>0.780813</td>\n",
       "      <td>0.707477</td>\n",
       "      <td>0.774830</td>\n",
       "      <td>0.752053</td>\n",
       "      <td>0.749262</td>\n",
       "      <td>0.764090</td>\n",
       "      <td>0.707477</td>\n",
       "      <td>0.751689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.644922</td>\n",
       "      <td>0.718332</td>\n",
       "      <td>0.768331</td>\n",
       "      <td>0.755554</td>\n",
       "      <td>0.733933</td>\n",
       "      <td>0.736843</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.688911</td>\n",
       "      <td>0.721870</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.735296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.734535</td>\n",
       "      <td>0.672677</td>\n",
       "      <td>0.759795</td>\n",
       "      <td>0.730765</td>\n",
       "      <td>0.714263</td>\n",
       "      <td>0.792320</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.779440</td>\n",
       "      <td>0.738841</td>\n",
       "      <td>0.655434</td>\n",
       "      <td>0.766860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.732134</td>\n",
       "      <td>0.786285</td>\n",
       "      <td>0.786285</td>\n",
       "      <td>0.789357</td>\n",
       "      <td>0.803756</td>\n",
       "      <td>0.777168</td>\n",
       "      <td>0.690594</td>\n",
       "      <td>0.775214</td>\n",
       "      <td>0.774310</td>\n",
       "      <td>0.719445</td>\n",
       "      <td>0.754904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.725264</td>\n",
       "      <td>0.731294</td>\n",
       "      <td>0.750805</td>\n",
       "      <td>0.763899</td>\n",
       "      <td>0.602237</td>\n",
       "      <td>0.763899</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.761439</td>\n",
       "      <td>0.779440</td>\n",
       "      <td>0.739607</td>\n",
       "      <td>0.747666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.764102    0.710732  0.813133          0.817854       0.732134   \n",
       "1            0.670427    0.776383  0.755689          0.792320       0.728888   \n",
       "2            0.759795    0.759167  0.752790          0.830952       0.778776   \n",
       "3            0.718332    0.758331  0.797115          0.813151       0.795437   \n",
       "4            0.684361    0.671251  0.690115          0.651882       0.690585   \n",
       "5            0.779440    0.733585  0.777788          0.751689       0.815778   \n",
       "6            0.670427    0.776383  0.755689          0.792320       0.728888   \n",
       "7            0.733585    0.678743  0.752790          0.773944       0.766860   \n",
       "8            0.744195    0.744332  0.754554          0.780813       0.707477   \n",
       "9            0.644922    0.718332  0.768331          0.755554       0.733933   \n",
       "10           0.734535    0.672677  0.759795          0.730765       0.714263   \n",
       "11           0.732134    0.786285  0.786285          0.789357       0.803756   \n",
       "12           0.725264    0.731294  0.750805          0.763899       0.602237   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.798160    0.266830  0.727483     0.744083  0.788824  0.772938  \n",
       "1        0.758331    0.266830  0.732134     0.723004  0.694161  0.750287  \n",
       "2        0.741880    0.266830  0.750009     0.729153  0.775986  0.769498  \n",
       "3        0.765047    0.266830  0.765047     0.708667  0.777788  0.752790  \n",
       "4        0.642735    0.266830  0.619732     0.666685  0.634437  0.666685  \n",
       "5        0.819457    0.266830  0.763899     0.704969  0.753537  0.784668  \n",
       "6        0.751689    0.266830  0.732134     0.723004  0.712394  0.750287  \n",
       "7        0.758331    0.266830  0.688448     0.733585  0.798160  0.766860  \n",
       "8        0.774830    0.752053  0.749262     0.764090  0.707477  0.751689  \n",
       "9        0.736843    0.266830  0.688911     0.721870  0.735099  0.735296  \n",
       "10       0.792320    0.266830  0.779440     0.738841  0.655434  0.766860  \n",
       "11       0.777168    0.690594  0.775214     0.774310  0.719445  0.754904  \n",
       "12       0.763899    0.266830  0.761439     0.779440  0.739607  0.747666  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Recall Score ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.655629</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.768212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.668874</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.596026</td>\n",
       "      <td>0.748344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.761589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.741722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.668874</td>\n",
       "      <td>0.589404</td>\n",
       "      <td>0.655629</td>\n",
       "      <td>0.629139</td>\n",
       "      <td>0.682119</td>\n",
       "      <td>0.642384</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.615894</td>\n",
       "      <td>0.655629</td>\n",
       "      <td>0.629139</td>\n",
       "      <td>0.655629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.781457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.668874</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.615894</td>\n",
       "      <td>0.748344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.635762</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.682119</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.754967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.523179</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.748344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.629139</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.735099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.629139</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.596026</td>\n",
       "      <td>0.754967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.549669</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.754967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.682119</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.602649</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.668874</td>\n",
       "      <td>0.741722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.741722    0.655629  0.788079          0.794702       0.728477   \n",
       "1            0.668874    0.735099  0.748344          0.788079       0.728477   \n",
       "2            0.741722    0.728477  0.741722          0.827815       0.774834   \n",
       "3            0.695364    0.748344  0.788079          0.794702       0.794702   \n",
       "4            0.668874    0.589404  0.655629          0.629139       0.682119   \n",
       "5            0.761589    0.708609  0.768212          0.748344       0.814570   \n",
       "6            0.668874    0.735099  0.748344          0.788079       0.728477   \n",
       "7            0.708609    0.635762  0.741722          0.748344       0.754967   \n",
       "8            0.741722    0.708609  0.735099          0.774834       0.695364   \n",
       "9            0.629139    0.695364  0.768212          0.754967       0.728477   \n",
       "10           0.715232    0.629139  0.741722          0.715232       0.708609   \n",
       "11           0.728477    0.774834  0.774834          0.788079       0.801325   \n",
       "12           0.708609    0.682119  0.708609          0.754967       0.602649   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.794702    0.516556  0.715232     0.721854  0.768212  0.768212  \n",
       "1        0.748344    0.516556  0.728477     0.695364  0.596026  0.748344  \n",
       "2        0.735099    0.516556  0.741722     0.708609  0.708609  0.761589  \n",
       "3        0.748344    0.516556  0.748344     0.688742  0.768212  0.741722  \n",
       "4        0.642384    0.516556  0.615894     0.655629  0.629139  0.655629  \n",
       "5        0.807947    0.516556  0.754967     0.688742  0.701987  0.781457  \n",
       "6        0.748344    0.516556  0.728477     0.695364  0.615894  0.748344  \n",
       "7        0.748344    0.516556  0.682119     0.708609  0.794702  0.754967  \n",
       "8        0.774834    0.523179  0.748344     0.735099  0.695364  0.748344  \n",
       "9        0.735099    0.516556  0.688742     0.708609  0.735099  0.735099  \n",
       "10       0.788079    0.516556  0.761589     0.715232  0.596026  0.754967  \n",
       "11       0.774834    0.549669  0.774834     0.754967  0.715232  0.754967  \n",
       "12       0.754967    0.516556  0.748344     0.761589  0.668874  0.741722  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Matriz confusao ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[42, 31], [8, 70]]</td>\n",
       "      <td>[[27, 46], [6, 72]]</td>\n",
       "      <td>[[46, 27], [5, 73]]</td>\n",
       "      <td>[[47, 26], [5, 73]]</td>\n",
       "      <td>[[47, 26], [15, 63]]</td>\n",
       "      <td>[[53, 20], [11, 67]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[42, 31], [12, 66]]</td>\n",
       "      <td>[[40, 33], [9, 69]]</td>\n",
       "      <td>[[45, 28], [7, 71]]</td>\n",
       "      <td>[[50, 23], [12, 66]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[43, 30], [20, 58]]</td>\n",
       "      <td>[[38, 35], [5, 73]]</td>\n",
       "      <td>[[47, 26], [12, 66]]</td>\n",
       "      <td>[[52, 21], [11, 67]]</td>\n",
       "      <td>[[50, 23], [18, 60]]</td>\n",
       "      <td>[[46, 27], [11, 67]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[47, 26], [15, 63]]</td>\n",
       "      <td>[[36, 37], [9, 69]]</td>\n",
       "      <td>[[15, 58], [3, 75]]</td>\n",
       "      <td>[[50, 23], [15, 63]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[43, 30], [9, 69]]</td>\n",
       "      <td>[[39, 34], [7, 71]]</td>\n",
       "      <td>[[45, 28], [11, 67]]</td>\n",
       "      <td>[[56, 17], [9, 69]]</td>\n",
       "      <td>[[51, 22], [12, 66]]</td>\n",
       "      <td>[[46, 27], [13, 65]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[46, 27], [12, 66]]</td>\n",
       "      <td>[[39, 34], [10, 68]]</td>\n",
       "      <td>[[32, 41], [3, 75]]</td>\n",
       "      <td>[[48, 25], [11, 67]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[37, 36], [10, 68]]</td>\n",
       "      <td>[[46, 27], [11, 67]]</td>\n",
       "      <td>[[50, 23], [9, 69]]</td>\n",
       "      <td>[[48, 25], [6, 72]]</td>\n",
       "      <td>[[59, 14], [17, 61]]</td>\n",
       "      <td>[[44, 29], [9, 69]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[44, 29], [9, 69]]</td>\n",
       "      <td>[[37, 36], [11, 67]]</td>\n",
       "      <td>[[48, 25], [10, 68]]</td>\n",
       "      <td>[[45, 28], [11, 67]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[36, 37], [13, 65]]</td>\n",
       "      <td>[[15, 58], [4, 74]]</td>\n",
       "      <td>[[30, 43], [9, 69]]</td>\n",
       "      <td>[[29, 44], [12, 66]]</td>\n",
       "      <td>[[40, 33], [15, 63]]</td>\n",
       "      <td>[[42, 31], [23, 55]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[35, 38], [20, 58]]</td>\n",
       "      <td>[[36, 37], [15, 63]]</td>\n",
       "      <td>[[51, 22], [34, 44]]</td>\n",
       "      <td>[[36, 37], [15, 63]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[[45, 28], [8, 70]]</td>\n",
       "      <td>[[38, 35], [9, 69]]</td>\n",
       "      <td>[[48, 25], [10, 68]]</td>\n",
       "      <td>[[49, 24], [14, 64]]</td>\n",
       "      <td>[[61, 12], [16, 62]]</td>\n",
       "      <td>[[51, 22], [7, 71]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[47, 26], [11, 67]]</td>\n",
       "      <td>[[38, 35], [12, 66]]</td>\n",
       "      <td>[[33, 40], [5, 73]]</td>\n",
       "      <td>[[52, 21], [12, 66]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[[43, 30], [20, 58]]</td>\n",
       "      <td>[[38, 35], [5, 73]]</td>\n",
       "      <td>[[47, 26], [12, 66]]</td>\n",
       "      <td>[[52, 21], [11, 67]]</td>\n",
       "      <td>[[50, 23], [18, 60]]</td>\n",
       "      <td>[[49, 24], [14, 64]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[47, 26], [15, 63]]</td>\n",
       "      <td>[[36, 37], [9, 69]]</td>\n",
       "      <td>[[18, 55], [3, 75]]</td>\n",
       "      <td>[[50, 23], [15, 63]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[[38, 35], [9, 69]]</td>\n",
       "      <td>[[26, 47], [8, 70]]</td>\n",
       "      <td>[[45, 28], [11, 67]]</td>\n",
       "      <td>[[42, 31], [7, 71]]</td>\n",
       "      <td>[[46, 27], [10, 68]]</td>\n",
       "      <td>[[46, 27], [11, 67]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[41, 32], [16, 62]]</td>\n",
       "      <td>[[38, 35], [9, 69]]</td>\n",
       "      <td>[[53, 20], [11, 67]]</td>\n",
       "      <td>[[46, 27], [10, 68]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[[49, 24], [15, 63]]</td>\n",
       "      <td>[[36, 37], [7, 71]]</td>\n",
       "      <td>[[42, 31], [9, 69]]</td>\n",
       "      <td>[[50, 23], [11, 67]]</td>\n",
       "      <td>[[40, 33], [13, 65]]</td>\n",
       "      <td>[[55, 18], [16, 62]]</td>\n",
       "      <td>[[1, 72], [0, 78]]</td>\n",
       "      <td>[[51, 22], [16, 62]]</td>\n",
       "      <td>[[40, 33], [7, 71]]</td>\n",
       "      <td>[[40, 33], [13, 65]]</td>\n",
       "      <td>[[49, 24], [14, 64]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[[31, 42], [14, 64]]</td>\n",
       "      <td>[[37, 36], [10, 68]]</td>\n",
       "      <td>[[54, 19], [16, 62]]</td>\n",
       "      <td>[[52, 21], [16, 62]]</td>\n",
       "      <td>[[46, 27], [14, 64]]</td>\n",
       "      <td>[[49, 24], [16, 62]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[50, 23], [24, 54]]</td>\n",
       "      <td>[[41, 32], [12, 66]]</td>\n",
       "      <td>[[53, 20], [20, 58]]</td>\n",
       "      <td>[[51, 22], [18, 60]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[[40, 33], [10, 68]]</td>\n",
       "      <td>[[25, 48], [8, 70]]</td>\n",
       "      <td>[[43, 30], [9, 69]]</td>\n",
       "      <td>[[41, 32], [11, 67]]</td>\n",
       "      <td>[[44, 29], [15, 63]]</td>\n",
       "      <td>[[52, 21], [11, 67]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[45, 28], [8, 70]]</td>\n",
       "      <td>[[39, 34], [9, 69]]</td>\n",
       "      <td>[[18, 55], [6, 72]]</td>\n",
       "      <td>[[46, 27], [10, 68]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[[47, 26], [15, 63]]</td>\n",
       "      <td>[[48, 25], [9, 69]]</td>\n",
       "      <td>[[48, 25], [9, 69]]</td>\n",
       "      <td>[[54, 19], [13, 65]]</td>\n",
       "      <td>[[61, 12], [18, 60]]</td>\n",
       "      <td>[[59, 14], [20, 58]]</td>\n",
       "      <td>[[6, 67], [1, 77]]</td>\n",
       "      <td>[[54, 19], [15, 63]]</td>\n",
       "      <td>[[44, 29], [8, 70]]</td>\n",
       "      <td>[[56, 17], [26, 52]]</td>\n",
       "      <td>[[54, 19], [18, 60]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[[40, 33], [11, 67]]</td>\n",
       "      <td>[[31, 42], [6, 72]]</td>\n",
       "      <td>[[35, 38], [6, 72]]</td>\n",
       "      <td>[[47, 26], [11, 67]]</td>\n",
       "      <td>[[41, 32], [28, 50]]</td>\n",
       "      <td>[[47, 26], [11, 67]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[45, 28], [10, 68]]</td>\n",
       "      <td>[[45, 28], [8, 70]]</td>\n",
       "      <td>[[27, 46], [4, 74]]</td>\n",
       "      <td>[[47, 26], [13, 65]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Nearest Neighbors            Linear SVM               RBF SVM  \\\n",
       "0    [[42, 31], [8, 70]]   [[27, 46], [6, 72]]   [[46, 27], [5, 73]]   \n",
       "1   [[43, 30], [20, 58]]   [[38, 35], [5, 73]]  [[47, 26], [12, 66]]   \n",
       "2    [[43, 30], [9, 69]]   [[39, 34], [7, 71]]  [[45, 28], [11, 67]]   \n",
       "3   [[37, 36], [10, 68]]  [[46, 27], [11, 67]]   [[50, 23], [9, 69]]   \n",
       "4   [[36, 37], [13, 65]]   [[15, 58], [4, 74]]   [[30, 43], [9, 69]]   \n",
       "5    [[45, 28], [8, 70]]   [[38, 35], [9, 69]]  [[48, 25], [10, 68]]   \n",
       "6   [[43, 30], [20, 58]]   [[38, 35], [5, 73]]  [[47, 26], [12, 66]]   \n",
       "7    [[38, 35], [9, 69]]   [[26, 47], [8, 70]]  [[45, 28], [11, 67]]   \n",
       "8   [[49, 24], [15, 63]]   [[36, 37], [7, 71]]   [[42, 31], [9, 69]]   \n",
       "9   [[31, 42], [14, 64]]  [[37, 36], [10, 68]]  [[54, 19], [16, 62]]   \n",
       "10  [[40, 33], [10, 68]]   [[25, 48], [8, 70]]   [[43, 30], [9, 69]]   \n",
       "11  [[47, 26], [15, 63]]   [[48, 25], [9, 69]]   [[48, 25], [9, 69]]   \n",
       "12  [[40, 33], [11, 67]]   [[31, 42], [6, 72]]   [[35, 38], [6, 72]]   \n",
       "\n",
       "        Gaussian Process         Decision Tree         Random Forest  \\\n",
       "0    [[47, 26], [5, 73]]  [[47, 26], [15, 63]]  [[53, 20], [11, 67]]   \n",
       "1   [[52, 21], [11, 67]]  [[50, 23], [18, 60]]  [[46, 27], [11, 67]]   \n",
       "2    [[56, 17], [9, 69]]  [[51, 22], [12, 66]]  [[46, 27], [13, 65]]   \n",
       "3    [[48, 25], [6, 72]]  [[59, 14], [17, 61]]   [[44, 29], [9, 69]]   \n",
       "4   [[29, 44], [12, 66]]  [[40, 33], [15, 63]]  [[42, 31], [23, 55]]   \n",
       "5   [[49, 24], [14, 64]]  [[61, 12], [16, 62]]   [[51, 22], [7, 71]]   \n",
       "6   [[52, 21], [11, 67]]  [[50, 23], [18, 60]]  [[49, 24], [14, 64]]   \n",
       "7    [[42, 31], [7, 71]]  [[46, 27], [10, 68]]  [[46, 27], [11, 67]]   \n",
       "8   [[50, 23], [11, 67]]  [[40, 33], [13, 65]]  [[55, 18], [16, 62]]   \n",
       "9   [[52, 21], [16, 62]]  [[46, 27], [14, 64]]  [[49, 24], [16, 62]]   \n",
       "10  [[41, 32], [11, 67]]  [[44, 29], [15, 63]]  [[52, 21], [11, 67]]   \n",
       "11  [[54, 19], [13, 65]]  [[61, 12], [18, 60]]  [[59, 14], [20, 58]]   \n",
       "12  [[47, 26], [11, 67]]  [[41, 32], [28, 50]]  [[47, 26], [11, 67]]   \n",
       "\n",
       "            Neural Net              AdaBoost           Naive Bayes  \\\n",
       "0   [[0, 73], [0, 78]]  [[42, 31], [12, 66]]   [[40, 33], [9, 69]]   \n",
       "1   [[0, 73], [0, 78]]  [[47, 26], [15, 63]]   [[36, 37], [9, 69]]   \n",
       "2   [[0, 73], [0, 78]]  [[46, 27], [12, 66]]  [[39, 34], [10, 68]]   \n",
       "3   [[0, 73], [0, 78]]   [[44, 29], [9, 69]]  [[37, 36], [11, 67]]   \n",
       "4   [[0, 73], [0, 78]]  [[35, 38], [20, 58]]  [[36, 37], [15, 63]]   \n",
       "5   [[0, 73], [0, 78]]  [[47, 26], [11, 67]]  [[38, 35], [12, 66]]   \n",
       "6   [[0, 73], [0, 78]]  [[47, 26], [15, 63]]   [[36, 37], [9, 69]]   \n",
       "7   [[0, 73], [0, 78]]  [[41, 32], [16, 62]]   [[38, 35], [9, 69]]   \n",
       "8   [[1, 72], [0, 78]]  [[51, 22], [16, 62]]   [[40, 33], [7, 71]]   \n",
       "9   [[0, 73], [0, 78]]  [[50, 23], [24, 54]]  [[41, 32], [12, 66]]   \n",
       "10  [[0, 73], [0, 78]]   [[45, 28], [8, 70]]   [[39, 34], [9, 69]]   \n",
       "11  [[6, 67], [1, 77]]  [[54, 19], [15, 63]]   [[44, 29], [8, 70]]   \n",
       "12  [[0, 73], [0, 78]]  [[45, 28], [10, 68]]   [[45, 28], [8, 70]]   \n",
       "\n",
       "                     QDA               XGBoost  \n",
       "0    [[45, 28], [7, 71]]  [[50, 23], [12, 66]]  \n",
       "1    [[15, 58], [3, 75]]  [[50, 23], [15, 63]]  \n",
       "2    [[32, 41], [3, 75]]  [[48, 25], [11, 67]]  \n",
       "3   [[48, 25], [10, 68]]  [[45, 28], [11, 67]]  \n",
       "4   [[51, 22], [34, 44]]  [[36, 37], [15, 63]]  \n",
       "5    [[33, 40], [5, 73]]  [[52, 21], [12, 66]]  \n",
       "6    [[18, 55], [3, 75]]  [[50, 23], [15, 63]]  \n",
       "7   [[53, 20], [11, 67]]  [[46, 27], [10, 68]]  \n",
       "8   [[40, 33], [13, 65]]  [[49, 24], [14, 64]]  \n",
       "9   [[53, 20], [20, 58]]  [[51, 22], [18, 60]]  \n",
       "10   [[18, 55], [6, 72]]  [[46, 27], [10, 68]]  \n",
       "11  [[56, 17], [26, 52]]  [[54, 19], [18, 60]]  \n",
       "12   [[27, 46], [4, 74]]  [[47, 26], [13, 65]]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ 8 pontos - 2 raio ------\n",
      "--- Acuracia ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.668874</td>\n",
       "      <td>0.615894</td>\n",
       "      <td>0.821192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.668874</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.748344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.655629</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.668874</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.774834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.668874</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.735099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.629139</td>\n",
       "      <td>0.768212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.668874</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.642384</td>\n",
       "      <td>0.635762</td>\n",
       "      <td>0.715232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.668874</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.748344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.649007</td>\n",
       "      <td>0.596026</td>\n",
       "      <td>0.774834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.635762</td>\n",
       "      <td>0.768212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.748344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.655629</td>\n",
       "      <td>0.662252</td>\n",
       "      <td>0.741722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.682119</td>\n",
       "      <td>0.807947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.668874</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.642384</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.754967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.821192    0.794702  0.781457          0.788079       0.688742   \n",
       "1            0.695364    0.748344  0.754967          0.761589       0.741722   \n",
       "2            0.768212    0.827815  0.841060          0.807947       0.655629   \n",
       "3            0.741722    0.821192  0.821192          0.827815       0.675497   \n",
       "4            0.688742    0.735099  0.761589          0.728477       0.735099   \n",
       "5            0.668874    0.701987  0.754967          0.781457       0.675497   \n",
       "6            0.695364    0.748344  0.754967          0.761589       0.741722   \n",
       "7            0.728477    0.781457  0.774834          0.788079       0.695364   \n",
       "8            0.721854    0.748344  0.741722          0.768212       0.781457   \n",
       "9            0.708609    0.741722  0.748344          0.761589       0.715232   \n",
       "10           0.768212    0.774834  0.761589          0.774834       0.695364   \n",
       "11           0.754967    0.801325  0.768212          0.827815       0.781457   \n",
       "12           0.668874    0.721854  0.715232          0.728477       0.642384   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.847682    0.516556  0.774834     0.668874  0.615894  0.821192  \n",
       "1        0.721854    0.516556  0.754967     0.668874  0.781457  0.748344  \n",
       "2        0.774834    0.516556  0.754967     0.668874  0.715232  0.774834  \n",
       "3        0.728477    0.516556  0.748344     0.668874  0.695364  0.735099  \n",
       "4        0.741722    0.516556  0.695364     0.721854  0.629139  0.768212  \n",
       "5        0.701987    0.516556  0.701987     0.642384  0.635762  0.715232  \n",
       "6        0.721854    0.516556  0.754967     0.668874  0.768212  0.748344  \n",
       "7        0.801325    0.516556  0.715232     0.649007  0.596026  0.774834  \n",
       "8        0.741722    0.516556  0.754967     0.748344  0.635762  0.768212  \n",
       "9        0.721854    0.516556  0.675497     0.741722  0.701987  0.748344  \n",
       "10       0.774834    0.516556  0.735099     0.655629  0.662252  0.741722  \n",
       "11       0.814570    0.516556  0.827815     0.748344  0.682119  0.807947  \n",
       "12       0.701987    0.516556  0.708609     0.768212  0.715232  0.754967  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- F1 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.818195</td>\n",
       "      <td>0.794485</td>\n",
       "      <td>0.780647</td>\n",
       "      <td>0.786671</td>\n",
       "      <td>0.672589</td>\n",
       "      <td>0.847347</td>\n",
       "      <td>0.35189</td>\n",
       "      <td>0.773338</td>\n",
       "      <td>0.652760</td>\n",
       "      <td>0.567016</td>\n",
       "      <td>0.821003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.690787</td>\n",
       "      <td>0.746064</td>\n",
       "      <td>0.754902</td>\n",
       "      <td>0.760005</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.720576</td>\n",
       "      <td>0.35189</td>\n",
       "      <td>0.753054</td>\n",
       "      <td>0.648241</td>\n",
       "      <td>0.776973</td>\n",
       "      <td>0.746064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.763456</td>\n",
       "      <td>0.827542</td>\n",
       "      <td>0.840808</td>\n",
       "      <td>0.807235</td>\n",
       "      <td>0.631562</td>\n",
       "      <td>0.771451</td>\n",
       "      <td>0.35189</td>\n",
       "      <td>0.753054</td>\n",
       "      <td>0.652760</td>\n",
       "      <td>0.703934</td>\n",
       "      <td>0.772794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.737393</td>\n",
       "      <td>0.820195</td>\n",
       "      <td>0.821003</td>\n",
       "      <td>0.826671</td>\n",
       "      <td>0.674556</td>\n",
       "      <td>0.726357</td>\n",
       "      <td>0.35189</td>\n",
       "      <td>0.744563</td>\n",
       "      <td>0.654782</td>\n",
       "      <td>0.671606</td>\n",
       "      <td>0.732699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.684573</td>\n",
       "      <td>0.723826</td>\n",
       "      <td>0.760005</td>\n",
       "      <td>0.724841</td>\n",
       "      <td>0.734121</td>\n",
       "      <td>0.741767</td>\n",
       "      <td>0.35189</td>\n",
       "      <td>0.695177</td>\n",
       "      <td>0.715583</td>\n",
       "      <td>0.603221</td>\n",
       "      <td>0.767701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.661408</td>\n",
       "      <td>0.686521</td>\n",
       "      <td>0.750860</td>\n",
       "      <td>0.776064</td>\n",
       "      <td>0.667489</td>\n",
       "      <td>0.696992</td>\n",
       "      <td>0.35189</td>\n",
       "      <td>0.696992</td>\n",
       "      <td>0.631050</td>\n",
       "      <td>0.599084</td>\n",
       "      <td>0.708204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.690787</td>\n",
       "      <td>0.746064</td>\n",
       "      <td>0.754902</td>\n",
       "      <td>0.760005</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.721045</td>\n",
       "      <td>0.35189</td>\n",
       "      <td>0.753054</td>\n",
       "      <td>0.648241</td>\n",
       "      <td>0.767967</td>\n",
       "      <td>0.746064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.720535</td>\n",
       "      <td>0.780647</td>\n",
       "      <td>0.772165</td>\n",
       "      <td>0.786671</td>\n",
       "      <td>0.688496</td>\n",
       "      <td>0.799524</td>\n",
       "      <td>0.35189</td>\n",
       "      <td>0.708204</td>\n",
       "      <td>0.628398</td>\n",
       "      <td>0.526597</td>\n",
       "      <td>0.773338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.718557</td>\n",
       "      <td>0.742670</td>\n",
       "      <td>0.737393</td>\n",
       "      <td>0.766402</td>\n",
       "      <td>0.781226</td>\n",
       "      <td>0.741449</td>\n",
       "      <td>0.35189</td>\n",
       "      <td>0.754708</td>\n",
       "      <td>0.743667</td>\n",
       "      <td>0.591466</td>\n",
       "      <td>0.767353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.707761</td>\n",
       "      <td>0.736423</td>\n",
       "      <td>0.744563</td>\n",
       "      <td>0.760494</td>\n",
       "      <td>0.703934</td>\n",
       "      <td>0.720006</td>\n",
       "      <td>0.35189</td>\n",
       "      <td>0.672963</td>\n",
       "      <td>0.739706</td>\n",
       "      <td>0.686521</td>\n",
       "      <td>0.747946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.761432</td>\n",
       "      <td>0.774478</td>\n",
       "      <td>0.758763</td>\n",
       "      <td>0.773338</td>\n",
       "      <td>0.687166</td>\n",
       "      <td>0.773338</td>\n",
       "      <td>0.35189</td>\n",
       "      <td>0.730175</td>\n",
       "      <td>0.636605</td>\n",
       "      <td>0.624818</td>\n",
       "      <td>0.741449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.753054</td>\n",
       "      <td>0.800004</td>\n",
       "      <td>0.766402</td>\n",
       "      <td>0.827709</td>\n",
       "      <td>0.780976</td>\n",
       "      <td>0.814602</td>\n",
       "      <td>0.35189</td>\n",
       "      <td>0.827542</td>\n",
       "      <td>0.744563</td>\n",
       "      <td>0.666649</td>\n",
       "      <td>0.807896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.652760</td>\n",
       "      <td>0.710017</td>\n",
       "      <td>0.703934</td>\n",
       "      <td>0.721776</td>\n",
       "      <td>0.611401</td>\n",
       "      <td>0.695872</td>\n",
       "      <td>0.35189</td>\n",
       "      <td>0.705155</td>\n",
       "      <td>0.765108</td>\n",
       "      <td>0.710459</td>\n",
       "      <td>0.753054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.818195    0.794485  0.780647          0.786671       0.672589   \n",
       "1            0.690787    0.746064  0.754902          0.760005       0.741722   \n",
       "2            0.763456    0.827542  0.840808          0.807235       0.631562   \n",
       "3            0.737393    0.820195  0.821003          0.826671       0.674556   \n",
       "4            0.684573    0.723826  0.760005          0.724841       0.734121   \n",
       "5            0.661408    0.686521  0.750860          0.776064       0.667489   \n",
       "6            0.690787    0.746064  0.754902          0.760005       0.741722   \n",
       "7            0.720535    0.780647  0.772165          0.786671       0.688496   \n",
       "8            0.718557    0.742670  0.737393          0.766402       0.781226   \n",
       "9            0.707761    0.736423  0.744563          0.760494       0.703934   \n",
       "10           0.761432    0.774478  0.758763          0.773338       0.687166   \n",
       "11           0.753054    0.800004  0.766402          0.827709       0.780976   \n",
       "12           0.652760    0.710017  0.703934          0.721776       0.611401   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.847347     0.35189  0.773338     0.652760  0.567016  0.821003  \n",
       "1        0.720576     0.35189  0.753054     0.648241  0.776973  0.746064  \n",
       "2        0.771451     0.35189  0.753054     0.652760  0.703934  0.772794  \n",
       "3        0.726357     0.35189  0.744563     0.654782  0.671606  0.732699  \n",
       "4        0.741767     0.35189  0.695177     0.715583  0.603221  0.767701  \n",
       "5        0.696992     0.35189  0.696992     0.631050  0.599084  0.708204  \n",
       "6        0.721045     0.35189  0.753054     0.648241  0.767967  0.746064  \n",
       "7        0.799524     0.35189  0.708204     0.628398  0.526597  0.773338  \n",
       "8        0.741449     0.35189  0.754708     0.743667  0.591466  0.767353  \n",
       "9        0.720006     0.35189  0.672963     0.739706  0.686521  0.747946  \n",
       "10       0.773338     0.35189  0.730175     0.636605  0.624818  0.741449  \n",
       "11       0.814602     0.35189  0.827542     0.744563  0.666649  0.807896  \n",
       "12       0.695872     0.35189  0.705155     0.765108  0.710459  0.753054  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Precision Score ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.837212</td>\n",
       "      <td>0.794898</td>\n",
       "      <td>0.783234</td>\n",
       "      <td>0.792320</td>\n",
       "      <td>0.723093</td>\n",
       "      <td>0.848885</td>\n",
       "      <td>0.26683</td>\n",
       "      <td>0.778776</td>\n",
       "      <td>0.696254</td>\n",
       "      <td>0.686030</td>\n",
       "      <td>0.821465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.702424</td>\n",
       "      <td>0.753483</td>\n",
       "      <td>0.754904</td>\n",
       "      <td>0.765233</td>\n",
       "      <td>0.743350</td>\n",
       "      <td>0.723399</td>\n",
       "      <td>0.26683</td>\n",
       "      <td>0.759337</td>\n",
       "      <td>0.707123</td>\n",
       "      <td>0.798873</td>\n",
       "      <td>0.753483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.784595</td>\n",
       "      <td>0.828437</td>\n",
       "      <td>0.841743</td>\n",
       "      <td>0.810038</td>\n",
       "      <td>0.696099</td>\n",
       "      <td>0.786285</td>\n",
       "      <td>0.26683</td>\n",
       "      <td>0.759337</td>\n",
       "      <td>0.696254</td>\n",
       "      <td>0.743737</td>\n",
       "      <td>0.780813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.752790</td>\n",
       "      <td>0.825142</td>\n",
       "      <td>0.821465</td>\n",
       "      <td>0.832951</td>\n",
       "      <td>0.680855</td>\n",
       "      <td>0.732134</td>\n",
       "      <td>0.26683</td>\n",
       "      <td>0.758331</td>\n",
       "      <td>0.691771</td>\n",
       "      <td>0.757720</td>\n",
       "      <td>0.739818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.694451</td>\n",
       "      <td>0.769853</td>\n",
       "      <td>0.765233</td>\n",
       "      <td>0.736120</td>\n",
       "      <td>0.742551</td>\n",
       "      <td>0.741878</td>\n",
       "      <td>0.26683</td>\n",
       "      <td>0.695234</td>\n",
       "      <td>0.736262</td>\n",
       "      <td>0.660905</td>\n",
       "      <td>0.768887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.678692</td>\n",
       "      <td>0.739342</td>\n",
       "      <td>0.766860</td>\n",
       "      <td>0.803339</td>\n",
       "      <td>0.687221</td>\n",
       "      <td>0.710579</td>\n",
       "      <td>0.26683</td>\n",
       "      <td>0.710579</td>\n",
       "      <td>0.654500</td>\n",
       "      <td>0.694127</td>\n",
       "      <td>0.730765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.702424</td>\n",
       "      <td>0.753483</td>\n",
       "      <td>0.754904</td>\n",
       "      <td>0.765233</td>\n",
       "      <td>0.743350</td>\n",
       "      <td>0.722532</td>\n",
       "      <td>0.26683</td>\n",
       "      <td>0.759337</td>\n",
       "      <td>0.707123</td>\n",
       "      <td>0.768331</td>\n",
       "      <td>0.753483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.749319</td>\n",
       "      <td>0.783234</td>\n",
       "      <td>0.783307</td>\n",
       "      <td>0.792320</td>\n",
       "      <td>0.707477</td>\n",
       "      <td>0.808142</td>\n",
       "      <td>0.26683</td>\n",
       "      <td>0.730765</td>\n",
       "      <td>0.679032</td>\n",
       "      <td>0.694161</td>\n",
       "      <td>0.778776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.728072</td>\n",
       "      <td>0.765047</td>\n",
       "      <td>0.752790</td>\n",
       "      <td>0.772938</td>\n",
       "      <td>0.781615</td>\n",
       "      <td>0.741764</td>\n",
       "      <td>0.26683</td>\n",
       "      <td>0.755047</td>\n",
       "      <td>0.761439</td>\n",
       "      <td>0.714869</td>\n",
       "      <td>0.769832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.709167</td>\n",
       "      <td>0.756039</td>\n",
       "      <td>0.758331</td>\n",
       "      <td>0.763731</td>\n",
       "      <td>0.743737</td>\n",
       "      <td>0.724602</td>\n",
       "      <td>0.26683</td>\n",
       "      <td>0.677728</td>\n",
       "      <td>0.745735</td>\n",
       "      <td>0.739342</td>\n",
       "      <td>0.748602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.793669</td>\n",
       "      <td>0.775214</td>\n",
       "      <td>0.769498</td>\n",
       "      <td>0.778776</td>\n",
       "      <td>0.710619</td>\n",
       "      <td>0.778776</td>\n",
       "      <td>0.26683</td>\n",
       "      <td>0.747268</td>\n",
       "      <td>0.684856</td>\n",
       "      <td>0.746620</td>\n",
       "      <td>0.741764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.759337</td>\n",
       "      <td>0.805864</td>\n",
       "      <td>0.772938</td>\n",
       "      <td>0.827894</td>\n",
       "      <td>0.782220</td>\n",
       "      <td>0.815778</td>\n",
       "      <td>0.26683</td>\n",
       "      <td>0.828437</td>\n",
       "      <td>0.758331</td>\n",
       "      <td>0.712280</td>\n",
       "      <td>0.807917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.696254</td>\n",
       "      <td>0.754237</td>\n",
       "      <td>0.743737</td>\n",
       "      <td>0.745280</td>\n",
       "      <td>0.691704</td>\n",
       "      <td>0.713205</td>\n",
       "      <td>0.26683</td>\n",
       "      <td>0.714263</td>\n",
       "      <td>0.777788</td>\n",
       "      <td>0.724649</td>\n",
       "      <td>0.759337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.837212    0.794898  0.783234          0.792320       0.723093   \n",
       "1            0.702424    0.753483  0.754904          0.765233       0.743350   \n",
       "2            0.784595    0.828437  0.841743          0.810038       0.696099   \n",
       "3            0.752790    0.825142  0.821465          0.832951       0.680855   \n",
       "4            0.694451    0.769853  0.765233          0.736120       0.742551   \n",
       "5            0.678692    0.739342  0.766860          0.803339       0.687221   \n",
       "6            0.702424    0.753483  0.754904          0.765233       0.743350   \n",
       "7            0.749319    0.783234  0.783307          0.792320       0.707477   \n",
       "8            0.728072    0.765047  0.752790          0.772938       0.781615   \n",
       "9            0.709167    0.756039  0.758331          0.763731       0.743737   \n",
       "10           0.793669    0.775214  0.769498          0.778776       0.710619   \n",
       "11           0.759337    0.805864  0.772938          0.827894       0.782220   \n",
       "12           0.696254    0.754237  0.743737          0.745280       0.691704   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.848885     0.26683  0.778776     0.696254  0.686030  0.821465  \n",
       "1        0.723399     0.26683  0.759337     0.707123  0.798873  0.753483  \n",
       "2        0.786285     0.26683  0.759337     0.696254  0.743737  0.780813  \n",
       "3        0.732134     0.26683  0.758331     0.691771  0.757720  0.739818  \n",
       "4        0.741878     0.26683  0.695234     0.736262  0.660905  0.768887  \n",
       "5        0.710579     0.26683  0.710579     0.654500  0.694127  0.730765  \n",
       "6        0.722532     0.26683  0.759337     0.707123  0.768331  0.753483  \n",
       "7        0.808142     0.26683  0.730765     0.679032  0.694161  0.778776  \n",
       "8        0.741764     0.26683  0.755047     0.761439  0.714869  0.769832  \n",
       "9        0.724602     0.26683  0.677728     0.745735  0.739342  0.748602  \n",
       "10       0.778776     0.26683  0.747268     0.684856  0.746620  0.741764  \n",
       "11       0.815778     0.26683  0.828437     0.758331  0.712280  0.807917  \n",
       "12       0.713205     0.26683  0.714263     0.777788  0.724649  0.759337  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Recall Score ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.668874</td>\n",
       "      <td>0.615894</td>\n",
       "      <td>0.821192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.668874</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.748344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.655629</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.668874</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.774834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.668874</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.735099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.629139</td>\n",
       "      <td>0.768212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.668874</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.642384</td>\n",
       "      <td>0.635762</td>\n",
       "      <td>0.715232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.668874</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.748344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.649007</td>\n",
       "      <td>0.596026</td>\n",
       "      <td>0.774834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.635762</td>\n",
       "      <td>0.768212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.748344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.655629</td>\n",
       "      <td>0.662252</td>\n",
       "      <td>0.741722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.682119</td>\n",
       "      <td>0.807947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.668874</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.642384</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.754967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.821192    0.794702  0.781457          0.788079       0.688742   \n",
       "1            0.695364    0.748344  0.754967          0.761589       0.741722   \n",
       "2            0.768212    0.827815  0.841060          0.807947       0.655629   \n",
       "3            0.741722    0.821192  0.821192          0.827815       0.675497   \n",
       "4            0.688742    0.735099  0.761589          0.728477       0.735099   \n",
       "5            0.668874    0.701987  0.754967          0.781457       0.675497   \n",
       "6            0.695364    0.748344  0.754967          0.761589       0.741722   \n",
       "7            0.728477    0.781457  0.774834          0.788079       0.695364   \n",
       "8            0.721854    0.748344  0.741722          0.768212       0.781457   \n",
       "9            0.708609    0.741722  0.748344          0.761589       0.715232   \n",
       "10           0.768212    0.774834  0.761589          0.774834       0.695364   \n",
       "11           0.754967    0.801325  0.768212          0.827815       0.781457   \n",
       "12           0.668874    0.721854  0.715232          0.728477       0.642384   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.847682    0.516556  0.774834     0.668874  0.615894  0.821192  \n",
       "1        0.721854    0.516556  0.754967     0.668874  0.781457  0.748344  \n",
       "2        0.774834    0.516556  0.754967     0.668874  0.715232  0.774834  \n",
       "3        0.728477    0.516556  0.748344     0.668874  0.695364  0.735099  \n",
       "4        0.741722    0.516556  0.695364     0.721854  0.629139  0.768212  \n",
       "5        0.701987    0.516556  0.701987     0.642384  0.635762  0.715232  \n",
       "6        0.721854    0.516556  0.754967     0.668874  0.768212  0.748344  \n",
       "7        0.801325    0.516556  0.715232     0.649007  0.596026  0.774834  \n",
       "8        0.741722    0.516556  0.754967     0.748344  0.635762  0.768212  \n",
       "9        0.721854    0.516556  0.675497     0.741722  0.701987  0.748344  \n",
       "10       0.774834    0.516556  0.735099     0.655629  0.662252  0.741722  \n",
       "11       0.814570    0.516556  0.827815     0.748344  0.682119  0.807947  \n",
       "12       0.701987    0.516556  0.708609     0.768212  0.715232  0.754967  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Matriz confusao ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[51, 22], [5, 73]]</td>\n",
       "      <td>[[56, 17], [14, 64]]</td>\n",
       "      <td>[[53, 20], [13, 65]]</td>\n",
       "      <td>[[52, 21], [11, 67]]</td>\n",
       "      <td>[[34, 39], [8, 70]]</td>\n",
       "      <td>[[59, 14], [9, 69]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[51, 22], [12, 66]]</td>\n",
       "      <td>[[33, 40], [10, 68]]</td>\n",
       "      <td>[[20, 53], [5, 73]]</td>\n",
       "      <td>[[58, 15], [12, 66]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[42, 31], [15, 63]]</td>\n",
       "      <td>[[48, 25], [13, 65]]</td>\n",
       "      <td>[[54, 19], [18, 60]]</td>\n",
       "      <td>[[50, 23], [13, 65]]</td>\n",
       "      <td>[[56, 17], [22, 56]]</td>\n",
       "      <td>[[48, 25], [17, 61]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[49, 24], [13, 65]]</td>\n",
       "      <td>[[31, 42], [8, 70]]</td>\n",
       "      <td>[[47, 26], [7, 71]]</td>\n",
       "      <td>[[48, 25], [13, 65]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[46, 27], [8, 70]]</td>\n",
       "      <td>[[58, 15], [11, 67]]</td>\n",
       "      <td>[[59, 14], [10, 68]]</td>\n",
       "      <td>[[55, 18], [11, 67]]</td>\n",
       "      <td>[[29, 44], [8, 70]]</td>\n",
       "      <td>[[48, 25], [9, 69]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[49, 24], [13, 65]]</td>\n",
       "      <td>[[33, 40], [10, 68]]</td>\n",
       "      <td>[[38, 35], [8, 70]]</td>\n",
       "      <td>[[50, 23], [11, 67]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[45, 28], [11, 67]]</td>\n",
       "      <td>[[55, 18], [9, 69]]</td>\n",
       "      <td>[[58, 15], [12, 66]]</td>\n",
       "      <td>[[55, 18], [8, 70]]</td>\n",
       "      <td>[[54, 19], [30, 48]]</td>\n",
       "      <td>[[47, 26], [15, 63]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[46, 27], [11, 67]]</td>\n",
       "      <td>[[34, 39], [11, 67]]</td>\n",
       "      <td>[[31, 42], [4, 74]]</td>\n",
       "      <td>[[47, 26], [14, 64]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[42, 31], [16, 62]]</td>\n",
       "      <td>[[39, 34], [6, 72]]</td>\n",
       "      <td>[[50, 23], [13, 65]]</td>\n",
       "      <td>[[45, 28], [13, 65]]</td>\n",
       "      <td>[[59, 14], [26, 52]]</td>\n",
       "      <td>[[54, 19], [20, 58]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[49, 24], [22, 56]]</td>\n",
       "      <td>[[42, 31], [11, 67]]</td>\n",
       "      <td>[[27, 46], [10, 68]]</td>\n",
       "      <td>[[53, 20], [15, 63]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[[38, 35], [15, 63]]</td>\n",
       "      <td>[[35, 38], [7, 71]]</td>\n",
       "      <td>[[46, 27], [10, 68]]</td>\n",
       "      <td>[[46, 27], [6, 72]]</td>\n",
       "      <td>[[38, 35], [14, 64]]</td>\n",
       "      <td>[[42, 31], [14, 64]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[42, 31], [14, 64]]</td>\n",
       "      <td>[[34, 39], [15, 63]]</td>\n",
       "      <td>[[24, 49], [6, 72]]</td>\n",
       "      <td>[[41, 32], [11, 67]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[[42, 31], [15, 63]]</td>\n",
       "      <td>[[48, 25], [13, 65]]</td>\n",
       "      <td>[[54, 19], [18, 60]]</td>\n",
       "      <td>[[50, 23], [13, 65]]</td>\n",
       "      <td>[[56, 17], [22, 56]]</td>\n",
       "      <td>[[49, 24], [18, 60]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[49, 24], [13, 65]]</td>\n",
       "      <td>[[31, 42], [8, 70]]</td>\n",
       "      <td>[[54, 19], [16, 62]]</td>\n",
       "      <td>[[48, 25], [13, 65]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[[41, 32], [9, 69]]</td>\n",
       "      <td>[[53, 20], [13, 65]]</td>\n",
       "      <td>[[49, 24], [10, 68]]</td>\n",
       "      <td>[[52, 21], [11, 67]]</td>\n",
       "      <td>[[40, 33], [13, 65]]</td>\n",
       "      <td>[[52, 21], [9, 69]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[41, 32], [11, 67]]</td>\n",
       "      <td>[[30, 43], [10, 68]]</td>\n",
       "      <td>[[15, 58], [3, 75]]</td>\n",
       "      <td>[[51, 22], [12, 66]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[[45, 28], [14, 64]]</td>\n",
       "      <td>[[44, 29], [9, 69]]</td>\n",
       "      <td>[[45, 28], [11, 67]]</td>\n",
       "      <td>[[50, 23], [12, 66]]</td>\n",
       "      <td>[[55, 18], [15, 63]]</td>\n",
       "      <td>[[52, 21], [18, 60]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[53, 20], [17, 61]]</td>\n",
       "      <td>[[45, 28], [10, 68]]</td>\n",
       "      <td>[[22, 51], [4, 74]]</td>\n",
       "      <td>[[52, 21], [14, 64]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[[48, 25], [19, 59]]</td>\n",
       "      <td>[[44, 29], [10, 68]]</td>\n",
       "      <td>[[46, 27], [11, 67]]</td>\n",
       "      <td>[[51, 22], [14, 64]]</td>\n",
       "      <td>[[38, 35], [8, 70]]</td>\n",
       "      <td>[[47, 26], [16, 62]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[43, 30], [19, 59]]</td>\n",
       "      <td>[[48, 25], [14, 64]]</td>\n",
       "      <td>[[35, 38], [7, 71]]</td>\n",
       "      <td>[[52, 21], [17, 61]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[[44, 29], [6, 72]]</td>\n",
       "      <td>[[54, 19], [15, 63]]</td>\n",
       "      <td>[[48, 25], [11, 67]]</td>\n",
       "      <td>[[51, 22], [12, 66]]</td>\n",
       "      <td>[[39, 34], [12, 66]]</td>\n",
       "      <td>[[51, 22], [12, 66]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[44, 29], [11, 67]]</td>\n",
       "      <td>[[31, 42], [10, 68]]</td>\n",
       "      <td>[[25, 48], [3, 75]]</td>\n",
       "      <td>[[52, 21], [18, 60]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[[49, 24], [13, 65]]</td>\n",
       "      <td>[[53, 20], [10, 68]]</td>\n",
       "      <td>[[50, 23], [12, 66]]</td>\n",
       "      <td>[[59, 14], [12, 66]]</td>\n",
       "      <td>[[54, 19], [14, 64]]</td>\n",
       "      <td>[[61, 12], [16, 62]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[58, 15], [11, 67]]</td>\n",
       "      <td>[[46, 27], [11, 67]]</td>\n",
       "      <td>[[34, 39], [9, 69]]</td>\n",
       "      <td>[[58, 15], [14, 64]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[[33, 40], [10, 68]]</td>\n",
       "      <td>[[38, 35], [7, 71]]</td>\n",
       "      <td>[[38, 35], [8, 70]]</td>\n",
       "      <td>[[42, 31], [10, 68]]</td>\n",
       "      <td>[[26, 47], [7, 71]]</td>\n",
       "      <td>[[41, 32], [13, 65]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[44, 29], [15, 63]]</td>\n",
       "      <td>[[48, 25], [10, 68]]</td>\n",
       "      <td>[[43, 30], [13, 65]]</td>\n",
       "      <td>[[49, 24], [13, 65]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Nearest Neighbors            Linear SVM               RBF SVM  \\\n",
       "0    [[51, 22], [5, 73]]  [[56, 17], [14, 64]]  [[53, 20], [13, 65]]   \n",
       "1   [[42, 31], [15, 63]]  [[48, 25], [13, 65]]  [[54, 19], [18, 60]]   \n",
       "2    [[46, 27], [8, 70]]  [[58, 15], [11, 67]]  [[59, 14], [10, 68]]   \n",
       "3   [[45, 28], [11, 67]]   [[55, 18], [9, 69]]  [[58, 15], [12, 66]]   \n",
       "4   [[42, 31], [16, 62]]   [[39, 34], [6, 72]]  [[50, 23], [13, 65]]   \n",
       "5   [[38, 35], [15, 63]]   [[35, 38], [7, 71]]  [[46, 27], [10, 68]]   \n",
       "6   [[42, 31], [15, 63]]  [[48, 25], [13, 65]]  [[54, 19], [18, 60]]   \n",
       "7    [[41, 32], [9, 69]]  [[53, 20], [13, 65]]  [[49, 24], [10, 68]]   \n",
       "8   [[45, 28], [14, 64]]   [[44, 29], [9, 69]]  [[45, 28], [11, 67]]   \n",
       "9   [[48, 25], [19, 59]]  [[44, 29], [10, 68]]  [[46, 27], [11, 67]]   \n",
       "10   [[44, 29], [6, 72]]  [[54, 19], [15, 63]]  [[48, 25], [11, 67]]   \n",
       "11  [[49, 24], [13, 65]]  [[53, 20], [10, 68]]  [[50, 23], [12, 66]]   \n",
       "12  [[33, 40], [10, 68]]   [[38, 35], [7, 71]]   [[38, 35], [8, 70]]   \n",
       "\n",
       "        Gaussian Process         Decision Tree         Random Forest  \\\n",
       "0   [[52, 21], [11, 67]]   [[34, 39], [8, 70]]   [[59, 14], [9, 69]]   \n",
       "1   [[50, 23], [13, 65]]  [[56, 17], [22, 56]]  [[48, 25], [17, 61]]   \n",
       "2   [[55, 18], [11, 67]]   [[29, 44], [8, 70]]   [[48, 25], [9, 69]]   \n",
       "3    [[55, 18], [8, 70]]  [[54, 19], [30, 48]]  [[47, 26], [15, 63]]   \n",
       "4   [[45, 28], [13, 65]]  [[59, 14], [26, 52]]  [[54, 19], [20, 58]]   \n",
       "5    [[46, 27], [6, 72]]  [[38, 35], [14, 64]]  [[42, 31], [14, 64]]   \n",
       "6   [[50, 23], [13, 65]]  [[56, 17], [22, 56]]  [[49, 24], [18, 60]]   \n",
       "7   [[52, 21], [11, 67]]  [[40, 33], [13, 65]]   [[52, 21], [9, 69]]   \n",
       "8   [[50, 23], [12, 66]]  [[55, 18], [15, 63]]  [[52, 21], [18, 60]]   \n",
       "9   [[51, 22], [14, 64]]   [[38, 35], [8, 70]]  [[47, 26], [16, 62]]   \n",
       "10  [[51, 22], [12, 66]]  [[39, 34], [12, 66]]  [[51, 22], [12, 66]]   \n",
       "11  [[59, 14], [12, 66]]  [[54, 19], [14, 64]]  [[61, 12], [16, 62]]   \n",
       "12  [[42, 31], [10, 68]]   [[26, 47], [7, 71]]  [[41, 32], [13, 65]]   \n",
       "\n",
       "            Neural Net              AdaBoost           Naive Bayes  \\\n",
       "0   [[0, 73], [0, 78]]  [[51, 22], [12, 66]]  [[33, 40], [10, 68]]   \n",
       "1   [[0, 73], [0, 78]]  [[49, 24], [13, 65]]   [[31, 42], [8, 70]]   \n",
       "2   [[0, 73], [0, 78]]  [[49, 24], [13, 65]]  [[33, 40], [10, 68]]   \n",
       "3   [[0, 73], [0, 78]]  [[46, 27], [11, 67]]  [[34, 39], [11, 67]]   \n",
       "4   [[0, 73], [0, 78]]  [[49, 24], [22, 56]]  [[42, 31], [11, 67]]   \n",
       "5   [[0, 73], [0, 78]]  [[42, 31], [14, 64]]  [[34, 39], [15, 63]]   \n",
       "6   [[0, 73], [0, 78]]  [[49, 24], [13, 65]]   [[31, 42], [8, 70]]   \n",
       "7   [[0, 73], [0, 78]]  [[41, 32], [11, 67]]  [[30, 43], [10, 68]]   \n",
       "8   [[0, 73], [0, 78]]  [[53, 20], [17, 61]]  [[45, 28], [10, 68]]   \n",
       "9   [[0, 73], [0, 78]]  [[43, 30], [19, 59]]  [[48, 25], [14, 64]]   \n",
       "10  [[0, 73], [0, 78]]  [[44, 29], [11, 67]]  [[31, 42], [10, 68]]   \n",
       "11  [[0, 73], [0, 78]]  [[58, 15], [11, 67]]  [[46, 27], [11, 67]]   \n",
       "12  [[0, 73], [0, 78]]  [[44, 29], [15, 63]]  [[48, 25], [10, 68]]   \n",
       "\n",
       "                     QDA               XGBoost  \n",
       "0    [[20, 53], [5, 73]]  [[58, 15], [12, 66]]  \n",
       "1    [[47, 26], [7, 71]]  [[48, 25], [13, 65]]  \n",
       "2    [[38, 35], [8, 70]]  [[50, 23], [11, 67]]  \n",
       "3    [[31, 42], [4, 74]]  [[47, 26], [14, 64]]  \n",
       "4   [[27, 46], [10, 68]]  [[53, 20], [15, 63]]  \n",
       "5    [[24, 49], [6, 72]]  [[41, 32], [11, 67]]  \n",
       "6   [[54, 19], [16, 62]]  [[48, 25], [13, 65]]  \n",
       "7    [[15, 58], [3, 75]]  [[51, 22], [12, 66]]  \n",
       "8    [[22, 51], [4, 74]]  [[52, 21], [14, 64]]  \n",
       "9    [[35, 38], [7, 71]]  [[52, 21], [17, 61]]  \n",
       "10   [[25, 48], [3, 75]]  [[52, 21], [18, 60]]  \n",
       "11   [[34, 39], [9, 69]]  [[58, 15], [14, 64]]  \n",
       "12  [[43, 30], [13, 65]]  [[49, 24], [13, 65]]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ 12 pontos - 2 raio ------\n",
      "--- Acuracia ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.682119</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.821192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.682119</td>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.523179</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.629139</td>\n",
       "      <td>0.794702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.801325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.754967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.622517</td>\n",
       "      <td>0.768212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.662252</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.662252</td>\n",
       "      <td>0.748344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.682119</td>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.529801</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.622517</td>\n",
       "      <td>0.794702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.662252</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.814570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.794702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.682119</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.741722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.655629</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.821192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.523179</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.801325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.642384</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.774834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.847682    0.807947  0.814570          0.821192       0.748344   \n",
       "1            0.682119    0.675497  0.774834          0.768212       0.741722   \n",
       "2            0.781457    0.821192  0.827815          0.834437       0.794702   \n",
       "3            0.688742    0.788079  0.841060          0.854305       0.774834   \n",
       "4            0.708609    0.695364  0.715232          0.708609       0.721854   \n",
       "5            0.662252    0.721854  0.768212          0.701987       0.748344   \n",
       "6            0.682119    0.675497  0.774834          0.768212       0.741722   \n",
       "7            0.807947    0.774834  0.841060          0.827815       0.721854   \n",
       "8            0.688742    0.735099  0.768212          0.801325       0.688742   \n",
       "9            0.748344    0.748344  0.735099          0.788079       0.728477   \n",
       "10           0.794702    0.774834  0.827815          0.821192       0.735099   \n",
       "11           0.735099    0.774834  0.788079          0.821192       0.801325   \n",
       "12           0.675497    0.735099  0.728477          0.721854       0.642384   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.827815    0.516556  0.854305     0.682119  0.854305  0.821192  \n",
       "1        0.788079    0.523179  0.788079     0.675497  0.629139  0.794702  \n",
       "2        0.847682    0.516556  0.827815     0.695364  0.788079  0.801325  \n",
       "3        0.761589    0.516556  0.748344     0.675497  0.754967  0.754967  \n",
       "4        0.735099    0.516556  0.701987     0.748344  0.622517  0.768212  \n",
       "5        0.735099    0.516556  0.781457     0.688742  0.662252  0.748344  \n",
       "6        0.794702    0.529801  0.788079     0.675497  0.622517  0.794702  \n",
       "7        0.827815    0.516556  0.754967     0.662252  0.728477  0.814570  \n",
       "8        0.788079    0.516556  0.728477     0.761589  0.768212  0.794702  \n",
       "9        0.682119    0.516556  0.708609     0.748344  0.748344  0.741722  \n",
       "10       0.827815    0.516556  0.814570     0.655629  0.794702  0.821192  \n",
       "11       0.807947    0.523179  0.768212     0.768212  0.801325  0.801325  \n",
       "12       0.774834    0.516556  0.754967     0.788079  0.768212  0.774834  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- F1 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.847642</td>\n",
       "      <td>0.806877</td>\n",
       "      <td>0.814030</td>\n",
       "      <td>0.820529</td>\n",
       "      <td>0.748389</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.854215</td>\n",
       "      <td>0.668591</td>\n",
       "      <td>0.853337</td>\n",
       "      <td>0.821145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.677342</td>\n",
       "      <td>0.664384</td>\n",
       "      <td>0.773800</td>\n",
       "      <td>0.767701</td>\n",
       "      <td>0.741790</td>\n",
       "      <td>0.787463</td>\n",
       "      <td>0.366499</td>\n",
       "      <td>0.787949</td>\n",
       "      <td>0.658657</td>\n",
       "      <td>0.589944</td>\n",
       "      <td>0.794648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.778530</td>\n",
       "      <td>0.820195</td>\n",
       "      <td>0.827023</td>\n",
       "      <td>0.833514</td>\n",
       "      <td>0.794485</td>\n",
       "      <td>0.846493</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.826254</td>\n",
       "      <td>0.684122</td>\n",
       "      <td>0.787949</td>\n",
       "      <td>0.799524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.683525</td>\n",
       "      <td>0.784895</td>\n",
       "      <td>0.839619</td>\n",
       "      <td>0.853635</td>\n",
       "      <td>0.770259</td>\n",
       "      <td>0.758763</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.745361</td>\n",
       "      <td>0.664384</td>\n",
       "      <td>0.746576</td>\n",
       "      <td>0.753601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.705969</td>\n",
       "      <td>0.674074</td>\n",
       "      <td>0.709389</td>\n",
       "      <td>0.704231</td>\n",
       "      <td>0.716684</td>\n",
       "      <td>0.734328</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.701330</td>\n",
       "      <td>0.745361</td>\n",
       "      <td>0.580679</td>\n",
       "      <td>0.766920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.644724</td>\n",
       "      <td>0.706488</td>\n",
       "      <td>0.765108</td>\n",
       "      <td>0.690163</td>\n",
       "      <td>0.747946</td>\n",
       "      <td>0.733339</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.778530</td>\n",
       "      <td>0.679637</td>\n",
       "      <td>0.637302</td>\n",
       "      <td>0.746064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.677342</td>\n",
       "      <td>0.664384</td>\n",
       "      <td>0.773800</td>\n",
       "      <td>0.767701</td>\n",
       "      <td>0.741790</td>\n",
       "      <td>0.794250</td>\n",
       "      <td>0.391225</td>\n",
       "      <td>0.787949</td>\n",
       "      <td>0.658657</td>\n",
       "      <td>0.580679</td>\n",
       "      <td>0.794648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.806448</td>\n",
       "      <td>0.771451</td>\n",
       "      <td>0.840597</td>\n",
       "      <td>0.827314</td>\n",
       "      <td>0.715583</td>\n",
       "      <td>0.827314</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.753054</td>\n",
       "      <td>0.646866</td>\n",
       "      <td>0.714386</td>\n",
       "      <td>0.814276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.684573</td>\n",
       "      <td>0.726704</td>\n",
       "      <td>0.766920</td>\n",
       "      <td>0.800412</td>\n",
       "      <td>0.685501</td>\n",
       "      <td>0.787106</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.724841</td>\n",
       "      <td>0.758007</td>\n",
       "      <td>0.760274</td>\n",
       "      <td>0.794250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.747188</td>\n",
       "      <td>0.742670</td>\n",
       "      <td>0.729127</td>\n",
       "      <td>0.787949</td>\n",
       "      <td>0.728310</td>\n",
       "      <td>0.680658</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.708430</td>\n",
       "      <td>0.746672</td>\n",
       "      <td>0.743667</td>\n",
       "      <td>0.741767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.793558</td>\n",
       "      <td>0.772794</td>\n",
       "      <td>0.827542</td>\n",
       "      <td>0.820798</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.827542</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.814455</td>\n",
       "      <td>0.638870</td>\n",
       "      <td>0.790490</td>\n",
       "      <td>0.821145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.731959</td>\n",
       "      <td>0.773338</td>\n",
       "      <td>0.785567</td>\n",
       "      <td>0.821239</td>\n",
       "      <td>0.801202</td>\n",
       "      <td>0.807981</td>\n",
       "      <td>0.366499</td>\n",
       "      <td>0.766402</td>\n",
       "      <td>0.765108</td>\n",
       "      <td>0.801010</td>\n",
       "      <td>0.800746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.662622</td>\n",
       "      <td>0.723826</td>\n",
       "      <td>0.719179</td>\n",
       "      <td>0.714369</td>\n",
       "      <td>0.611401</td>\n",
       "      <td>0.774179</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.750860</td>\n",
       "      <td>0.786159</td>\n",
       "      <td>0.767353</td>\n",
       "      <td>0.772165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.847642    0.806877  0.814030          0.820529       0.748389   \n",
       "1            0.677342    0.664384  0.773800          0.767701       0.741790   \n",
       "2            0.778530    0.820195  0.827023          0.833514       0.794485   \n",
       "3            0.683525    0.784895  0.839619          0.853635       0.770259   \n",
       "4            0.705969    0.674074  0.709389          0.704231       0.716684   \n",
       "5            0.644724    0.706488  0.765108          0.690163       0.747946   \n",
       "6            0.677342    0.664384  0.773800          0.767701       0.741790   \n",
       "7            0.806448    0.771451  0.840597          0.827314       0.715583   \n",
       "8            0.684573    0.726704  0.766920          0.800412       0.685501   \n",
       "9            0.747188    0.742670  0.729127          0.787949       0.728310   \n",
       "10           0.793558    0.772794  0.827542          0.820798       0.735099   \n",
       "11           0.731959    0.773338  0.785567          0.821239       0.801202   \n",
       "12           0.662622    0.723826  0.719179          0.714369       0.611401   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.827815    0.351890  0.854215     0.668591  0.853337  0.821145  \n",
       "1        0.787463    0.366499  0.787949     0.658657  0.589944  0.794648  \n",
       "2        0.846493    0.351890  0.826254     0.684122  0.787949  0.799524  \n",
       "3        0.758763    0.351890  0.745361     0.664384  0.746576  0.753601  \n",
       "4        0.734328    0.351890  0.701330     0.745361  0.580679  0.766920  \n",
       "5        0.733339    0.351890  0.778530     0.679637  0.637302  0.746064  \n",
       "6        0.794250    0.391225  0.787949     0.658657  0.580679  0.794648  \n",
       "7        0.827314    0.351890  0.753054     0.646866  0.714386  0.814276  \n",
       "8        0.787106    0.351890  0.724841     0.758007  0.760274  0.794250  \n",
       "9        0.680658    0.351890  0.708430     0.746672  0.743667  0.741767  \n",
       "10       0.827542    0.351890  0.814455     0.638870  0.790490  0.821145  \n",
       "11       0.807981    0.366499  0.766402     0.765108  0.801010  0.800746  \n",
       "12       0.774179    0.351890  0.750860     0.786159  0.767353  0.772165  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Precision Score ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.847676</td>\n",
       "      <td>0.811651</td>\n",
       "      <td>0.816087</td>\n",
       "      <td>0.823440</td>\n",
       "      <td>0.749483</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.854426</td>\n",
       "      <td>0.707388</td>\n",
       "      <td>0.860038</td>\n",
       "      <td>0.821170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.688448</td>\n",
       "      <td>0.693580</td>\n",
       "      <td>0.777175</td>\n",
       "      <td>0.768887</td>\n",
       "      <td>0.742443</td>\n",
       "      <td>0.789357</td>\n",
       "      <td>0.752053</td>\n",
       "      <td>0.788096</td>\n",
       "      <td>0.706843</td>\n",
       "      <td>0.688274</td>\n",
       "      <td>0.794664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.791678</td>\n",
       "      <td>0.825142</td>\n",
       "      <td>0.830952</td>\n",
       "      <td>0.838633</td>\n",
       "      <td>0.794898</td>\n",
       "      <td>0.854547</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.835472</td>\n",
       "      <td>0.718332</td>\n",
       "      <td>0.788096</td>\n",
       "      <td>0.808142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.696508</td>\n",
       "      <td>0.800262</td>\n",
       "      <td>0.849137</td>\n",
       "      <td>0.857840</td>\n",
       "      <td>0.807636</td>\n",
       "      <td>0.769498</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.755689</td>\n",
       "      <td>0.693580</td>\n",
       "      <td>0.784101</td>\n",
       "      <td>0.757686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.712489</td>\n",
       "      <td>0.748891</td>\n",
       "      <td>0.727483</td>\n",
       "      <td>0.716401</td>\n",
       "      <td>0.733098</td>\n",
       "      <td>0.735897</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.702221</td>\n",
       "      <td>0.755689</td>\n",
       "      <td>0.682223</td>\n",
       "      <td>0.771177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.690593</td>\n",
       "      <td>0.767293</td>\n",
       "      <td>0.777788</td>\n",
       "      <td>0.728308</td>\n",
       "      <td>0.748602</td>\n",
       "      <td>0.738145</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.791678</td>\n",
       "      <td>0.704969</td>\n",
       "      <td>0.708358</td>\n",
       "      <td>0.753483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.688448</td>\n",
       "      <td>0.693580</td>\n",
       "      <td>0.777175</td>\n",
       "      <td>0.768887</td>\n",
       "      <td>0.742443</td>\n",
       "      <td>0.795553</td>\n",
       "      <td>0.633160</td>\n",
       "      <td>0.788096</td>\n",
       "      <td>0.706843</td>\n",
       "      <td>0.682223</td>\n",
       "      <td>0.794664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.813743</td>\n",
       "      <td>0.786285</td>\n",
       "      <td>0.842818</td>\n",
       "      <td>0.829453</td>\n",
       "      <td>0.736262</td>\n",
       "      <td>0.829453</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.759337</td>\n",
       "      <td>0.686034</td>\n",
       "      <td>0.771841</td>\n",
       "      <td>0.815131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.694451</td>\n",
       "      <td>0.759014</td>\n",
       "      <td>0.771177</td>\n",
       "      <td>0.804064</td>\n",
       "      <td>0.692731</td>\n",
       "      <td>0.790619</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.736120</td>\n",
       "      <td>0.772308</td>\n",
       "      <td>0.799188</td>\n",
       "      <td>0.795553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.750287</td>\n",
       "      <td>0.765047</td>\n",
       "      <td>0.750655</td>\n",
       "      <td>0.788096</td>\n",
       "      <td>0.731284</td>\n",
       "      <td>0.683067</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.708500</td>\n",
       "      <td>0.751689</td>\n",
       "      <td>0.761439</td>\n",
       "      <td>0.741878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.798160</td>\n",
       "      <td>0.780813</td>\n",
       "      <td>0.828437</td>\n",
       "      <td>0.822219</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.828437</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.814628</td>\n",
       "      <td>0.680228</td>\n",
       "      <td>0.813151</td>\n",
       "      <td>0.821170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.741880</td>\n",
       "      <td>0.778776</td>\n",
       "      <td>0.797115</td>\n",
       "      <td>0.821934</td>\n",
       "      <td>0.801362</td>\n",
       "      <td>0.808085</td>\n",
       "      <td>0.752053</td>\n",
       "      <td>0.772938</td>\n",
       "      <td>0.777788</td>\n",
       "      <td>0.801825</td>\n",
       "      <td>0.802722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.697450</td>\n",
       "      <td>0.769853</td>\n",
       "      <td>0.753927</td>\n",
       "      <td>0.739909</td>\n",
       "      <td>0.691704</td>\n",
       "      <td>0.775992</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.766860</td>\n",
       "      <td>0.794478</td>\n",
       "      <td>0.769832</td>\n",
       "      <td>0.783307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.847676    0.811651  0.816087          0.823440       0.749483   \n",
       "1            0.688448    0.693580  0.777175          0.768887       0.742443   \n",
       "2            0.791678    0.825142  0.830952          0.838633       0.794898   \n",
       "3            0.696508    0.800262  0.849137          0.857840       0.807636   \n",
       "4            0.712489    0.748891  0.727483          0.716401       0.733098   \n",
       "5            0.690593    0.767293  0.777788          0.728308       0.748602   \n",
       "6            0.688448    0.693580  0.777175          0.768887       0.742443   \n",
       "7            0.813743    0.786285  0.842818          0.829453       0.736262   \n",
       "8            0.694451    0.759014  0.771177          0.804064       0.692731   \n",
       "9            0.750287    0.765047  0.750655          0.788096       0.731284   \n",
       "10           0.798160    0.780813  0.828437          0.822219       0.735099   \n",
       "11           0.741880    0.778776  0.797115          0.821934       0.801362   \n",
       "12           0.697450    0.769853  0.753927          0.739909       0.691704   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.827815    0.266830  0.854426     0.707388  0.860038  0.821170  \n",
       "1        0.789357    0.752053  0.788096     0.706843  0.688274  0.794664  \n",
       "2        0.854547    0.266830  0.835472     0.718332  0.788096  0.808142  \n",
       "3        0.769498    0.266830  0.755689     0.693580  0.784101  0.757686  \n",
       "4        0.735897    0.266830  0.702221     0.755689  0.682223  0.771177  \n",
       "5        0.738145    0.266830  0.791678     0.704969  0.708358  0.753483  \n",
       "6        0.795553    0.633160  0.788096     0.706843  0.682223  0.794664  \n",
       "7        0.829453    0.266830  0.759337     0.686034  0.771841  0.815131  \n",
       "8        0.790619    0.266830  0.736120     0.772308  0.799188  0.795553  \n",
       "9        0.683067    0.266830  0.708500     0.751689  0.761439  0.741878  \n",
       "10       0.828437    0.266830  0.814628     0.680228  0.813151  0.821170  \n",
       "11       0.808085    0.752053  0.772938     0.777788  0.801825  0.802722  \n",
       "12       0.775992    0.266830  0.766860     0.794478  0.769832  0.783307  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Recall Score ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.682119</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.821192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.682119</td>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.523179</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.629139</td>\n",
       "      <td>0.794702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.801325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.754967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.622517</td>\n",
       "      <td>0.768212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.662252</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.662252</td>\n",
       "      <td>0.748344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.682119</td>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.529801</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.622517</td>\n",
       "      <td>0.794702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.662252</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.814570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.794702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.682119</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.741722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.655629</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.821192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.523179</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.801325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.642384</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.774834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.847682    0.807947  0.814570          0.821192       0.748344   \n",
       "1            0.682119    0.675497  0.774834          0.768212       0.741722   \n",
       "2            0.781457    0.821192  0.827815          0.834437       0.794702   \n",
       "3            0.688742    0.788079  0.841060          0.854305       0.774834   \n",
       "4            0.708609    0.695364  0.715232          0.708609       0.721854   \n",
       "5            0.662252    0.721854  0.768212          0.701987       0.748344   \n",
       "6            0.682119    0.675497  0.774834          0.768212       0.741722   \n",
       "7            0.807947    0.774834  0.841060          0.827815       0.721854   \n",
       "8            0.688742    0.735099  0.768212          0.801325       0.688742   \n",
       "9            0.748344    0.748344  0.735099          0.788079       0.728477   \n",
       "10           0.794702    0.774834  0.827815          0.821192       0.735099   \n",
       "11           0.735099    0.774834  0.788079          0.821192       0.801325   \n",
       "12           0.675497    0.735099  0.728477          0.721854       0.642384   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.827815    0.516556  0.854305     0.682119  0.854305  0.821192  \n",
       "1        0.788079    0.523179  0.788079     0.675497  0.629139  0.794702  \n",
       "2        0.847682    0.516556  0.827815     0.695364  0.788079  0.801325  \n",
       "3        0.761589    0.516556  0.748344     0.675497  0.754967  0.754967  \n",
       "4        0.735099    0.516556  0.701987     0.748344  0.622517  0.768212  \n",
       "5        0.735099    0.516556  0.781457     0.688742  0.662252  0.748344  \n",
       "6        0.794702    0.529801  0.788079     0.675497  0.622517  0.794702  \n",
       "7        0.827815    0.516556  0.754967     0.662252  0.728477  0.814570  \n",
       "8        0.788079    0.516556  0.728477     0.761589  0.768212  0.794702  \n",
       "9        0.682119    0.516556  0.708609     0.748344  0.748344  0.741722  \n",
       "10       0.827815    0.516556  0.814570     0.655629  0.794702  0.821192  \n",
       "11       0.807947    0.523179  0.768212     0.768212  0.801325  0.801325  \n",
       "12       0.774834    0.516556  0.754967     0.788079  0.768212  0.774834  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Matriz confusao ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[61, 12], [11, 67]]</td>\n",
       "      <td>[[54, 19], [10, 68]]</td>\n",
       "      <td>[[56, 17], [11, 67]]</td>\n",
       "      <td>[[56, 17], [10, 68]]</td>\n",
       "      <td>[[56, 17], [21, 57]]</td>\n",
       "      <td>[[60, 13], [13, 65]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[61, 12], [10, 68]]</td>\n",
       "      <td>[[35, 38], [10, 68]]</td>\n",
       "      <td>[[57, 16], [6, 72]]</td>\n",
       "      <td>[[59, 14], [13, 65]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[41, 32], [16, 62]]</td>\n",
       "      <td>[[36, 37], [12, 66]]</td>\n",
       "      <td>[[52, 21], [13, 65]]</td>\n",
       "      <td>[[53, 20], [15, 63]]</td>\n",
       "      <td>[[55, 18], [21, 57]]</td>\n",
       "      <td>[[54, 19], [13, 65]]</td>\n",
       "      <td>[[1, 72], [0, 78]]</td>\n",
       "      <td>[[56, 17], [15, 63]]</td>\n",
       "      <td>[[33, 40], [9, 69]]</td>\n",
       "      <td>[[23, 50], [6, 72]]</td>\n",
       "      <td>[[57, 16], [15, 63]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[49, 24], [9, 69]]</td>\n",
       "      <td>[[55, 18], [9, 69]]</td>\n",
       "      <td>[[56, 17], [9, 69]]</td>\n",
       "      <td>[[56, 17], [8, 70]]</td>\n",
       "      <td>[[56, 17], [14, 64]]</td>\n",
       "      <td>[[56, 17], [6, 72]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[54, 19], [7, 71]]</td>\n",
       "      <td>[[37, 36], [10, 68]]</td>\n",
       "      <td>[[56, 17], [15, 63]]</td>\n",
       "      <td>[[52, 21], [9, 69]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[41, 32], [15, 63]]</td>\n",
       "      <td>[[49, 24], [8, 70]]</td>\n",
       "      <td>[[55, 18], [6, 72]]</td>\n",
       "      <td>[[58, 15], [7, 71]]</td>\n",
       "      <td>[[68, 5], [29, 49]]</td>\n",
       "      <td>[[48, 25], [11, 67]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[47, 26], [12, 66]]</td>\n",
       "      <td>[[36, 37], [12, 66]]</td>\n",
       "      <td>[[42, 31], [6, 72]]</td>\n",
       "      <td>[[50, 23], [14, 64]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[45, 28], [16, 62]]</td>\n",
       "      <td>[[32, 41], [5, 73]]</td>\n",
       "      <td>[[42, 31], [12, 66]]</td>\n",
       "      <td>[[43, 30], [14, 64]]</td>\n",
       "      <td>[[43, 30], [12, 66]]</td>\n",
       "      <td>[[50, 23], [17, 61]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[48, 25], [20, 58]]</td>\n",
       "      <td>[[47, 26], [12, 66]]</td>\n",
       "      <td>[[22, 51], [6, 72]]</td>\n",
       "      <td>[[51, 22], [13, 65]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[[32, 41], [10, 68]]</td>\n",
       "      <td>[[36, 37], [5, 73]]</td>\n",
       "      <td>[[48, 25], [10, 68]]</td>\n",
       "      <td>[[37, 36], [9, 69]]</td>\n",
       "      <td>[[52, 21], [17, 61]]</td>\n",
       "      <td>[[48, 25], [15, 63]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[49, 24], [9, 69]]</td>\n",
       "      <td>[[38, 35], [12, 66]]</td>\n",
       "      <td>[[29, 44], [7, 71]]</td>\n",
       "      <td>[[48, 25], [13, 65]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[[41, 32], [16, 62]]</td>\n",
       "      <td>[[36, 37], [12, 66]]</td>\n",
       "      <td>[[52, 21], [13, 65]]</td>\n",
       "      <td>[[53, 20], [15, 63]]</td>\n",
       "      <td>[[55, 18], [21, 57]]</td>\n",
       "      <td>[[55, 18], [13, 65]]</td>\n",
       "      <td>[[3, 70], [1, 77]]</td>\n",
       "      <td>[[56, 17], [15, 63]]</td>\n",
       "      <td>[[33, 40], [9, 69]]</td>\n",
       "      <td>[[22, 51], [6, 72]]</td>\n",
       "      <td>[[57, 16], [15, 63]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[[53, 20], [9, 69]]</td>\n",
       "      <td>[[48, 25], [9, 69]]</td>\n",
       "      <td>[[58, 15], [9, 69]]</td>\n",
       "      <td>[[57, 16], [10, 68]]</td>\n",
       "      <td>[[42, 31], [11, 67]]</td>\n",
       "      <td>[[57, 16], [10, 68]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[49, 24], [13, 65]]</td>\n",
       "      <td>[[33, 40], [11, 67]]</td>\n",
       "      <td>[[37, 36], [5, 73]]</td>\n",
       "      <td>[[57, 16], [12, 66]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[[42, 31], [16, 62]]</td>\n",
       "      <td>[[41, 32], [8, 70]]</td>\n",
       "      <td>[[51, 22], [13, 65]]</td>\n",
       "      <td>[[54, 19], [11, 67]]</td>\n",
       "      <td>[[43, 30], [17, 61]]</td>\n",
       "      <td>[[53, 20], [12, 66]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[45, 28], [13, 65]]</td>\n",
       "      <td>[[47, 26], [10, 68]]</td>\n",
       "      <td>[[43, 30], [5, 73]]</td>\n",
       "      <td>[[55, 18], [13, 65]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[[50, 23], [15, 63]]</td>\n",
       "      <td>[[44, 29], [9, 69]]</td>\n",
       "      <td>[[43, 30], [10, 68]]</td>\n",
       "      <td>[[56, 17], [15, 63]]</td>\n",
       "      <td>[[56, 17], [24, 54]]</td>\n",
       "      <td>[[45, 28], [20, 58]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[50, 23], [21, 57]]</td>\n",
       "      <td>[[49, 24], [14, 64]]</td>\n",
       "      <td>[[45, 28], [10, 68]]</td>\n",
       "      <td>[[54, 19], [20, 58]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[[53, 20], [11, 67]]</td>\n",
       "      <td>[[50, 23], [11, 67]]</td>\n",
       "      <td>[[58, 15], [11, 67]]</td>\n",
       "      <td>[[57, 16], [11, 67]]</td>\n",
       "      <td>[[53, 20], [20, 58]]</td>\n",
       "      <td>[[58, 15], [11, 67]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[58, 15], [13, 65]]</td>\n",
       "      <td>[[32, 41], [11, 67]]</td>\n",
       "      <td>[[48, 25], [6, 72]]</td>\n",
       "      <td>[[59, 14], [13, 65]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[[46, 27], [13, 65]]</td>\n",
       "      <td>[[51, 22], [12, 66]]</td>\n",
       "      <td>[[50, 23], [9, 69]]</td>\n",
       "      <td>[[61, 12], [15, 63]]</td>\n",
       "      <td>[[57, 16], [14, 64]]</td>\n",
       "      <td>[[59, 14], [15, 63]]</td>\n",
       "      <td>[[1, 72], [0, 78]]</td>\n",
       "      <td>[[50, 23], [12, 66]]</td>\n",
       "      <td>[[48, 25], [10, 68]]</td>\n",
       "      <td>[[56, 17], [13, 65]]</td>\n",
       "      <td>[[55, 18], [12, 66]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[[35, 38], [11, 67]]</td>\n",
       "      <td>[[39, 34], [6, 72]]</td>\n",
       "      <td>[[40, 33], [8, 70]]</td>\n",
       "      <td>[[41, 32], [10, 68]]</td>\n",
       "      <td>[[26, 47], [7, 71]]</td>\n",
       "      <td>[[53, 20], [14, 64]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[46, 27], [10, 68]]</td>\n",
       "      <td>[[51, 22], [10, 68]]</td>\n",
       "      <td>[[52, 21], [14, 64]]</td>\n",
       "      <td>[[49, 24], [10, 68]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Nearest Neighbors            Linear SVM               RBF SVM  \\\n",
       "0   [[61, 12], [11, 67]]  [[54, 19], [10, 68]]  [[56, 17], [11, 67]]   \n",
       "1   [[41, 32], [16, 62]]  [[36, 37], [12, 66]]  [[52, 21], [13, 65]]   \n",
       "2    [[49, 24], [9, 69]]   [[55, 18], [9, 69]]   [[56, 17], [9, 69]]   \n",
       "3   [[41, 32], [15, 63]]   [[49, 24], [8, 70]]   [[55, 18], [6, 72]]   \n",
       "4   [[45, 28], [16, 62]]   [[32, 41], [5, 73]]  [[42, 31], [12, 66]]   \n",
       "5   [[32, 41], [10, 68]]   [[36, 37], [5, 73]]  [[48, 25], [10, 68]]   \n",
       "6   [[41, 32], [16, 62]]  [[36, 37], [12, 66]]  [[52, 21], [13, 65]]   \n",
       "7    [[53, 20], [9, 69]]   [[48, 25], [9, 69]]   [[58, 15], [9, 69]]   \n",
       "8   [[42, 31], [16, 62]]   [[41, 32], [8, 70]]  [[51, 22], [13, 65]]   \n",
       "9   [[50, 23], [15, 63]]   [[44, 29], [9, 69]]  [[43, 30], [10, 68]]   \n",
       "10  [[53, 20], [11, 67]]  [[50, 23], [11, 67]]  [[58, 15], [11, 67]]   \n",
       "11  [[46, 27], [13, 65]]  [[51, 22], [12, 66]]   [[50, 23], [9, 69]]   \n",
       "12  [[35, 38], [11, 67]]   [[39, 34], [6, 72]]   [[40, 33], [8, 70]]   \n",
       "\n",
       "        Gaussian Process         Decision Tree         Random Forest  \\\n",
       "0   [[56, 17], [10, 68]]  [[56, 17], [21, 57]]  [[60, 13], [13, 65]]   \n",
       "1   [[53, 20], [15, 63]]  [[55, 18], [21, 57]]  [[54, 19], [13, 65]]   \n",
       "2    [[56, 17], [8, 70]]  [[56, 17], [14, 64]]   [[56, 17], [6, 72]]   \n",
       "3    [[58, 15], [7, 71]]   [[68, 5], [29, 49]]  [[48, 25], [11, 67]]   \n",
       "4   [[43, 30], [14, 64]]  [[43, 30], [12, 66]]  [[50, 23], [17, 61]]   \n",
       "5    [[37, 36], [9, 69]]  [[52, 21], [17, 61]]  [[48, 25], [15, 63]]   \n",
       "6   [[53, 20], [15, 63]]  [[55, 18], [21, 57]]  [[55, 18], [13, 65]]   \n",
       "7   [[57, 16], [10, 68]]  [[42, 31], [11, 67]]  [[57, 16], [10, 68]]   \n",
       "8   [[54, 19], [11, 67]]  [[43, 30], [17, 61]]  [[53, 20], [12, 66]]   \n",
       "9   [[56, 17], [15, 63]]  [[56, 17], [24, 54]]  [[45, 28], [20, 58]]   \n",
       "10  [[57, 16], [11, 67]]  [[53, 20], [20, 58]]  [[58, 15], [11, 67]]   \n",
       "11  [[61, 12], [15, 63]]  [[57, 16], [14, 64]]  [[59, 14], [15, 63]]   \n",
       "12  [[41, 32], [10, 68]]   [[26, 47], [7, 71]]  [[53, 20], [14, 64]]   \n",
       "\n",
       "            Neural Net              AdaBoost           Naive Bayes  \\\n",
       "0   [[0, 73], [0, 78]]  [[61, 12], [10, 68]]  [[35, 38], [10, 68]]   \n",
       "1   [[1, 72], [0, 78]]  [[56, 17], [15, 63]]   [[33, 40], [9, 69]]   \n",
       "2   [[0, 73], [0, 78]]   [[54, 19], [7, 71]]  [[37, 36], [10, 68]]   \n",
       "3   [[0, 73], [0, 78]]  [[47, 26], [12, 66]]  [[36, 37], [12, 66]]   \n",
       "4   [[0, 73], [0, 78]]  [[48, 25], [20, 58]]  [[47, 26], [12, 66]]   \n",
       "5   [[0, 73], [0, 78]]   [[49, 24], [9, 69]]  [[38, 35], [12, 66]]   \n",
       "6   [[3, 70], [1, 77]]  [[56, 17], [15, 63]]   [[33, 40], [9, 69]]   \n",
       "7   [[0, 73], [0, 78]]  [[49, 24], [13, 65]]  [[33, 40], [11, 67]]   \n",
       "8   [[0, 73], [0, 78]]  [[45, 28], [13, 65]]  [[47, 26], [10, 68]]   \n",
       "9   [[0, 73], [0, 78]]  [[50, 23], [21, 57]]  [[49, 24], [14, 64]]   \n",
       "10  [[0, 73], [0, 78]]  [[58, 15], [13, 65]]  [[32, 41], [11, 67]]   \n",
       "11  [[1, 72], [0, 78]]  [[50, 23], [12, 66]]  [[48, 25], [10, 68]]   \n",
       "12  [[0, 73], [0, 78]]  [[46, 27], [10, 68]]  [[51, 22], [10, 68]]   \n",
       "\n",
       "                     QDA               XGBoost  \n",
       "0    [[57, 16], [6, 72]]  [[59, 14], [13, 65]]  \n",
       "1    [[23, 50], [6, 72]]  [[57, 16], [15, 63]]  \n",
       "2   [[56, 17], [15, 63]]   [[52, 21], [9, 69]]  \n",
       "3    [[42, 31], [6, 72]]  [[50, 23], [14, 64]]  \n",
       "4    [[22, 51], [6, 72]]  [[51, 22], [13, 65]]  \n",
       "5    [[29, 44], [7, 71]]  [[48, 25], [13, 65]]  \n",
       "6    [[22, 51], [6, 72]]  [[57, 16], [15, 63]]  \n",
       "7    [[37, 36], [5, 73]]  [[57, 16], [12, 66]]  \n",
       "8    [[43, 30], [5, 73]]  [[55, 18], [13, 65]]  \n",
       "9   [[45, 28], [10, 68]]  [[54, 19], [20, 58]]  \n",
       "10   [[48, 25], [6, 72]]  [[59, 14], [13, 65]]  \n",
       "11  [[56, 17], [13, 65]]  [[55, 18], [12, 66]]  \n",
       "12  [[52, 21], [14, 64]]  [[49, 24], [10, 68]]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ 16 pontos - 2 raio ------\n",
      "--- Acuracia ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.788079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.662252</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.662252</td>\n",
       "      <td>0.655629</td>\n",
       "      <td>0.741722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.788079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.801325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.761589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.662252</td>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.655629</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.768212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.662252</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.662252</td>\n",
       "      <td>0.655629</td>\n",
       "      <td>0.741722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.794702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.768212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.748344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.801325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.788079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.682119</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.662252</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.761589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.814570    0.794702  0.814570          0.827815       0.701987   \n",
       "1            0.721854    0.688742  0.754967          0.774834       0.662252   \n",
       "2            0.768212    0.807947  0.841060          0.834437       0.754967   \n",
       "3            0.721854    0.735099  0.814570          0.788079       0.735099   \n",
       "4            0.721854    0.701987  0.768212          0.721854       0.721854   \n",
       "5            0.662252    0.688742  0.708609          0.715232       0.735099   \n",
       "6            0.721854    0.688742  0.754967          0.774834       0.662252   \n",
       "7            0.788079    0.774834  0.774834          0.801325       0.735099   \n",
       "8            0.735099    0.754967  0.761589          0.768212       0.695364   \n",
       "9            0.721854    0.741722  0.741722          0.801325       0.695364   \n",
       "10           0.807947    0.781457  0.774834          0.781457       0.735099   \n",
       "11           0.741722    0.788079  0.735099          0.807947       0.754967   \n",
       "12           0.682119    0.715232  0.741722          0.721854       0.662252   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.827815    0.516556  0.754967     0.715232  0.688742  0.788079  \n",
       "1        0.741722    0.516556  0.768212     0.662252  0.655629  0.741722  \n",
       "2        0.827815    0.516556  0.774834     0.721854  0.794702  0.788079  \n",
       "3        0.807947    0.516556  0.774834     0.715232  0.715232  0.801325  \n",
       "4        0.794702    0.516556  0.748344     0.748344  0.715232  0.761589  \n",
       "5        0.768212    0.516556  0.741722     0.655629  0.708609  0.768212  \n",
       "6        0.774834    0.516556  0.761589     0.662252  0.655629  0.741722  \n",
       "7        0.827815    0.516556  0.807947     0.695364  0.695364  0.794702  \n",
       "8        0.761589    0.516556  0.701987     0.748344  0.701987  0.768212  \n",
       "9        0.735099    0.516556  0.708609     0.754967  0.715232  0.748344  \n",
       "10       0.841060    0.516556  0.761589     0.708609  0.761589  0.801325  \n",
       "11       0.834437    0.516556  0.761589     0.728477  0.768212  0.788079  \n",
       "12       0.741722    0.516556  0.741722     0.768212  0.768212  0.761589  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- F1 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.813337</td>\n",
       "      <td>0.794250</td>\n",
       "      <td>0.814276</td>\n",
       "      <td>0.827542</td>\n",
       "      <td>0.695872</td>\n",
       "      <td>0.827709</td>\n",
       "      <td>0.35189</td>\n",
       "      <td>0.754708</td>\n",
       "      <td>0.706902</td>\n",
       "      <td>0.674563</td>\n",
       "      <td>0.787463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.721045</td>\n",
       "      <td>0.676393</td>\n",
       "      <td>0.754427</td>\n",
       "      <td>0.774478</td>\n",
       "      <td>0.660999</td>\n",
       "      <td>0.741153</td>\n",
       "      <td>0.35189</td>\n",
       "      <td>0.765799</td>\n",
       "      <td>0.644724</td>\n",
       "      <td>0.625793</td>\n",
       "      <td>0.738263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.764327</td>\n",
       "      <td>0.806877</td>\n",
       "      <td>0.840004</td>\n",
       "      <td>0.833145</td>\n",
       "      <td>0.745245</td>\n",
       "      <td>0.826671</td>\n",
       "      <td>0.35189</td>\n",
       "      <td>0.771451</td>\n",
       "      <td>0.716684</td>\n",
       "      <td>0.794738</td>\n",
       "      <td>0.785567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.719334</td>\n",
       "      <td>0.726704</td>\n",
       "      <td>0.814030</td>\n",
       "      <td>0.784895</td>\n",
       "      <td>0.731959</td>\n",
       "      <td>0.804728</td>\n",
       "      <td>0.35189</td>\n",
       "      <td>0.772794</td>\n",
       "      <td>0.708204</td>\n",
       "      <td>0.700454</td>\n",
       "      <td>0.799524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.717675</td>\n",
       "      <td>0.688411</td>\n",
       "      <td>0.765108</td>\n",
       "      <td>0.718557</td>\n",
       "      <td>0.717675</td>\n",
       "      <td>0.794250</td>\n",
       "      <td>0.35189</td>\n",
       "      <td>0.748190</td>\n",
       "      <td>0.744563</td>\n",
       "      <td>0.698511</td>\n",
       "      <td>0.760494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.644724</td>\n",
       "      <td>0.668188</td>\n",
       "      <td>0.700767</td>\n",
       "      <td>0.703934</td>\n",
       "      <td>0.734936</td>\n",
       "      <td>0.763456</td>\n",
       "      <td>0.35189</td>\n",
       "      <td>0.739033</td>\n",
       "      <td>0.649228</td>\n",
       "      <td>0.692512</td>\n",
       "      <td>0.764327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.721045</td>\n",
       "      <td>0.676393</td>\n",
       "      <td>0.754427</td>\n",
       "      <td>0.774478</td>\n",
       "      <td>0.660999</td>\n",
       "      <td>0.774478</td>\n",
       "      <td>0.35189</td>\n",
       "      <td>0.758763</td>\n",
       "      <td>0.644724</td>\n",
       "      <td>0.628772</td>\n",
       "      <td>0.738263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.784140</td>\n",
       "      <td>0.772794</td>\n",
       "      <td>0.773338</td>\n",
       "      <td>0.800746</td>\n",
       "      <td>0.735146</td>\n",
       "      <td>0.827709</td>\n",
       "      <td>0.35189</td>\n",
       "      <td>0.807981</td>\n",
       "      <td>0.685709</td>\n",
       "      <td>0.680539</td>\n",
       "      <td>0.794648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.727970</td>\n",
       "      <td>0.748920</td>\n",
       "      <td>0.758763</td>\n",
       "      <td>0.766920</td>\n",
       "      <td>0.694882</td>\n",
       "      <td>0.760005</td>\n",
       "      <td>0.35189</td>\n",
       "      <td>0.700882</td>\n",
       "      <td>0.743667</td>\n",
       "      <td>0.684489</td>\n",
       "      <td>0.765799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.720576</td>\n",
       "      <td>0.735348</td>\n",
       "      <td>0.739033</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.685709</td>\n",
       "      <td>0.734328</td>\n",
       "      <td>0.35189</td>\n",
       "      <td>0.703193</td>\n",
       "      <td>0.753601</td>\n",
       "      <td>0.711418</td>\n",
       "      <td>0.747188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.806877</td>\n",
       "      <td>0.779751</td>\n",
       "      <td>0.773338</td>\n",
       "      <td>0.780976</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.840808</td>\n",
       "      <td>0.35189</td>\n",
       "      <td>0.761652</td>\n",
       "      <td>0.700767</td>\n",
       "      <td>0.760005</td>\n",
       "      <td>0.801325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.739033</td>\n",
       "      <td>0.787463</td>\n",
       "      <td>0.731959</td>\n",
       "      <td>0.807524</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.834466</td>\n",
       "      <td>0.35189</td>\n",
       "      <td>0.759429</td>\n",
       "      <td>0.723926</td>\n",
       "      <td>0.766402</td>\n",
       "      <td>0.787463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.672044</td>\n",
       "      <td>0.698511</td>\n",
       "      <td>0.732877</td>\n",
       "      <td>0.715583</td>\n",
       "      <td>0.639949</td>\n",
       "      <td>0.739033</td>\n",
       "      <td>0.35189</td>\n",
       "      <td>0.737393</td>\n",
       "      <td>0.765799</td>\n",
       "      <td>0.768253</td>\n",
       "      <td>0.758007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.813337    0.794250  0.814276          0.827542       0.695872   \n",
       "1            0.721045    0.676393  0.754427          0.774478       0.660999   \n",
       "2            0.764327    0.806877  0.840004          0.833145       0.745245   \n",
       "3            0.719334    0.726704  0.814030          0.784895       0.731959   \n",
       "4            0.717675    0.688411  0.765108          0.718557       0.717675   \n",
       "5            0.644724    0.668188  0.700767          0.703934       0.734936   \n",
       "6            0.721045    0.676393  0.754427          0.774478       0.660999   \n",
       "7            0.784140    0.772794  0.773338          0.800746       0.735146   \n",
       "8            0.727970    0.748920  0.758763          0.766920       0.694882   \n",
       "9            0.720576    0.735348  0.739033          0.801325       0.685709   \n",
       "10           0.806877    0.779751  0.773338          0.780976       0.735099   \n",
       "11           0.739033    0.787463  0.731959          0.807524       0.754967   \n",
       "12           0.672044    0.698511  0.732877          0.715583       0.639949   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.827709     0.35189  0.754708     0.706902  0.674563  0.787463  \n",
       "1        0.741153     0.35189  0.765799     0.644724  0.625793  0.738263  \n",
       "2        0.826671     0.35189  0.771451     0.716684  0.794738  0.785567  \n",
       "3        0.804728     0.35189  0.772794     0.708204  0.700454  0.799524  \n",
       "4        0.794250     0.35189  0.748190     0.744563  0.698511  0.760494  \n",
       "5        0.763456     0.35189  0.739033     0.649228  0.692512  0.764327  \n",
       "6        0.774478     0.35189  0.758763     0.644724  0.628772  0.738263  \n",
       "7        0.827709     0.35189  0.807981     0.685709  0.680539  0.794648  \n",
       "8        0.760005     0.35189  0.700882     0.743667  0.684489  0.765799  \n",
       "9        0.734328     0.35189  0.703193     0.753601  0.711418  0.747188  \n",
       "10       0.840808     0.35189  0.761652     0.700767  0.760005  0.801325  \n",
       "11       0.834466     0.35189  0.759429     0.723926  0.766402  0.787463  \n",
       "12       0.739033     0.35189  0.737393     0.765799  0.768253  0.758007  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Precision Score ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.819407</td>\n",
       "      <td>0.795553</td>\n",
       "      <td>0.815131</td>\n",
       "      <td>0.828437</td>\n",
       "      <td>0.713205</td>\n",
       "      <td>0.827894</td>\n",
       "      <td>0.26683</td>\n",
       "      <td>0.755047</td>\n",
       "      <td>0.734535</td>\n",
       "      <td>0.717664</td>\n",
       "      <td>0.789357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.722532</td>\n",
       "      <td>0.712879</td>\n",
       "      <td>0.755554</td>\n",
       "      <td>0.775214</td>\n",
       "      <td>0.662615</td>\n",
       "      <td>0.742221</td>\n",
       "      <td>0.26683</td>\n",
       "      <td>0.775134</td>\n",
       "      <td>0.690593</td>\n",
       "      <td>0.710732</td>\n",
       "      <td>0.750009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.780930</td>\n",
       "      <td>0.811651</td>\n",
       "      <td>0.846495</td>\n",
       "      <td>0.840946</td>\n",
       "      <td>0.790025</td>\n",
       "      <td>0.832951</td>\n",
       "      <td>0.26683</td>\n",
       "      <td>0.786285</td>\n",
       "      <td>0.733098</td>\n",
       "      <td>0.794844</td>\n",
       "      <td>0.797115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.726154</td>\n",
       "      <td>0.759014</td>\n",
       "      <td>0.816087</td>\n",
       "      <td>0.800262</td>\n",
       "      <td>0.741880</td>\n",
       "      <td>0.823141</td>\n",
       "      <td>0.26683</td>\n",
       "      <td>0.780813</td>\n",
       "      <td>0.730765</td>\n",
       "      <td>0.755592</td>\n",
       "      <td>0.808142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.730378</td>\n",
       "      <td>0.733479</td>\n",
       "      <td>0.777788</td>\n",
       "      <td>0.728072</td>\n",
       "      <td>0.730378</td>\n",
       "      <td>0.795553</td>\n",
       "      <td>0.26683</td>\n",
       "      <td>0.748298</td>\n",
       "      <td>0.758331</td>\n",
       "      <td>0.762730</td>\n",
       "      <td>0.763731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.690593</td>\n",
       "      <td>0.736244</td>\n",
       "      <td>0.725264</td>\n",
       "      <td>0.743737</td>\n",
       "      <td>0.735032</td>\n",
       "      <td>0.784595</td>\n",
       "      <td>0.26683</td>\n",
       "      <td>0.747666</td>\n",
       "      <td>0.662244</td>\n",
       "      <td>0.750805</td>\n",
       "      <td>0.780930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.722532</td>\n",
       "      <td>0.712879</td>\n",
       "      <td>0.755554</td>\n",
       "      <td>0.775214</td>\n",
       "      <td>0.662615</td>\n",
       "      <td>0.775214</td>\n",
       "      <td>0.26683</td>\n",
       "      <td>0.769498</td>\n",
       "      <td>0.690593</td>\n",
       "      <td>0.702923</td>\n",
       "      <td>0.750009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.803951</td>\n",
       "      <td>0.780813</td>\n",
       "      <td>0.778776</td>\n",
       "      <td>0.802722</td>\n",
       "      <td>0.736224</td>\n",
       "      <td>0.827894</td>\n",
       "      <td>0.26683</td>\n",
       "      <td>0.808085</td>\n",
       "      <td>0.714222</td>\n",
       "      <td>0.728306</td>\n",
       "      <td>0.794664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.754554</td>\n",
       "      <td>0.774310</td>\n",
       "      <td>0.769498</td>\n",
       "      <td>0.771177</td>\n",
       "      <td>0.695378</td>\n",
       "      <td>0.765233</td>\n",
       "      <td>0.26683</td>\n",
       "      <td>0.702821</td>\n",
       "      <td>0.761439</td>\n",
       "      <td>0.745991</td>\n",
       "      <td>0.775134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.723399</td>\n",
       "      <td>0.759795</td>\n",
       "      <td>0.747666</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.714222</td>\n",
       "      <td>0.735897</td>\n",
       "      <td>0.26683</td>\n",
       "      <td>0.718927</td>\n",
       "      <td>0.757686</td>\n",
       "      <td>0.722230</td>\n",
       "      <td>0.750287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.811651</td>\n",
       "      <td>0.786540</td>\n",
       "      <td>0.778776</td>\n",
       "      <td>0.782220</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.841743</td>\n",
       "      <td>0.26683</td>\n",
       "      <td>0.761982</td>\n",
       "      <td>0.725264</td>\n",
       "      <td>0.765233</td>\n",
       "      <td>0.801325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.747666</td>\n",
       "      <td>0.789357</td>\n",
       "      <td>0.741880</td>\n",
       "      <td>0.808886</td>\n",
       "      <td>0.756624</td>\n",
       "      <td>0.834568</td>\n",
       "      <td>0.26683</td>\n",
       "      <td>0.767148</td>\n",
       "      <td>0.738719</td>\n",
       "      <td>0.772938</td>\n",
       "      <td>0.789357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.699292</td>\n",
       "      <td>0.762730</td>\n",
       "      <td>0.769014</td>\n",
       "      <td>0.736262</td>\n",
       "      <td>0.701657</td>\n",
       "      <td>0.747666</td>\n",
       "      <td>0.26683</td>\n",
       "      <td>0.752790</td>\n",
       "      <td>0.775134</td>\n",
       "      <td>0.768361</td>\n",
       "      <td>0.772308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.819407    0.795553  0.815131          0.828437       0.713205   \n",
       "1            0.722532    0.712879  0.755554          0.775214       0.662615   \n",
       "2            0.780930    0.811651  0.846495          0.840946       0.790025   \n",
       "3            0.726154    0.759014  0.816087          0.800262       0.741880   \n",
       "4            0.730378    0.733479  0.777788          0.728072       0.730378   \n",
       "5            0.690593    0.736244  0.725264          0.743737       0.735032   \n",
       "6            0.722532    0.712879  0.755554          0.775214       0.662615   \n",
       "7            0.803951    0.780813  0.778776          0.802722       0.736224   \n",
       "8            0.754554    0.774310  0.769498          0.771177       0.695378   \n",
       "9            0.723399    0.759795  0.747666          0.801325       0.714222   \n",
       "10           0.811651    0.786540  0.778776          0.782220       0.735099   \n",
       "11           0.747666    0.789357  0.741880          0.808886       0.756624   \n",
       "12           0.699292    0.762730  0.769014          0.736262       0.701657   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.827894     0.26683  0.755047     0.734535  0.717664  0.789357  \n",
       "1        0.742221     0.26683  0.775134     0.690593  0.710732  0.750009  \n",
       "2        0.832951     0.26683  0.786285     0.733098  0.794844  0.797115  \n",
       "3        0.823141     0.26683  0.780813     0.730765  0.755592  0.808142  \n",
       "4        0.795553     0.26683  0.748298     0.758331  0.762730  0.763731  \n",
       "5        0.784595     0.26683  0.747666     0.662244  0.750805  0.780930  \n",
       "6        0.775214     0.26683  0.769498     0.690593  0.702923  0.750009  \n",
       "7        0.827894     0.26683  0.808085     0.714222  0.728306  0.794664  \n",
       "8        0.765233     0.26683  0.702821     0.761439  0.745991  0.775134  \n",
       "9        0.735897     0.26683  0.718927     0.757686  0.722230  0.750287  \n",
       "10       0.841743     0.26683  0.761982     0.725264  0.765233  0.801325  \n",
       "11       0.834568     0.26683  0.767148     0.738719  0.772938  0.789357  \n",
       "12       0.747666     0.26683  0.752790     0.775134  0.768361  0.772308  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Recall Score ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.788079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.662252</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.662252</td>\n",
       "      <td>0.655629</td>\n",
       "      <td>0.741722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.788079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.801325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.761589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.662252</td>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.655629</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.768212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.662252</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.662252</td>\n",
       "      <td>0.655629</td>\n",
       "      <td>0.741722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.794702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.768212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.748344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.801325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.788079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.682119</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.662252</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.761589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.814570    0.794702  0.814570          0.827815       0.701987   \n",
       "1            0.721854    0.688742  0.754967          0.774834       0.662252   \n",
       "2            0.768212    0.807947  0.841060          0.834437       0.754967   \n",
       "3            0.721854    0.735099  0.814570          0.788079       0.735099   \n",
       "4            0.721854    0.701987  0.768212          0.721854       0.721854   \n",
       "5            0.662252    0.688742  0.708609          0.715232       0.735099   \n",
       "6            0.721854    0.688742  0.754967          0.774834       0.662252   \n",
       "7            0.788079    0.774834  0.774834          0.801325       0.735099   \n",
       "8            0.735099    0.754967  0.761589          0.768212       0.695364   \n",
       "9            0.721854    0.741722  0.741722          0.801325       0.695364   \n",
       "10           0.807947    0.781457  0.774834          0.781457       0.735099   \n",
       "11           0.741722    0.788079  0.735099          0.807947       0.754967   \n",
       "12           0.682119    0.715232  0.741722          0.721854       0.662252   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.827815    0.516556  0.754967     0.715232  0.688742  0.788079  \n",
       "1        0.741722    0.516556  0.768212     0.662252  0.655629  0.741722  \n",
       "2        0.827815    0.516556  0.774834     0.721854  0.794702  0.788079  \n",
       "3        0.807947    0.516556  0.774834     0.715232  0.715232  0.801325  \n",
       "4        0.794702    0.516556  0.748344     0.748344  0.715232  0.761589  \n",
       "5        0.768212    0.516556  0.741722     0.655629  0.708609  0.768212  \n",
       "6        0.774834    0.516556  0.761589     0.662252  0.655629  0.741722  \n",
       "7        0.827815    0.516556  0.807947     0.695364  0.695364  0.794702  \n",
       "8        0.761589    0.516556  0.701987     0.748344  0.701987  0.768212  \n",
       "9        0.735099    0.516556  0.708609     0.754967  0.715232  0.748344  \n",
       "10       0.841060    0.516556  0.761589     0.708609  0.761589  0.801325  \n",
       "11       0.834437    0.516556  0.761589     0.728477  0.768212  0.788079  \n",
       "12       0.741722    0.516556  0.741722     0.768212  0.768212  0.761589  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Matriz confusao ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[54, 19], [9, 69]]</td>\n",
       "      <td>[[55, 18], [13, 65]]</td>\n",
       "      <td>[[57, 16], [12, 66]]</td>\n",
       "      <td>[[58, 15], [11, 67]]</td>\n",
       "      <td>[[41, 32], [13, 65]]</td>\n",
       "      <td>[[59, 14], [12, 66]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[53, 20], [17, 61]]</td>\n",
       "      <td>[[40, 33], [10, 68]]</td>\n",
       "      <td>[[35, 38], [9, 69]]</td>\n",
       "      <td>[[54, 19], [13, 65]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[49, 24], [18, 60]]</td>\n",
       "      <td>[[36, 37], [10, 68]]</td>\n",
       "      <td>[[52, 21], [16, 62]]</td>\n",
       "      <td>[[54, 19], [15, 63]]</td>\n",
       "      <td>[[44, 29], [22, 56]]</td>\n",
       "      <td>[[51, 22], [17, 61]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[49, 24], [11, 67]]</td>\n",
       "      <td>[[32, 41], [10, 68]]</td>\n",
       "      <td>[[27, 46], [6, 72]]</td>\n",
       "      <td>[[46, 27], [12, 66]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[47, 26], [9, 69]]</td>\n",
       "      <td>[[54, 19], [10, 68]]</td>\n",
       "      <td>[[56, 17], [7, 71]]</td>\n",
       "      <td>[[55, 18], [7, 71]]</td>\n",
       "      <td>[[41, 32], [5, 73]]</td>\n",
       "      <td>[[55, 18], [8, 70]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[48, 25], [9, 69]]</td>\n",
       "      <td>[[43, 30], [12, 66]]</td>\n",
       "      <td>[[58, 15], [16, 62]]</td>\n",
       "      <td>[[50, 23], [9, 69]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[46, 27], [15, 63]]</td>\n",
       "      <td>[[41, 32], [8, 70]]</td>\n",
       "      <td>[[56, 17], [11, 67]]</td>\n",
       "      <td>[[49, 24], [8, 70]]</td>\n",
       "      <td>[[46, 27], [13, 65]]</td>\n",
       "      <td>[[50, 23], [6, 72]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[50, 23], [11, 67]]</td>\n",
       "      <td>[[41, 32], [11, 67]]</td>\n",
       "      <td>[[36, 37], [6, 72]]</td>\n",
       "      <td>[[52, 21], [9, 69]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[44, 29], [13, 65]]</td>\n",
       "      <td>[[36, 37], [8, 70]]</td>\n",
       "      <td>[[48, 25], [10, 68]]</td>\n",
       "      <td>[[45, 28], [14, 64]]</td>\n",
       "      <td>[[44, 29], [13, 65]]</td>\n",
       "      <td>[[55, 18], [13, 65]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[53, 20], [18, 60]]</td>\n",
       "      <td>[[46, 27], [11, 67]]</td>\n",
       "      <td>[[35, 38], [5, 73]]</td>\n",
       "      <td>[[51, 22], [14, 64]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[[32, 41], [10, 68]]</td>\n",
       "      <td>[[32, 41], [6, 72]]</td>\n",
       "      <td>[[40, 33], [11, 67]]</td>\n",
       "      <td>[[38, 35], [8, 70]]</td>\n",
       "      <td>[[52, 21], [19, 59]]</td>\n",
       "      <td>[[46, 27], [8, 70]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[47, 26], [13, 65]]</td>\n",
       "      <td>[[38, 35], [17, 61]]</td>\n",
       "      <td>[[35, 38], [6, 72]]</td>\n",
       "      <td>[[47, 26], [9, 69]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[[49, 24], [18, 60]]</td>\n",
       "      <td>[[36, 37], [10, 68]]</td>\n",
       "      <td>[[52, 21], [16, 62]]</td>\n",
       "      <td>[[54, 19], [15, 63]]</td>\n",
       "      <td>[[44, 29], [22, 56]]</td>\n",
       "      <td>[[54, 19], [15, 63]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[48, 25], [11, 67]]</td>\n",
       "      <td>[[32, 41], [10, 68]]</td>\n",
       "      <td>[[28, 45], [7, 71]]</td>\n",
       "      <td>[[46, 27], [12, 66]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[[48, 25], [7, 71]]</td>\n",
       "      <td>[[50, 23], [11, 67]]</td>\n",
       "      <td>[[51, 22], [12, 66]]</td>\n",
       "      <td>[[55, 18], [12, 66]]</td>\n",
       "      <td>[[55, 18], [22, 56]]</td>\n",
       "      <td>[[59, 14], [12, 66]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[59, 14], [15, 63]]</td>\n",
       "      <td>[[38, 35], [11, 67]]</td>\n",
       "      <td>[[35, 38], [8, 70]]</td>\n",
       "      <td>[[57, 16], [15, 63]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[[42, 31], [9, 69]]</td>\n",
       "      <td>[[44, 29], [8, 70]]</td>\n",
       "      <td>[[48, 25], [11, 67]]</td>\n",
       "      <td>[[51, 22], [13, 65]]</td>\n",
       "      <td>[[48, 25], [21, 57]]</td>\n",
       "      <td>[[50, 23], [13, 65]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[47, 26], [19, 59]]</td>\n",
       "      <td>[[45, 28], [10, 68]]</td>\n",
       "      <td>[[34, 39], [6, 72]]</td>\n",
       "      <td>[[49, 24], [11, 67]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[[48, 25], [17, 61]]</td>\n",
       "      <td>[[43, 30], [9, 69]]</td>\n",
       "      <td>[[47, 26], [13, 65]]</td>\n",
       "      <td>[[58, 15], [15, 63]]</td>\n",
       "      <td>[[38, 35], [11, 67]]</td>\n",
       "      <td>[[50, 23], [17, 61]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[42, 31], [13, 65]]</td>\n",
       "      <td>[[50, 23], [14, 64]]</td>\n",
       "      <td>[[44, 29], [14, 64]]</td>\n",
       "      <td>[[50, 23], [15, 63]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[[54, 19], [10, 68]]</td>\n",
       "      <td>[[51, 22], [11, 67]]</td>\n",
       "      <td>[[51, 22], [12, 66]]</td>\n",
       "      <td>[[54, 19], [14, 64]]</td>\n",
       "      <td>[[53, 20], [20, 58]]</td>\n",
       "      <td>[[59, 14], [10, 68]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[56, 17], [19, 59]]</td>\n",
       "      <td>[[40, 33], [11, 67]]</td>\n",
       "      <td>[[50, 23], [13, 65]]</td>\n",
       "      <td>[[58, 15], [15, 63]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[[47, 26], [13, 65]]</td>\n",
       "      <td>[[54, 19], [13, 65]]</td>\n",
       "      <td>[[46, 27], [13, 65]]</td>\n",
       "      <td>[[56, 17], [12, 66]]</td>\n",
       "      <td>[[57, 16], [21, 57]]</td>\n",
       "      <td>[[61, 12], [13, 65]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[49, 24], [12, 66]]</td>\n",
       "      <td>[[44, 29], [12, 66]]</td>\n",
       "      <td>[[50, 23], [12, 66]]</td>\n",
       "      <td>[[54, 19], [13, 65]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[[37, 36], [12, 66]]</td>\n",
       "      <td>[[35, 38], [5, 73]]</td>\n",
       "      <td>[[41, 32], [7, 71]]</td>\n",
       "      <td>[[42, 31], [11, 67]]</td>\n",
       "      <td>[[30, 43], [8, 70]]</td>\n",
       "      <td>[[47, 26], [13, 65]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[45, 28], [11, 67]]</td>\n",
       "      <td>[[49, 24], [11, 67]]</td>\n",
       "      <td>[[56, 17], [18, 60]]</td>\n",
       "      <td>[[47, 26], [10, 68]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Nearest Neighbors            Linear SVM               RBF SVM  \\\n",
       "0    [[54, 19], [9, 69]]  [[55, 18], [13, 65]]  [[57, 16], [12, 66]]   \n",
       "1   [[49, 24], [18, 60]]  [[36, 37], [10, 68]]  [[52, 21], [16, 62]]   \n",
       "2    [[47, 26], [9, 69]]  [[54, 19], [10, 68]]   [[56, 17], [7, 71]]   \n",
       "3   [[46, 27], [15, 63]]   [[41, 32], [8, 70]]  [[56, 17], [11, 67]]   \n",
       "4   [[44, 29], [13, 65]]   [[36, 37], [8, 70]]  [[48, 25], [10, 68]]   \n",
       "5   [[32, 41], [10, 68]]   [[32, 41], [6, 72]]  [[40, 33], [11, 67]]   \n",
       "6   [[49, 24], [18, 60]]  [[36, 37], [10, 68]]  [[52, 21], [16, 62]]   \n",
       "7    [[48, 25], [7, 71]]  [[50, 23], [11, 67]]  [[51, 22], [12, 66]]   \n",
       "8    [[42, 31], [9, 69]]   [[44, 29], [8, 70]]  [[48, 25], [11, 67]]   \n",
       "9   [[48, 25], [17, 61]]   [[43, 30], [9, 69]]  [[47, 26], [13, 65]]   \n",
       "10  [[54, 19], [10, 68]]  [[51, 22], [11, 67]]  [[51, 22], [12, 66]]   \n",
       "11  [[47, 26], [13, 65]]  [[54, 19], [13, 65]]  [[46, 27], [13, 65]]   \n",
       "12  [[37, 36], [12, 66]]   [[35, 38], [5, 73]]   [[41, 32], [7, 71]]   \n",
       "\n",
       "        Gaussian Process         Decision Tree         Random Forest  \\\n",
       "0   [[58, 15], [11, 67]]  [[41, 32], [13, 65]]  [[59, 14], [12, 66]]   \n",
       "1   [[54, 19], [15, 63]]  [[44, 29], [22, 56]]  [[51, 22], [17, 61]]   \n",
       "2    [[55, 18], [7, 71]]   [[41, 32], [5, 73]]   [[55, 18], [8, 70]]   \n",
       "3    [[49, 24], [8, 70]]  [[46, 27], [13, 65]]   [[50, 23], [6, 72]]   \n",
       "4   [[45, 28], [14, 64]]  [[44, 29], [13, 65]]  [[55, 18], [13, 65]]   \n",
       "5    [[38, 35], [8, 70]]  [[52, 21], [19, 59]]   [[46, 27], [8, 70]]   \n",
       "6   [[54, 19], [15, 63]]  [[44, 29], [22, 56]]  [[54, 19], [15, 63]]   \n",
       "7   [[55, 18], [12, 66]]  [[55, 18], [22, 56]]  [[59, 14], [12, 66]]   \n",
       "8   [[51, 22], [13, 65]]  [[48, 25], [21, 57]]  [[50, 23], [13, 65]]   \n",
       "9   [[58, 15], [15, 63]]  [[38, 35], [11, 67]]  [[50, 23], [17, 61]]   \n",
       "10  [[54, 19], [14, 64]]  [[53, 20], [20, 58]]  [[59, 14], [10, 68]]   \n",
       "11  [[56, 17], [12, 66]]  [[57, 16], [21, 57]]  [[61, 12], [13, 65]]   \n",
       "12  [[42, 31], [11, 67]]   [[30, 43], [8, 70]]  [[47, 26], [13, 65]]   \n",
       "\n",
       "            Neural Net              AdaBoost           Naive Bayes  \\\n",
       "0   [[0, 73], [0, 78]]  [[53, 20], [17, 61]]  [[40, 33], [10, 68]]   \n",
       "1   [[0, 73], [0, 78]]  [[49, 24], [11, 67]]  [[32, 41], [10, 68]]   \n",
       "2   [[0, 73], [0, 78]]   [[48, 25], [9, 69]]  [[43, 30], [12, 66]]   \n",
       "3   [[0, 73], [0, 78]]  [[50, 23], [11, 67]]  [[41, 32], [11, 67]]   \n",
       "4   [[0, 73], [0, 78]]  [[53, 20], [18, 60]]  [[46, 27], [11, 67]]   \n",
       "5   [[0, 73], [0, 78]]  [[47, 26], [13, 65]]  [[38, 35], [17, 61]]   \n",
       "6   [[0, 73], [0, 78]]  [[48, 25], [11, 67]]  [[32, 41], [10, 68]]   \n",
       "7   [[0, 73], [0, 78]]  [[59, 14], [15, 63]]  [[38, 35], [11, 67]]   \n",
       "8   [[0, 73], [0, 78]]  [[47, 26], [19, 59]]  [[45, 28], [10, 68]]   \n",
       "9   [[0, 73], [0, 78]]  [[42, 31], [13, 65]]  [[50, 23], [14, 64]]   \n",
       "10  [[0, 73], [0, 78]]  [[56, 17], [19, 59]]  [[40, 33], [11, 67]]   \n",
       "11  [[0, 73], [0, 78]]  [[49, 24], [12, 66]]  [[44, 29], [12, 66]]   \n",
       "12  [[0, 73], [0, 78]]  [[45, 28], [11, 67]]  [[49, 24], [11, 67]]   \n",
       "\n",
       "                     QDA               XGBoost  \n",
       "0    [[35, 38], [9, 69]]  [[54, 19], [13, 65]]  \n",
       "1    [[27, 46], [6, 72]]  [[46, 27], [12, 66]]  \n",
       "2   [[58, 15], [16, 62]]   [[50, 23], [9, 69]]  \n",
       "3    [[36, 37], [6, 72]]   [[52, 21], [9, 69]]  \n",
       "4    [[35, 38], [5, 73]]  [[51, 22], [14, 64]]  \n",
       "5    [[35, 38], [6, 72]]   [[47, 26], [9, 69]]  \n",
       "6    [[28, 45], [7, 71]]  [[46, 27], [12, 66]]  \n",
       "7    [[35, 38], [8, 70]]  [[57, 16], [15, 63]]  \n",
       "8    [[34, 39], [6, 72]]  [[49, 24], [11, 67]]  \n",
       "9   [[44, 29], [14, 64]]  [[50, 23], [15, 63]]  \n",
       "10  [[50, 23], [13, 65]]  [[58, 15], [15, 63]]  \n",
       "11  [[50, 23], [12, 66]]  [[54, 19], [13, 65]]  \n",
       "12  [[56, 17], [18, 60]]  [[47, 26], [10, 68]]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ 16 pontos - 3 raio ------\n",
      "--- Acuracia ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.523179</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.807947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.642384</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.662252</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.728477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.781457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.682119</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.788079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.748344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.649007</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.649007</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.741722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.642384</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.662252</td>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.728477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.662252</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.814570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.801325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.682119</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.748344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.841060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.523179</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.754967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.602649</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.721854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.794702    0.801325  0.841060          0.841060       0.728477   \n",
       "1            0.688742    0.695364  0.821192          0.801325       0.642384   \n",
       "2            0.774834    0.794702  0.801325          0.814570       0.768212   \n",
       "3            0.761589    0.721854  0.754967          0.794702       0.794702   \n",
       "4            0.688742    0.735099  0.781457          0.774834       0.675497   \n",
       "5            0.701987    0.649007  0.715232          0.735099       0.748344   \n",
       "6            0.688742    0.695364  0.821192          0.801325       0.642384   \n",
       "7            0.748344    0.801325  0.801325          0.834437       0.662252   \n",
       "8            0.708609    0.774834  0.781457          0.801325       0.735099   \n",
       "9            0.788079    0.721854  0.708609          0.781457       0.708609   \n",
       "10           0.768212    0.801325  0.841060          0.847682       0.715232   \n",
       "11           0.721854    0.774834  0.788079          0.794702       0.708609   \n",
       "12           0.715232    0.754967  0.741722          0.741722       0.602649   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.807947    0.523179  0.781457     0.741722  0.748344  0.807947  \n",
       "1        0.781457    0.516556  0.701987     0.662252  0.721854  0.728477  \n",
       "2        0.814570    0.516556  0.794702     0.735099  0.708609  0.781457  \n",
       "3        0.788079    0.516556  0.807947     0.682119  0.708609  0.788079  \n",
       "4        0.768212    0.516556  0.728477     0.788079  0.708609  0.748344  \n",
       "5        0.748344    0.516556  0.735099     0.649007  0.701987  0.741722  \n",
       "6        0.788079    0.516556  0.701987     0.662252  0.688742  0.728477  \n",
       "7        0.807947    0.516556  0.781457     0.728477  0.814570  0.814570  \n",
       "8        0.774834    0.516556  0.708609     0.774834  0.741722  0.801325  \n",
       "9        0.814570    0.516556  0.682119     0.708609  0.788079  0.748344  \n",
       "10       0.807947    0.516556  0.821192     0.741722  0.807947  0.841060  \n",
       "11       0.768212    0.523179  0.708609     0.781457  0.794702  0.754967  \n",
       "12       0.728477    0.516556  0.708609     0.774834  0.801325  0.721854  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- F1 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.794250</td>\n",
       "      <td>0.799524</td>\n",
       "      <td>0.840597</td>\n",
       "      <td>0.840808</td>\n",
       "      <td>0.723926</td>\n",
       "      <td>0.806877</td>\n",
       "      <td>0.366499</td>\n",
       "      <td>0.778530</td>\n",
       "      <td>0.737393</td>\n",
       "      <td>0.741572</td>\n",
       "      <td>0.805948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.681061</td>\n",
       "      <td>0.678535</td>\n",
       "      <td>0.821003</td>\n",
       "      <td>0.800746</td>\n",
       "      <td>0.632760</td>\n",
       "      <td>0.781399</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.700326</td>\n",
       "      <td>0.652372</td>\n",
       "      <td>0.714369</td>\n",
       "      <td>0.727470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.770649</td>\n",
       "      <td>0.792565</td>\n",
       "      <td>0.800412</td>\n",
       "      <td>0.813717</td>\n",
       "      <td>0.766920</td>\n",
       "      <td>0.813337</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.793099</td>\n",
       "      <td>0.731959</td>\n",
       "      <td>0.694429</td>\n",
       "      <td>0.778530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.755173</td>\n",
       "      <td>0.710017</td>\n",
       "      <td>0.753054</td>\n",
       "      <td>0.792565</td>\n",
       "      <td>0.794576</td>\n",
       "      <td>0.784140</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.804728</td>\n",
       "      <td>0.672044</td>\n",
       "      <td>0.700767</td>\n",
       "      <td>0.786159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.686312</td>\n",
       "      <td>0.726704</td>\n",
       "      <td>0.777794</td>\n",
       "      <td>0.772794</td>\n",
       "      <td>0.651526</td>\n",
       "      <td>0.767701</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.726963</td>\n",
       "      <td>0.787106</td>\n",
       "      <td>0.696209</td>\n",
       "      <td>0.746672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.691781</td>\n",
       "      <td>0.610105</td>\n",
       "      <td>0.703934</td>\n",
       "      <td>0.725323</td>\n",
       "      <td>0.746672</td>\n",
       "      <td>0.744563</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.727970</td>\n",
       "      <td>0.636987</td>\n",
       "      <td>0.679973</td>\n",
       "      <td>0.732877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.681061</td>\n",
       "      <td>0.678535</td>\n",
       "      <td>0.821003</td>\n",
       "      <td>0.800746</td>\n",
       "      <td>0.632760</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.700326</td>\n",
       "      <td>0.652372</td>\n",
       "      <td>0.676393</td>\n",
       "      <td>0.727470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.747612</td>\n",
       "      <td>0.800004</td>\n",
       "      <td>0.800412</td>\n",
       "      <td>0.834262</td>\n",
       "      <td>0.655322</td>\n",
       "      <td>0.806448</td>\n",
       "      <td>0.363331</td>\n",
       "      <td>0.779182</td>\n",
       "      <td>0.725650</td>\n",
       "      <td>0.814602</td>\n",
       "      <td>0.813717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.705155</td>\n",
       "      <td>0.769758</td>\n",
       "      <td>0.779751</td>\n",
       "      <td>0.800004</td>\n",
       "      <td>0.735146</td>\n",
       "      <td>0.773338</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.706673</td>\n",
       "      <td>0.773800</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.800412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.786671</td>\n",
       "      <td>0.716684</td>\n",
       "      <td>0.707761</td>\n",
       "      <td>0.780239</td>\n",
       "      <td>0.707533</td>\n",
       "      <td>0.814602</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.682175</td>\n",
       "      <td>0.708148</td>\n",
       "      <td>0.784140</td>\n",
       "      <td>0.747188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.767353</td>\n",
       "      <td>0.799524</td>\n",
       "      <td>0.840004</td>\n",
       "      <td>0.846833</td>\n",
       "      <td>0.712267</td>\n",
       "      <td>0.807235</td>\n",
       "      <td>0.363331</td>\n",
       "      <td>0.819796</td>\n",
       "      <td>0.739033</td>\n",
       "      <td>0.806448</td>\n",
       "      <td>0.840962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.717675</td>\n",
       "      <td>0.773800</td>\n",
       "      <td>0.787949</td>\n",
       "      <td>0.792565</td>\n",
       "      <td>0.690452</td>\n",
       "      <td>0.766920</td>\n",
       "      <td>0.366499</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.779182</td>\n",
       "      <td>0.793941</td>\n",
       "      <td>0.754058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.703934</td>\n",
       "      <td>0.748920</td>\n",
       "      <td>0.735348</td>\n",
       "      <td>0.737393</td>\n",
       "      <td>0.556501</td>\n",
       "      <td>0.725650</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.705155</td>\n",
       "      <td>0.773800</td>\n",
       "      <td>0.800412</td>\n",
       "      <td>0.717675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.794250    0.799524  0.840597          0.840808       0.723926   \n",
       "1            0.681061    0.678535  0.821003          0.800746       0.632760   \n",
       "2            0.770649    0.792565  0.800412          0.813717       0.766920   \n",
       "3            0.755173    0.710017  0.753054          0.792565       0.794576   \n",
       "4            0.686312    0.726704  0.777794          0.772794       0.651526   \n",
       "5            0.691781    0.610105  0.703934          0.725323       0.746672   \n",
       "6            0.681061    0.678535  0.821003          0.800746       0.632760   \n",
       "7            0.747612    0.800004  0.800412          0.834262       0.655322   \n",
       "8            0.705155    0.769758  0.779751          0.800004       0.735146   \n",
       "9            0.786671    0.716684  0.707761          0.780239       0.707533   \n",
       "10           0.767353    0.799524  0.840004          0.846833       0.712267   \n",
       "11           0.717675    0.773800  0.787949          0.792565       0.690452   \n",
       "12           0.703934    0.748920  0.735348          0.737393       0.556501   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.806877    0.366499  0.778530     0.737393  0.741572  0.805948  \n",
       "1        0.781399    0.351890  0.700326     0.652372  0.714369  0.727470  \n",
       "2        0.813337    0.351890  0.793099     0.731959  0.694429  0.778530  \n",
       "3        0.784140    0.351890  0.804728     0.672044  0.700767  0.786159  \n",
       "4        0.767701    0.351890  0.726963     0.787106  0.696209  0.746672  \n",
       "5        0.744563    0.351890  0.727970     0.636987  0.679973  0.732877  \n",
       "6        0.788079    0.351890  0.700326     0.652372  0.676393  0.727470  \n",
       "7        0.806448    0.363331  0.779182     0.725650  0.814602  0.813717  \n",
       "8        0.773338    0.351890  0.706673     0.773800  0.741722  0.800412  \n",
       "9        0.814602    0.351890  0.682175     0.708148  0.784140  0.747188  \n",
       "10       0.807235    0.363331  0.819796     0.739033  0.806448  0.840962  \n",
       "11       0.766920    0.366499  0.708609     0.779182  0.793941  0.754058  \n",
       "12       0.725650    0.351890  0.705155     0.773800  0.800412  0.717675  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Precision Score ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.795553</td>\n",
       "      <td>0.808142</td>\n",
       "      <td>0.842818</td>\n",
       "      <td>0.841743</td>\n",
       "      <td>0.738719</td>\n",
       "      <td>0.811651</td>\n",
       "      <td>0.752053</td>\n",
       "      <td>0.791678</td>\n",
       "      <td>0.752790</td>\n",
       "      <td>0.769199</td>\n",
       "      <td>0.816336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.701736</td>\n",
       "      <td>0.734318</td>\n",
       "      <td>0.821465</td>\n",
       "      <td>0.802722</td>\n",
       "      <td>0.652040</td>\n",
       "      <td>0.781410</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.703721</td>\n",
       "      <td>0.675402</td>\n",
       "      <td>0.739909</td>\n",
       "      <td>0.729625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.789780</td>\n",
       "      <td>0.802602</td>\n",
       "      <td>0.804064</td>\n",
       "      <td>0.817508</td>\n",
       "      <td>0.771177</td>\n",
       "      <td>0.819407</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.800141</td>\n",
       "      <td>0.741880</td>\n",
       "      <td>0.744332</td>\n",
       "      <td>0.791678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.783844</td>\n",
       "      <td>0.754237</td>\n",
       "      <td>0.759337</td>\n",
       "      <td>0.802602</td>\n",
       "      <td>0.797877</td>\n",
       "      <td>0.803951</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.823141</td>\n",
       "      <td>0.699292</td>\n",
       "      <td>0.725264</td>\n",
       "      <td>0.794478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.691329</td>\n",
       "      <td>0.759014</td>\n",
       "      <td>0.795001</td>\n",
       "      <td>0.780813</td>\n",
       "      <td>0.726279</td>\n",
       "      <td>0.768887</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.730703</td>\n",
       "      <td>0.790619</td>\n",
       "      <td>0.738620</td>\n",
       "      <td>0.751689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.723754</td>\n",
       "      <td>0.725154</td>\n",
       "      <td>0.743737</td>\n",
       "      <td>0.764090</td>\n",
       "      <td>0.751689</td>\n",
       "      <td>0.758331</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.754554</td>\n",
       "      <td>0.663406</td>\n",
       "      <td>0.762120</td>\n",
       "      <td>0.769014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.701736</td>\n",
       "      <td>0.734318</td>\n",
       "      <td>0.821465</td>\n",
       "      <td>0.802722</td>\n",
       "      <td>0.652040</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.703721</td>\n",
       "      <td>0.675402</td>\n",
       "      <td>0.712879</td>\n",
       "      <td>0.729625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.749262</td>\n",
       "      <td>0.805864</td>\n",
       "      <td>0.804064</td>\n",
       "      <td>0.834749</td>\n",
       "      <td>0.670371</td>\n",
       "      <td>0.813743</td>\n",
       "      <td>0.508667</td>\n",
       "      <td>0.788868</td>\n",
       "      <td>0.733933</td>\n",
       "      <td>0.815778</td>\n",
       "      <td>0.817508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.714263</td>\n",
       "      <td>0.793832</td>\n",
       "      <td>0.786540</td>\n",
       "      <td>0.805864</td>\n",
       "      <td>0.736224</td>\n",
       "      <td>0.778776</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.711058</td>\n",
       "      <td>0.777175</td>\n",
       "      <td>0.743350</td>\n",
       "      <td>0.804064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.792320</td>\n",
       "      <td>0.733098</td>\n",
       "      <td>0.709167</td>\n",
       "      <td>0.784668</td>\n",
       "      <td>0.715522</td>\n",
       "      <td>0.815778</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.683188</td>\n",
       "      <td>0.708684</td>\n",
       "      <td>0.803951</td>\n",
       "      <td>0.750287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.769832</td>\n",
       "      <td>0.808142</td>\n",
       "      <td>0.846495</td>\n",
       "      <td>0.852124</td>\n",
       "      <td>0.720199</td>\n",
       "      <td>0.810038</td>\n",
       "      <td>0.508667</td>\n",
       "      <td>0.827344</td>\n",
       "      <td>0.747666</td>\n",
       "      <td>0.813743</td>\n",
       "      <td>0.841160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.730378</td>\n",
       "      <td>0.777175</td>\n",
       "      <td>0.788096</td>\n",
       "      <td>0.802602</td>\n",
       "      <td>0.758148</td>\n",
       "      <td>0.771177</td>\n",
       "      <td>0.752053</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.788868</td>\n",
       "      <td>0.796636</td>\n",
       "      <td>0.756430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.743737</td>\n",
       "      <td>0.774310</td>\n",
       "      <td>0.759795</td>\n",
       "      <td>0.752790</td>\n",
       "      <td>0.653877</td>\n",
       "      <td>0.733933</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.714263</td>\n",
       "      <td>0.777175</td>\n",
       "      <td>0.804064</td>\n",
       "      <td>0.730378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.795553    0.808142  0.842818          0.841743       0.738719   \n",
       "1            0.701736    0.734318  0.821465          0.802722       0.652040   \n",
       "2            0.789780    0.802602  0.804064          0.817508       0.771177   \n",
       "3            0.783844    0.754237  0.759337          0.802602       0.797877   \n",
       "4            0.691329    0.759014  0.795001          0.780813       0.726279   \n",
       "5            0.723754    0.725154  0.743737          0.764090       0.751689   \n",
       "6            0.701736    0.734318  0.821465          0.802722       0.652040   \n",
       "7            0.749262    0.805864  0.804064          0.834749       0.670371   \n",
       "8            0.714263    0.793832  0.786540          0.805864       0.736224   \n",
       "9            0.792320    0.733098  0.709167          0.784668       0.715522   \n",
       "10           0.769832    0.808142  0.846495          0.852124       0.720199   \n",
       "11           0.730378    0.777175  0.788096          0.802602       0.758148   \n",
       "12           0.743737    0.774310  0.759795          0.752790       0.653877   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.811651    0.752053  0.791678     0.752790  0.769199  0.816336  \n",
       "1        0.781410    0.266830  0.703721     0.675402  0.739909  0.729625  \n",
       "2        0.819407    0.266830  0.800141     0.741880  0.744332  0.791678  \n",
       "3        0.803951    0.266830  0.823141     0.699292  0.725264  0.794478  \n",
       "4        0.768887    0.266830  0.730703     0.790619  0.738620  0.751689  \n",
       "5        0.758331    0.266830  0.754554     0.663406  0.762120  0.769014  \n",
       "6        0.788079    0.266830  0.703721     0.675402  0.712879  0.729625  \n",
       "7        0.813743    0.508667  0.788868     0.733933  0.815778  0.817508  \n",
       "8        0.778776    0.266830  0.711058     0.777175  0.743350  0.804064  \n",
       "9        0.815778    0.266830  0.683188     0.708684  0.803951  0.750287  \n",
       "10       0.810038    0.508667  0.827344     0.747666  0.813743  0.841160  \n",
       "11       0.771177    0.752053  0.708609     0.788868  0.796636  0.756430  \n",
       "12       0.733933    0.266830  0.714263     0.777175  0.804064  0.730378  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Recall Score ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.523179</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.807947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.642384</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.662252</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.728477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.781457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.682119</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.788079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.748344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.649007</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.649007</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.741722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.642384</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.662252</td>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.728477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.662252</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.814570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.801325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.682119</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.748344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.841060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.523179</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.754967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.602649</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.721854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.794702    0.801325  0.841060          0.841060       0.728477   \n",
       "1            0.688742    0.695364  0.821192          0.801325       0.642384   \n",
       "2            0.774834    0.794702  0.801325          0.814570       0.768212   \n",
       "3            0.761589    0.721854  0.754967          0.794702       0.794702   \n",
       "4            0.688742    0.735099  0.781457          0.774834       0.675497   \n",
       "5            0.701987    0.649007  0.715232          0.735099       0.748344   \n",
       "6            0.688742    0.695364  0.821192          0.801325       0.642384   \n",
       "7            0.748344    0.801325  0.801325          0.834437       0.662252   \n",
       "8            0.708609    0.774834  0.781457          0.801325       0.735099   \n",
       "9            0.788079    0.721854  0.708609          0.781457       0.708609   \n",
       "10           0.768212    0.801325  0.841060          0.847682       0.715232   \n",
       "11           0.721854    0.774834  0.788079          0.794702       0.708609   \n",
       "12           0.715232    0.754967  0.741722          0.741722       0.602649   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.807947    0.523179  0.781457     0.741722  0.748344  0.807947  \n",
       "1        0.781457    0.516556  0.701987     0.662252  0.721854  0.728477  \n",
       "2        0.814570    0.516556  0.794702     0.735099  0.708609  0.781457  \n",
       "3        0.788079    0.516556  0.807947     0.682119  0.708609  0.788079  \n",
       "4        0.768212    0.516556  0.728477     0.788079  0.708609  0.748344  \n",
       "5        0.748344    0.516556  0.735099     0.649007  0.701987  0.741722  \n",
       "6        0.788079    0.516556  0.701987     0.662252  0.688742  0.728477  \n",
       "7        0.807947    0.516556  0.781457     0.728477  0.814570  0.814570  \n",
       "8        0.774834    0.516556  0.708609     0.774834  0.741722  0.801325  \n",
       "9        0.814570    0.516556  0.682119     0.708609  0.788079  0.748344  \n",
       "10       0.807947    0.516556  0.821192     0.741722  0.807947  0.841060  \n",
       "11       0.768212    0.523179  0.708609     0.781457  0.794702  0.754967  \n",
       "12       0.728477    0.516556  0.708609     0.774834  0.801325  0.721854  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Matriz confusao ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[55, 18], [13, 65]]</td>\n",
       "      <td>[[52, 21], [9, 69]]</td>\n",
       "      <td>[[58, 15], [9, 69]]</td>\n",
       "      <td>[[59, 14], [10, 68]]</td>\n",
       "      <td>[[44, 29], [12, 66]]</td>\n",
       "      <td>[[54, 19], [10, 68]]</td>\n",
       "      <td>[[1, 72], [0, 78]]</td>\n",
       "      <td>[[49, 24], [9, 69]]</td>\n",
       "      <td>[[45, 28], [11, 67]]</td>\n",
       "      <td>[[43, 30], [8, 70]]</td>\n",
       "      <td>[[52, 21], [8, 70]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[39, 34], [13, 65]]</td>\n",
       "      <td>[[34, 39], [7, 71]]</td>\n",
       "      <td>[[58, 15], [12, 66]]</td>\n",
       "      <td>[[55, 18], [12, 66]]</td>\n",
       "      <td>[[35, 38], [16, 62]]</td>\n",
       "      <td>[[56, 17], [16, 62]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[46, 27], [18, 60]]</td>\n",
       "      <td>[[36, 37], [14, 64]]</td>\n",
       "      <td>[[41, 32], [10, 68]]</td>\n",
       "      <td>[[49, 24], [17, 61]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[47, 26], [8, 70]]</td>\n",
       "      <td>[[51, 22], [9, 69]]</td>\n",
       "      <td>[[54, 19], [11, 67]]</td>\n",
       "      <td>[[55, 18], [10, 68]]</td>\n",
       "      <td>[[51, 22], [13, 65]]</td>\n",
       "      <td>[[54, 19], [9, 69]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[52, 21], [10, 68]]</td>\n",
       "      <td>[[46, 27], [13, 65]]</td>\n",
       "      <td>[[36, 37], [7, 71]]</td>\n",
       "      <td>[[49, 24], [9, 69]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[44, 29], [7, 71]]</td>\n",
       "      <td>[[38, 35], [7, 71]]</td>\n",
       "      <td>[[49, 24], [13, 65]]</td>\n",
       "      <td>[[51, 22], [9, 69]]</td>\n",
       "      <td>[[61, 12], [19, 59]]</td>\n",
       "      <td>[[48, 25], [7, 71]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[50, 23], [6, 72]]</td>\n",
       "      <td>[[37, 36], [12, 66]]</td>\n",
       "      <td>[[40, 33], [11, 67]]</td>\n",
       "      <td>[[51, 22], [10, 68]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[44, 29], [18, 60]]</td>\n",
       "      <td>[[41, 32], [8, 70]]</td>\n",
       "      <td>[[48, 25], [8, 70]]</td>\n",
       "      <td>[[50, 23], [11, 67]]</td>\n",
       "      <td>[[30, 43], [6, 72]]</td>\n",
       "      <td>[[53, 20], [15, 63]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[48, 25], [16, 62]]</td>\n",
       "      <td>[[53, 20], [12, 66]]</td>\n",
       "      <td>[[37, 36], [8, 70]]</td>\n",
       "      <td>[[49, 24], [14, 64]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[[38, 35], [10, 68]]</td>\n",
       "      <td>[[24, 49], [4, 74]]</td>\n",
       "      <td>[[38, 35], [8, 70]]</td>\n",
       "      <td>[[40, 33], [7, 71]]</td>\n",
       "      <td>[[49, 24], [14, 64]]</td>\n",
       "      <td>[[46, 27], [11, 67]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[42, 31], [9, 69]]</td>\n",
       "      <td>[[34, 39], [14, 64]]</td>\n",
       "      <td>[[32, 41], [4, 74]]</td>\n",
       "      <td>[[41, 32], [7, 71]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[[39, 34], [13, 65]]</td>\n",
       "      <td>[[34, 39], [7, 71]]</td>\n",
       "      <td>[[58, 15], [12, 66]]</td>\n",
       "      <td>[[55, 18], [12, 66]]</td>\n",
       "      <td>[[35, 38], [16, 62]]</td>\n",
       "      <td>[[57, 16], [16, 62]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[46, 27], [18, 60]]</td>\n",
       "      <td>[[36, 37], [14, 64]]</td>\n",
       "      <td>[[36, 37], [10, 68]]</td>\n",
       "      <td>[[49, 24], [17, 61]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[[51, 22], [16, 62]]</td>\n",
       "      <td>[[53, 20], [10, 68]]</td>\n",
       "      <td>[[54, 19], [11, 67]]</td>\n",
       "      <td>[[59, 14], [11, 67]]</td>\n",
       "      <td>[[38, 35], [16, 62]]</td>\n",
       "      <td>[[53, 20], [9, 69]]</td>\n",
       "      <td>[[1, 72], [1, 77]]</td>\n",
       "      <td>[[50, 23], [10, 68]]</td>\n",
       "      <td>[[46, 27], [14, 64]]</td>\n",
       "      <td>[[61, 12], [16, 62]]</td>\n",
       "      <td>[[55, 18], [10, 68]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[[44, 29], [15, 63]]</td>\n",
       "      <td>[[46, 27], [7, 71]]</td>\n",
       "      <td>[[51, 22], [11, 67]]</td>\n",
       "      <td>[[53, 20], [10, 68]]</td>\n",
       "      <td>[[55, 18], [22, 56]]</td>\n",
       "      <td>[[51, 22], [12, 66]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[46, 27], [17, 61]]</td>\n",
       "      <td>[[52, 21], [13, 65]]</td>\n",
       "      <td>[[56, 17], [22, 56]]</td>\n",
       "      <td>[[54, 19], [11, 67]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[[52, 21], [11, 67]]</td>\n",
       "      <td>[[43, 30], [12, 66]]</td>\n",
       "      <td>[[48, 25], [19, 59]]</td>\n",
       "      <td>[[52, 21], [12, 66]]</td>\n",
       "      <td>[[57, 16], [28, 50]]</td>\n",
       "      <td>[[61, 12], [16, 62]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[51, 22], [26, 52]]</td>\n",
       "      <td>[[49, 24], [20, 58]]</td>\n",
       "      <td>[[48, 25], [7, 71]]</td>\n",
       "      <td>[[50, 23], [15, 63]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[[52, 21], [14, 64]]</td>\n",
       "      <td>[[52, 21], [9, 69]]</td>\n",
       "      <td>[[56, 17], [7, 71]]</td>\n",
       "      <td>[[57, 16], [7, 71]]</td>\n",
       "      <td>[[45, 28], [15, 63]]</td>\n",
       "      <td>[[55, 18], [11, 67]]</td>\n",
       "      <td>[[1, 72], [1, 77]]</td>\n",
       "      <td>[[54, 19], [8, 70]]</td>\n",
       "      <td>[[47, 26], [13, 65]]</td>\n",
       "      <td>[[53, 20], [9, 69]]</td>\n",
       "      <td>[[60, 13], [11, 67]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[[44, 29], [13, 65]]</td>\n",
       "      <td>[[52, 21], [13, 65]]</td>\n",
       "      <td>[[56, 17], [15, 63]]</td>\n",
       "      <td>[[51, 22], [9, 69]]</td>\n",
       "      <td>[[34, 39], [5, 73]]</td>\n",
       "      <td>[[51, 22], [13, 65]]</td>\n",
       "      <td>[[1, 72], [0, 78]]</td>\n",
       "      <td>[[51, 22], [22, 56]]</td>\n",
       "      <td>[[50, 23], [10, 68]]</td>\n",
       "      <td>[[54, 19], [12, 66]]</td>\n",
       "      <td>[[51, 22], [15, 63]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[[38, 35], [8, 70]]</td>\n",
       "      <td>[[44, 29], [8, 70]]</td>\n",
       "      <td>[[43, 30], [9, 69]]</td>\n",
       "      <td>[[45, 28], [11, 67]]</td>\n",
       "      <td>[[20, 53], [7, 71]]</td>\n",
       "      <td>[[46, 27], [14, 64]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[44, 29], [15, 63]]</td>\n",
       "      <td>[[52, 21], [13, 65]]</td>\n",
       "      <td>[[54, 19], [11, 67]]</td>\n",
       "      <td>[[44, 29], [13, 65]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Nearest Neighbors            Linear SVM               RBF SVM  \\\n",
       "0   [[55, 18], [13, 65]]   [[52, 21], [9, 69]]   [[58, 15], [9, 69]]   \n",
       "1   [[39, 34], [13, 65]]   [[34, 39], [7, 71]]  [[58, 15], [12, 66]]   \n",
       "2    [[47, 26], [8, 70]]   [[51, 22], [9, 69]]  [[54, 19], [11, 67]]   \n",
       "3    [[44, 29], [7, 71]]   [[38, 35], [7, 71]]  [[49, 24], [13, 65]]   \n",
       "4   [[44, 29], [18, 60]]   [[41, 32], [8, 70]]   [[48, 25], [8, 70]]   \n",
       "5   [[38, 35], [10, 68]]   [[24, 49], [4, 74]]   [[38, 35], [8, 70]]   \n",
       "6   [[39, 34], [13, 65]]   [[34, 39], [7, 71]]  [[58, 15], [12, 66]]   \n",
       "7   [[51, 22], [16, 62]]  [[53, 20], [10, 68]]  [[54, 19], [11, 67]]   \n",
       "8   [[44, 29], [15, 63]]   [[46, 27], [7, 71]]  [[51, 22], [11, 67]]   \n",
       "9   [[52, 21], [11, 67]]  [[43, 30], [12, 66]]  [[48, 25], [19, 59]]   \n",
       "10  [[52, 21], [14, 64]]   [[52, 21], [9, 69]]   [[56, 17], [7, 71]]   \n",
       "11  [[44, 29], [13, 65]]  [[52, 21], [13, 65]]  [[56, 17], [15, 63]]   \n",
       "12   [[38, 35], [8, 70]]   [[44, 29], [8, 70]]   [[43, 30], [9, 69]]   \n",
       "\n",
       "        Gaussian Process         Decision Tree         Random Forest  \\\n",
       "0   [[59, 14], [10, 68]]  [[44, 29], [12, 66]]  [[54, 19], [10, 68]]   \n",
       "1   [[55, 18], [12, 66]]  [[35, 38], [16, 62]]  [[56, 17], [16, 62]]   \n",
       "2   [[55, 18], [10, 68]]  [[51, 22], [13, 65]]   [[54, 19], [9, 69]]   \n",
       "3    [[51, 22], [9, 69]]  [[61, 12], [19, 59]]   [[48, 25], [7, 71]]   \n",
       "4   [[50, 23], [11, 67]]   [[30, 43], [6, 72]]  [[53, 20], [15, 63]]   \n",
       "5    [[40, 33], [7, 71]]  [[49, 24], [14, 64]]  [[46, 27], [11, 67]]   \n",
       "6   [[55, 18], [12, 66]]  [[35, 38], [16, 62]]  [[57, 16], [16, 62]]   \n",
       "7   [[59, 14], [11, 67]]  [[38, 35], [16, 62]]   [[53, 20], [9, 69]]   \n",
       "8   [[53, 20], [10, 68]]  [[55, 18], [22, 56]]  [[51, 22], [12, 66]]   \n",
       "9   [[52, 21], [12, 66]]  [[57, 16], [28, 50]]  [[61, 12], [16, 62]]   \n",
       "10   [[57, 16], [7, 71]]  [[45, 28], [15, 63]]  [[55, 18], [11, 67]]   \n",
       "11   [[51, 22], [9, 69]]   [[34, 39], [5, 73]]  [[51, 22], [13, 65]]   \n",
       "12  [[45, 28], [11, 67]]   [[20, 53], [7, 71]]  [[46, 27], [14, 64]]   \n",
       "\n",
       "            Neural Net              AdaBoost           Naive Bayes  \\\n",
       "0   [[1, 72], [0, 78]]   [[49, 24], [9, 69]]  [[45, 28], [11, 67]]   \n",
       "1   [[0, 73], [0, 78]]  [[46, 27], [18, 60]]  [[36, 37], [14, 64]]   \n",
       "2   [[0, 73], [0, 78]]  [[52, 21], [10, 68]]  [[46, 27], [13, 65]]   \n",
       "3   [[0, 73], [0, 78]]   [[50, 23], [6, 72]]  [[37, 36], [12, 66]]   \n",
       "4   [[0, 73], [0, 78]]  [[48, 25], [16, 62]]  [[53, 20], [12, 66]]   \n",
       "5   [[0, 73], [0, 78]]   [[42, 31], [9, 69]]  [[34, 39], [14, 64]]   \n",
       "6   [[0, 73], [0, 78]]  [[46, 27], [18, 60]]  [[36, 37], [14, 64]]   \n",
       "7   [[1, 72], [1, 77]]  [[50, 23], [10, 68]]  [[46, 27], [14, 64]]   \n",
       "8   [[0, 73], [0, 78]]  [[46, 27], [17, 61]]  [[52, 21], [13, 65]]   \n",
       "9   [[0, 73], [0, 78]]  [[51, 22], [26, 52]]  [[49, 24], [20, 58]]   \n",
       "10  [[1, 72], [1, 77]]   [[54, 19], [8, 70]]  [[47, 26], [13, 65]]   \n",
       "11  [[1, 72], [0, 78]]  [[51, 22], [22, 56]]  [[50, 23], [10, 68]]   \n",
       "12  [[0, 73], [0, 78]]  [[44, 29], [15, 63]]  [[52, 21], [13, 65]]   \n",
       "\n",
       "                     QDA               XGBoost  \n",
       "0    [[43, 30], [8, 70]]   [[52, 21], [8, 70]]  \n",
       "1   [[41, 32], [10, 68]]  [[49, 24], [17, 61]]  \n",
       "2    [[36, 37], [7, 71]]   [[49, 24], [9, 69]]  \n",
       "3   [[40, 33], [11, 67]]  [[51, 22], [10, 68]]  \n",
       "4    [[37, 36], [8, 70]]  [[49, 24], [14, 64]]  \n",
       "5    [[32, 41], [4, 74]]   [[41, 32], [7, 71]]  \n",
       "6   [[36, 37], [10, 68]]  [[49, 24], [17, 61]]  \n",
       "7   [[61, 12], [16, 62]]  [[55, 18], [10, 68]]  \n",
       "8   [[56, 17], [22, 56]]  [[54, 19], [11, 67]]  \n",
       "9    [[48, 25], [7, 71]]  [[50, 23], [15, 63]]  \n",
       "10   [[53, 20], [9, 69]]  [[60, 13], [11, 67]]  \n",
       "11  [[54, 19], [12, 66]]  [[51, 22], [15, 63]]  \n",
       "12  [[54, 19], [11, 67]]  [[44, 29], [13, 65]]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ 24 pontos - 3 raio ------\n",
      "--- Acuracia ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.860927</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.860927</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.814570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.662252</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.662252</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.721854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.807947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.748344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.774834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.629139</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.682119</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.649007</td>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.754967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.662252</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.662252</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.721854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.523179</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.794702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.788079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.682119</td>\n",
       "      <td>0.748344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.807947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.781457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.754967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.781457    0.801325  0.854305          0.860927       0.728477   \n",
       "1            0.715232    0.695364  0.801325          0.788079       0.662252   \n",
       "2            0.774834    0.807947  0.821192          0.841060       0.735099   \n",
       "3            0.748344    0.728477  0.814570          0.814570       0.774834   \n",
       "4            0.721854    0.728477  0.794702          0.794702       0.728477   \n",
       "5            0.688742    0.629139  0.701987          0.721854       0.682119   \n",
       "6            0.715232    0.695364  0.801325          0.788079       0.662252   \n",
       "7            0.748344    0.807947  0.821192          0.814570       0.748344   \n",
       "8            0.721854    0.754967  0.774834          0.781457       0.735099   \n",
       "9            0.761589    0.728477  0.768212          0.774834       0.701987   \n",
       "10           0.761589    0.794702  0.807947          0.814570       0.721854   \n",
       "11           0.695364    0.708609  0.768212          0.781457       0.735099   \n",
       "12           0.701987    0.728477  0.761589          0.715232       0.721854   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.860927    0.516556  0.801325     0.748344  0.768212  0.814570  \n",
       "1        0.721854    0.516556  0.721854     0.662252  0.708609  0.721854  \n",
       "2        0.807947    0.516556  0.741722     0.754967  0.728477  0.807947  \n",
       "3        0.768212    0.516556  0.774834     0.701987  0.735099  0.748344  \n",
       "4        0.768212    0.516556  0.688742     0.768212  0.701987  0.774834  \n",
       "5        0.748344    0.516556  0.715232     0.649007  0.675497  0.754967  \n",
       "6        0.728477    0.516556  0.721854     0.662252  0.695364  0.721854  \n",
       "7        0.854305    0.523179  0.748344     0.735099  0.715232  0.794702  \n",
       "8        0.748344    0.516556  0.701987     0.781457  0.695364  0.788079  \n",
       "9        0.801325    0.516556  0.735099     0.708609  0.682119  0.748344  \n",
       "10       0.827815    0.516556  0.794702     0.735099  0.761589  0.807947  \n",
       "11       0.774834    0.516556  0.741722     0.768212  0.701987  0.781457  \n",
       "12       0.781457    0.516556  0.695364     0.781457  0.741722  0.754967  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- F1 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.781226</td>\n",
       "      <td>0.798969</td>\n",
       "      <td>0.853881</td>\n",
       "      <td>0.860412</td>\n",
       "      <td>0.717704</td>\n",
       "      <td>0.860412</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.799524</td>\n",
       "      <td>0.744563</td>\n",
       "      <td>0.764327</td>\n",
       "      <td>0.813337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.708204</td>\n",
       "      <td>0.676382</td>\n",
       "      <td>0.801010</td>\n",
       "      <td>0.787744</td>\n",
       "      <td>0.656591</td>\n",
       "      <td>0.721414</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.721414</td>\n",
       "      <td>0.650685</td>\n",
       "      <td>0.705155</td>\n",
       "      <td>0.721414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.771451</td>\n",
       "      <td>0.807235</td>\n",
       "      <td>0.820195</td>\n",
       "      <td>0.840004</td>\n",
       "      <td>0.730175</td>\n",
       "      <td>0.805375</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.739033</td>\n",
       "      <td>0.753054</td>\n",
       "      <td>0.720535</td>\n",
       "      <td>0.806448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.742670</td>\n",
       "      <td>0.717704</td>\n",
       "      <td>0.812371</td>\n",
       "      <td>0.813717</td>\n",
       "      <td>0.774894</td>\n",
       "      <td>0.765108</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.774179</td>\n",
       "      <td>0.691781</td>\n",
       "      <td>0.731959</td>\n",
       "      <td>0.746064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.720006</td>\n",
       "      <td>0.716108</td>\n",
       "      <td>0.792565</td>\n",
       "      <td>0.793558</td>\n",
       "      <td>0.725650</td>\n",
       "      <td>0.765799</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.686312</td>\n",
       "      <td>0.766920</td>\n",
       "      <td>0.695872</td>\n",
       "      <td>0.769758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.674563</td>\n",
       "      <td>0.581947</td>\n",
       "      <td>0.691781</td>\n",
       "      <td>0.711589</td>\n",
       "      <td>0.680007</td>\n",
       "      <td>0.746064</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.706902</td>\n",
       "      <td>0.640345</td>\n",
       "      <td>0.645909</td>\n",
       "      <td>0.750860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.708204</td>\n",
       "      <td>0.676382</td>\n",
       "      <td>0.801010</td>\n",
       "      <td>0.787744</td>\n",
       "      <td>0.656591</td>\n",
       "      <td>0.728405</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.721414</td>\n",
       "      <td>0.650685</td>\n",
       "      <td>0.691753</td>\n",
       "      <td>0.721414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.747188</td>\n",
       "      <td>0.806448</td>\n",
       "      <td>0.819331</td>\n",
       "      <td>0.813337</td>\n",
       "      <td>0.746672</td>\n",
       "      <td>0.853635</td>\n",
       "      <td>0.366499</td>\n",
       "      <td>0.746672</td>\n",
       "      <td>0.732699</td>\n",
       "      <td>0.702260</td>\n",
       "      <td>0.793558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.715583</td>\n",
       "      <td>0.749939</td>\n",
       "      <td>0.772165</td>\n",
       "      <td>0.780647</td>\n",
       "      <td>0.735030</td>\n",
       "      <td>0.746672</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.695872</td>\n",
       "      <td>0.780239</td>\n",
       "      <td>0.692604</td>\n",
       "      <td>0.786671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.760005</td>\n",
       "      <td>0.723926</td>\n",
       "      <td>0.766920</td>\n",
       "      <td>0.774179</td>\n",
       "      <td>0.701516</td>\n",
       "      <td>0.801010</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.734680</td>\n",
       "      <td>0.707761</td>\n",
       "      <td>0.680658</td>\n",
       "      <td>0.748190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.793099</td>\n",
       "      <td>0.807235</td>\n",
       "      <td>0.814030</td>\n",
       "      <td>0.721683</td>\n",
       "      <td>0.827314</td>\n",
       "      <td>0.363331</td>\n",
       "      <td>0.792565</td>\n",
       "      <td>0.732699</td>\n",
       "      <td>0.755173</td>\n",
       "      <td>0.806448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.690787</td>\n",
       "      <td>0.702039</td>\n",
       "      <td>0.764327</td>\n",
       "      <td>0.777794</td>\n",
       "      <td>0.732699</td>\n",
       "      <td>0.774478</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.741790</td>\n",
       "      <td>0.765108</td>\n",
       "      <td>0.694632</td>\n",
       "      <td>0.781226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.693270</td>\n",
       "      <td>0.717704</td>\n",
       "      <td>0.757158</td>\n",
       "      <td>0.708204</td>\n",
       "      <td>0.720576</td>\n",
       "      <td>0.779182</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.687166</td>\n",
       "      <td>0.779751</td>\n",
       "      <td>0.740282</td>\n",
       "      <td>0.749939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.781226    0.798969  0.853881          0.860412       0.717704   \n",
       "1            0.708204    0.676382  0.801010          0.787744       0.656591   \n",
       "2            0.771451    0.807235  0.820195          0.840004       0.730175   \n",
       "3            0.742670    0.717704  0.812371          0.813717       0.774894   \n",
       "4            0.720006    0.716108  0.792565          0.793558       0.725650   \n",
       "5            0.674563    0.581947  0.691781          0.711589       0.680007   \n",
       "6            0.708204    0.676382  0.801010          0.787744       0.656591   \n",
       "7            0.747188    0.806448  0.819331          0.813337       0.746672   \n",
       "8            0.715583    0.749939  0.772165          0.780647       0.735030   \n",
       "9            0.760005    0.723926  0.766920          0.774179       0.701516   \n",
       "10           0.761589    0.793099  0.807235          0.814030       0.721683   \n",
       "11           0.690787    0.702039  0.764327          0.777794       0.732699   \n",
       "12           0.693270    0.717704  0.757158          0.708204       0.720576   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.860412    0.351890  0.799524     0.744563  0.764327  0.813337  \n",
       "1        0.721414    0.351890  0.721414     0.650685  0.705155  0.721414  \n",
       "2        0.805375    0.351890  0.739033     0.753054  0.720535  0.806448  \n",
       "3        0.765108    0.351890  0.774179     0.691781  0.731959  0.746064  \n",
       "4        0.765799    0.351890  0.686312     0.766920  0.695872  0.769758  \n",
       "5        0.746064    0.351890  0.706902     0.640345  0.645909  0.750860  \n",
       "6        0.728405    0.351890  0.721414     0.650685  0.691753  0.721414  \n",
       "7        0.853635    0.366499  0.746672     0.732699  0.702260  0.793558  \n",
       "8        0.746672    0.351890  0.695872     0.780239  0.692604  0.786671  \n",
       "9        0.801010    0.351890  0.734680     0.707761  0.680658  0.748190  \n",
       "10       0.827314    0.363331  0.792565     0.732699  0.755173  0.806448  \n",
       "11       0.774478    0.351890  0.741790     0.765108  0.694632  0.781226  \n",
       "12       0.779182    0.351890  0.687166     0.779751  0.740282  0.749939  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Precision Score ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.781615</td>\n",
       "      <td>0.810924</td>\n",
       "      <td>0.856183</td>\n",
       "      <td>0.863646</td>\n",
       "      <td>0.759167</td>\n",
       "      <td>0.863646</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.808142</td>\n",
       "      <td>0.758331</td>\n",
       "      <td>0.780930</td>\n",
       "      <td>0.819407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.730765</td>\n",
       "      <td>0.741140</td>\n",
       "      <td>0.801825</td>\n",
       "      <td>0.788520</td>\n",
       "      <td>0.668368</td>\n",
       "      <td>0.721990</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.721990</td>\n",
       "      <td>0.678493</td>\n",
       "      <td>0.714263</td>\n",
       "      <td>0.721990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.786285</td>\n",
       "      <td>0.810038</td>\n",
       "      <td>0.825142</td>\n",
       "      <td>0.846495</td>\n",
       "      <td>0.747268</td>\n",
       "      <td>0.819457</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.747666</td>\n",
       "      <td>0.759337</td>\n",
       "      <td>0.749319</td>\n",
       "      <td>0.813743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.765047</td>\n",
       "      <td>0.759167</td>\n",
       "      <td>0.824733</td>\n",
       "      <td>0.817508</td>\n",
       "      <td>0.775225</td>\n",
       "      <td>0.777788</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.775992</td>\n",
       "      <td>0.723754</td>\n",
       "      <td>0.741880</td>\n",
       "      <td>0.753483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.724602</td>\n",
       "      <td>0.765109</td>\n",
       "      <td>0.802602</td>\n",
       "      <td>0.798160</td>\n",
       "      <td>0.733933</td>\n",
       "      <td>0.775134</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.691329</td>\n",
       "      <td>0.771177</td>\n",
       "      <td>0.713205</td>\n",
       "      <td>0.793832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.717664</td>\n",
       "      <td>0.709467</td>\n",
       "      <td>0.723754</td>\n",
       "      <td>0.748838</td>\n",
       "      <td>0.683971</td>\n",
       "      <td>0.753483</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.734535</td>\n",
       "      <td>0.658192</td>\n",
       "      <td>0.744233</td>\n",
       "      <td>0.766860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.730765</td>\n",
       "      <td>0.741140</td>\n",
       "      <td>0.801825</td>\n",
       "      <td>0.788520</td>\n",
       "      <td>0.668368</td>\n",
       "      <td>0.728398</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.721990</td>\n",
       "      <td>0.678493</td>\n",
       "      <td>0.700454</td>\n",
       "      <td>0.721990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.750287</td>\n",
       "      <td>0.813743</td>\n",
       "      <td>0.830069</td>\n",
       "      <td>0.819407</td>\n",
       "      <td>0.751689</td>\n",
       "      <td>0.857840</td>\n",
       "      <td>0.752053</td>\n",
       "      <td>0.751689</td>\n",
       "      <td>0.739818</td>\n",
       "      <td>0.749294</td>\n",
       "      <td>0.798160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.736262</td>\n",
       "      <td>0.770317</td>\n",
       "      <td>0.783307</td>\n",
       "      <td>0.783234</td>\n",
       "      <td>0.737286</td>\n",
       "      <td>0.751689</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.713205</td>\n",
       "      <td>0.784668</td>\n",
       "      <td>0.698824</td>\n",
       "      <td>0.792320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.765233</td>\n",
       "      <td>0.738719</td>\n",
       "      <td>0.771177</td>\n",
       "      <td>0.775992</td>\n",
       "      <td>0.706064</td>\n",
       "      <td>0.801825</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.735296</td>\n",
       "      <td>0.709167</td>\n",
       "      <td>0.683067</td>\n",
       "      <td>0.748298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.800141</td>\n",
       "      <td>0.810038</td>\n",
       "      <td>0.816087</td>\n",
       "      <td>0.721766</td>\n",
       "      <td>0.829453</td>\n",
       "      <td>0.508667</td>\n",
       "      <td>0.802602</td>\n",
       "      <td>0.739818</td>\n",
       "      <td>0.783844</td>\n",
       "      <td>0.813743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.702424</td>\n",
       "      <td>0.721870</td>\n",
       "      <td>0.780930</td>\n",
       "      <td>0.795001</td>\n",
       "      <td>0.739818</td>\n",
       "      <td>0.775214</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.742443</td>\n",
       "      <td>0.777788</td>\n",
       "      <td>0.716251</td>\n",
       "      <td>0.781615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.719752</td>\n",
       "      <td>0.759167</td>\n",
       "      <td>0.775610</td>\n",
       "      <td>0.730765</td>\n",
       "      <td>0.723399</td>\n",
       "      <td>0.788868</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.710619</td>\n",
       "      <td>0.786540</td>\n",
       "      <td>0.744195</td>\n",
       "      <td>0.770317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.781615    0.810924  0.856183          0.863646       0.759167   \n",
       "1            0.730765    0.741140  0.801825          0.788520       0.668368   \n",
       "2            0.786285    0.810038  0.825142          0.846495       0.747268   \n",
       "3            0.765047    0.759167  0.824733          0.817508       0.775225   \n",
       "4            0.724602    0.765109  0.802602          0.798160       0.733933   \n",
       "5            0.717664    0.709467  0.723754          0.748838       0.683971   \n",
       "6            0.730765    0.741140  0.801825          0.788520       0.668368   \n",
       "7            0.750287    0.813743  0.830069          0.819407       0.751689   \n",
       "8            0.736262    0.770317  0.783307          0.783234       0.737286   \n",
       "9            0.765233    0.738719  0.771177          0.775992       0.706064   \n",
       "10           0.761589    0.800141  0.810038          0.816087       0.721766   \n",
       "11           0.702424    0.721870  0.780930          0.795001       0.739818   \n",
       "12           0.719752    0.759167  0.775610          0.730765       0.723399   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.863646    0.266830  0.808142     0.758331  0.780930  0.819407  \n",
       "1        0.721990    0.266830  0.721990     0.678493  0.714263  0.721990  \n",
       "2        0.819457    0.266830  0.747666     0.759337  0.749319  0.813743  \n",
       "3        0.777788    0.266830  0.775992     0.723754  0.741880  0.753483  \n",
       "4        0.775134    0.266830  0.691329     0.771177  0.713205  0.793832  \n",
       "5        0.753483    0.266830  0.734535     0.658192  0.744233  0.766860  \n",
       "6        0.728398    0.266830  0.721990     0.678493  0.700454  0.721990  \n",
       "7        0.857840    0.752053  0.751689     0.739818  0.749294  0.798160  \n",
       "8        0.751689    0.266830  0.713205     0.784668  0.698824  0.792320  \n",
       "9        0.801825    0.266830  0.735296     0.709167  0.683067  0.748298  \n",
       "10       0.829453    0.508667  0.802602     0.739818  0.783844  0.813743  \n",
       "11       0.775214    0.266830  0.742443     0.777788  0.716251  0.781615  \n",
       "12       0.788868    0.266830  0.710619     0.786540  0.744195  0.770317  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Recall Score ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.860927</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.860927</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.814570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.662252</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.662252</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.721854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.841060</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.807947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.748344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.774834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.629139</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.682119</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.649007</td>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.754967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.662252</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.662252</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.721854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.523179</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.794702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.788079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.682119</td>\n",
       "      <td>0.748344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.807947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.781457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.754967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.781457    0.801325  0.854305          0.860927       0.728477   \n",
       "1            0.715232    0.695364  0.801325          0.788079       0.662252   \n",
       "2            0.774834    0.807947  0.821192          0.841060       0.735099   \n",
       "3            0.748344    0.728477  0.814570          0.814570       0.774834   \n",
       "4            0.721854    0.728477  0.794702          0.794702       0.728477   \n",
       "5            0.688742    0.629139  0.701987          0.721854       0.682119   \n",
       "6            0.715232    0.695364  0.801325          0.788079       0.662252   \n",
       "7            0.748344    0.807947  0.821192          0.814570       0.748344   \n",
       "8            0.721854    0.754967  0.774834          0.781457       0.735099   \n",
       "9            0.761589    0.728477  0.768212          0.774834       0.701987   \n",
       "10           0.761589    0.794702  0.807947          0.814570       0.721854   \n",
       "11           0.695364    0.708609  0.768212          0.781457       0.735099   \n",
       "12           0.701987    0.728477  0.761589          0.715232       0.721854   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.860927    0.516556  0.801325     0.748344  0.768212  0.814570  \n",
       "1        0.721854    0.516556  0.721854     0.662252  0.708609  0.721854  \n",
       "2        0.807947    0.516556  0.741722     0.754967  0.728477  0.807947  \n",
       "3        0.768212    0.516556  0.774834     0.701987  0.735099  0.748344  \n",
       "4        0.768212    0.516556  0.688742     0.768212  0.701987  0.774834  \n",
       "5        0.748344    0.516556  0.715232     0.649007  0.675497  0.754967  \n",
       "6        0.728477    0.516556  0.721854     0.662252  0.695364  0.721854  \n",
       "7        0.854305    0.523179  0.748344     0.735099  0.715232  0.794702  \n",
       "8        0.748344    0.516556  0.701987     0.781457  0.695364  0.788079  \n",
       "9        0.801325    0.516556  0.735099     0.708609  0.682119  0.748344  \n",
       "10       0.827815    0.516556  0.794702     0.735099  0.761589  0.807947  \n",
       "11       0.774834    0.516556  0.741722     0.768212  0.701987  0.781457  \n",
       "12       0.781457    0.516556  0.695364     0.781457  0.741722  0.754967  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Matriz confusao ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[55, 18], [15, 63]]</td>\n",
       "      <td>[[51, 22], [8, 70]]</td>\n",
       "      <td>[[59, 14], [8, 70]]</td>\n",
       "      <td>[[59, 14], [7, 71]]</td>\n",
       "      <td>[[39, 34], [7, 71]]</td>\n",
       "      <td>[[59, 14], [7, 71]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[52, 21], [9, 69]]</td>\n",
       "      <td>[[46, 27], [11, 67]]</td>\n",
       "      <td>[[47, 26], [9, 69]]</td>\n",
       "      <td>[[54, 19], [9, 69]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[41, 32], [11, 67]]</td>\n",
       "      <td>[[33, 40], [6, 72]]</td>\n",
       "      <td>[[56, 17], [13, 65]]</td>\n",
       "      <td>[[55, 18], [14, 64]]</td>\n",
       "      <td>[[39, 34], [17, 61]]</td>\n",
       "      <td>[[50, 23], [19, 59]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[50, 23], [19, 59]]</td>\n",
       "      <td>[[35, 38], [13, 65]]</td>\n",
       "      <td>[[44, 29], [15, 63]]</td>\n",
       "      <td>[[50, 23], [19, 59]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[48, 25], [9, 69]]</td>\n",
       "      <td>[[55, 18], [11, 67]]</td>\n",
       "      <td>[[55, 18], [9, 69]]</td>\n",
       "      <td>[[56, 17], [7, 71]]</td>\n",
       "      <td>[[44, 29], [11, 67]]</td>\n",
       "      <td>[[51, 22], [7, 71]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[47, 26], [13, 65]]</td>\n",
       "      <td>[[49, 24], [13, 65]]</td>\n",
       "      <td>[[41, 32], [9, 69]]</td>\n",
       "      <td>[[53, 20], [9, 69]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[44, 29], [9, 69]]</td>\n",
       "      <td>[[39, 34], [7, 71]]</td>\n",
       "      <td>[[52, 21], [7, 71]]</td>\n",
       "      <td>[[55, 18], [10, 68]]</td>\n",
       "      <td>[[57, 16], [18, 60]]</td>\n",
       "      <td>[[48, 25], [10, 68]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[53, 20], [14, 64]]</td>\n",
       "      <td>[[38, 35], [10, 68]]</td>\n",
       "      <td>[[46, 27], [13, 65]]</td>\n",
       "      <td>[[48, 25], [13, 65]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[47, 26], [16, 62]]</td>\n",
       "      <td>[[38, 35], [6, 72]]</td>\n",
       "      <td>[[51, 22], [9, 69]]</td>\n",
       "      <td>[[53, 20], [11, 67]]</td>\n",
       "      <td>[[46, 27], [14, 64]]</td>\n",
       "      <td>[[49, 24], [11, 67]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[44, 29], [18, 60]]</td>\n",
       "      <td>[[51, 22], [13, 65]]</td>\n",
       "      <td>[[41, 32], [13, 65]]</td>\n",
       "      <td>[[46, 27], [7, 71]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[[35, 38], [9, 69]]</td>\n",
       "      <td>[[21, 52], [4, 74]]</td>\n",
       "      <td>[[38, 35], [10, 68]]</td>\n",
       "      <td>[[39, 34], [8, 70]]</td>\n",
       "      <td>[[44, 29], [19, 59]]</td>\n",
       "      <td>[[48, 25], [13, 65]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[40, 33], [10, 68]]</td>\n",
       "      <td>[[36, 37], [16, 62]]</td>\n",
       "      <td>[[28, 45], [4, 74]]</td>\n",
       "      <td>[[46, 27], [10, 68]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[[41, 32], [11, 67]]</td>\n",
       "      <td>[[33, 40], [6, 72]]</td>\n",
       "      <td>[[56, 17], [13, 65]]</td>\n",
       "      <td>[[55, 18], [14, 64]]</td>\n",
       "      <td>[[39, 34], [17, 61]]</td>\n",
       "      <td>[[52, 21], [20, 58]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[50, 23], [19, 59]]</td>\n",
       "      <td>[[35, 38], [13, 65]]</td>\n",
       "      <td>[[43, 30], [16, 62]]</td>\n",
       "      <td>[[50, 23], [19, 59]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[[50, 23], [15, 63]]</td>\n",
       "      <td>[[53, 20], [9, 69]]</td>\n",
       "      <td>[[53, 20], [7, 71]]</td>\n",
       "      <td>[[54, 19], [9, 69]]</td>\n",
       "      <td>[[49, 24], [14, 64]]</td>\n",
       "      <td>[[58, 15], [7, 71]]</td>\n",
       "      <td>[[1, 72], [0, 78]]</td>\n",
       "      <td>[[49, 24], [14, 64]]</td>\n",
       "      <td>[[47, 26], [14, 64]]</td>\n",
       "      <td>[[37, 36], [7, 71]]</td>\n",
       "      <td>[[53, 20], [11, 67]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[[42, 31], [11, 67]]</td>\n",
       "      <td>[[45, 28], [9, 69]]</td>\n",
       "      <td>[[49, 24], [10, 68]]</td>\n",
       "      <td>[[53, 20], [13, 65]]</td>\n",
       "      <td>[[56, 17], [23, 55]]</td>\n",
       "      <td>[[49, 24], [14, 64]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[41, 32], [13, 65]]</td>\n",
       "      <td>[[52, 21], [12, 66]]</td>\n",
       "      <td>[[44, 29], [17, 61]]</td>\n",
       "      <td>[[52, 21], [11, 67]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[[50, 23], [13, 65]]</td>\n",
       "      <td>[[44, 29], [12, 66]]</td>\n",
       "      <td>[[51, 22], [13, 65]]</td>\n",
       "      <td>[[53, 20], [14, 64]]</td>\n",
       "      <td>[[55, 18], [27, 51]]</td>\n",
       "      <td>[[56, 17], [13, 65]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[51, 22], [18, 60]]</td>\n",
       "      <td>[[48, 25], [19, 59]]</td>\n",
       "      <td>[[45, 28], [20, 58]]</td>\n",
       "      <td>[[53, 20], [18, 60]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[[55, 18], [18, 60]]</td>\n",
       "      <td>[[52, 21], [10, 68]]</td>\n",
       "      <td>[[55, 18], [11, 67]]</td>\n",
       "      <td>[[56, 17], [11, 67]]</td>\n",
       "      <td>[[51, 22], [20, 58]]</td>\n",
       "      <td>[[57, 16], [10, 68]]</td>\n",
       "      <td>[[1, 72], [1, 77]]</td>\n",
       "      <td>[[51, 22], [9, 69]]</td>\n",
       "      <td>[[47, 26], [14, 64]]</td>\n",
       "      <td>[[44, 29], [7, 71]]</td>\n",
       "      <td>[[53, 20], [9, 69]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[[42, 31], [15, 63]]</td>\n",
       "      <td>[[41, 32], [12, 66]]</td>\n",
       "      <td>[[47, 26], [9, 69]]</td>\n",
       "      <td>[[48, 25], [8, 70]]</td>\n",
       "      <td>[[47, 26], [14, 64]]</td>\n",
       "      <td>[[54, 19], [15, 63]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[55, 18], [21, 57]]</td>\n",
       "      <td>[[48, 25], [10, 68]]</td>\n",
       "      <td>[[40, 33], [12, 66]]</td>\n",
       "      <td>[[55, 18], [15, 63]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[[39, 34], [11, 67]]</td>\n",
       "      <td>[[39, 34], [7, 71]]</td>\n",
       "      <td>[[46, 27], [9, 69]]</td>\n",
       "      <td>[[41, 32], [11, 67]]</td>\n",
       "      <td>[[48, 25], [17, 61]]</td>\n",
       "      <td>[[50, 23], [10, 68]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[39, 34], [12, 66]]</td>\n",
       "      <td>[[51, 22], [11, 67]]</td>\n",
       "      <td>[[49, 24], [15, 63]]</td>\n",
       "      <td>[[45, 28], [9, 69]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Nearest Neighbors            Linear SVM               RBF SVM  \\\n",
       "0   [[55, 18], [15, 63]]   [[51, 22], [8, 70]]   [[59, 14], [8, 70]]   \n",
       "1   [[41, 32], [11, 67]]   [[33, 40], [6, 72]]  [[56, 17], [13, 65]]   \n",
       "2    [[48, 25], [9, 69]]  [[55, 18], [11, 67]]   [[55, 18], [9, 69]]   \n",
       "3    [[44, 29], [9, 69]]   [[39, 34], [7, 71]]   [[52, 21], [7, 71]]   \n",
       "4   [[47, 26], [16, 62]]   [[38, 35], [6, 72]]   [[51, 22], [9, 69]]   \n",
       "5    [[35, 38], [9, 69]]   [[21, 52], [4, 74]]  [[38, 35], [10, 68]]   \n",
       "6   [[41, 32], [11, 67]]   [[33, 40], [6, 72]]  [[56, 17], [13, 65]]   \n",
       "7   [[50, 23], [15, 63]]   [[53, 20], [9, 69]]   [[53, 20], [7, 71]]   \n",
       "8   [[42, 31], [11, 67]]   [[45, 28], [9, 69]]  [[49, 24], [10, 68]]   \n",
       "9   [[50, 23], [13, 65]]  [[44, 29], [12, 66]]  [[51, 22], [13, 65]]   \n",
       "10  [[55, 18], [18, 60]]  [[52, 21], [10, 68]]  [[55, 18], [11, 67]]   \n",
       "11  [[42, 31], [15, 63]]  [[41, 32], [12, 66]]   [[47, 26], [9, 69]]   \n",
       "12  [[39, 34], [11, 67]]   [[39, 34], [7, 71]]   [[46, 27], [9, 69]]   \n",
       "\n",
       "        Gaussian Process         Decision Tree         Random Forest  \\\n",
       "0    [[59, 14], [7, 71]]   [[39, 34], [7, 71]]   [[59, 14], [7, 71]]   \n",
       "1   [[55, 18], [14, 64]]  [[39, 34], [17, 61]]  [[50, 23], [19, 59]]   \n",
       "2    [[56, 17], [7, 71]]  [[44, 29], [11, 67]]   [[51, 22], [7, 71]]   \n",
       "3   [[55, 18], [10, 68]]  [[57, 16], [18, 60]]  [[48, 25], [10, 68]]   \n",
       "4   [[53, 20], [11, 67]]  [[46, 27], [14, 64]]  [[49, 24], [11, 67]]   \n",
       "5    [[39, 34], [8, 70]]  [[44, 29], [19, 59]]  [[48, 25], [13, 65]]   \n",
       "6   [[55, 18], [14, 64]]  [[39, 34], [17, 61]]  [[52, 21], [20, 58]]   \n",
       "7    [[54, 19], [9, 69]]  [[49, 24], [14, 64]]   [[58, 15], [7, 71]]   \n",
       "8   [[53, 20], [13, 65]]  [[56, 17], [23, 55]]  [[49, 24], [14, 64]]   \n",
       "9   [[53, 20], [14, 64]]  [[55, 18], [27, 51]]  [[56, 17], [13, 65]]   \n",
       "10  [[56, 17], [11, 67]]  [[51, 22], [20, 58]]  [[57, 16], [10, 68]]   \n",
       "11   [[48, 25], [8, 70]]  [[47, 26], [14, 64]]  [[54, 19], [15, 63]]   \n",
       "12  [[41, 32], [11, 67]]  [[48, 25], [17, 61]]  [[50, 23], [10, 68]]   \n",
       "\n",
       "            Neural Net              AdaBoost           Naive Bayes  \\\n",
       "0   [[0, 73], [0, 78]]   [[52, 21], [9, 69]]  [[46, 27], [11, 67]]   \n",
       "1   [[0, 73], [0, 78]]  [[50, 23], [19, 59]]  [[35, 38], [13, 65]]   \n",
       "2   [[0, 73], [0, 78]]  [[47, 26], [13, 65]]  [[49, 24], [13, 65]]   \n",
       "3   [[0, 73], [0, 78]]  [[53, 20], [14, 64]]  [[38, 35], [10, 68]]   \n",
       "4   [[0, 73], [0, 78]]  [[44, 29], [18, 60]]  [[51, 22], [13, 65]]   \n",
       "5   [[0, 73], [0, 78]]  [[40, 33], [10, 68]]  [[36, 37], [16, 62]]   \n",
       "6   [[0, 73], [0, 78]]  [[50, 23], [19, 59]]  [[35, 38], [13, 65]]   \n",
       "7   [[1, 72], [0, 78]]  [[49, 24], [14, 64]]  [[47, 26], [14, 64]]   \n",
       "8   [[0, 73], [0, 78]]  [[41, 32], [13, 65]]  [[52, 21], [12, 66]]   \n",
       "9   [[0, 73], [0, 78]]  [[51, 22], [18, 60]]  [[48, 25], [19, 59]]   \n",
       "10  [[1, 72], [1, 77]]   [[51, 22], [9, 69]]  [[47, 26], [14, 64]]   \n",
       "11  [[0, 73], [0, 78]]  [[55, 18], [21, 57]]  [[48, 25], [10, 68]]   \n",
       "12  [[0, 73], [0, 78]]  [[39, 34], [12, 66]]  [[51, 22], [11, 67]]   \n",
       "\n",
       "                     QDA               XGBoost  \n",
       "0    [[47, 26], [9, 69]]   [[54, 19], [9, 69]]  \n",
       "1   [[44, 29], [15, 63]]  [[50, 23], [19, 59]]  \n",
       "2    [[41, 32], [9, 69]]   [[53, 20], [9, 69]]  \n",
       "3   [[46, 27], [13, 65]]  [[48, 25], [13, 65]]  \n",
       "4   [[41, 32], [13, 65]]   [[46, 27], [7, 71]]  \n",
       "5    [[28, 45], [4, 74]]  [[46, 27], [10, 68]]  \n",
       "6   [[43, 30], [16, 62]]  [[50, 23], [19, 59]]  \n",
       "7    [[37, 36], [7, 71]]  [[53, 20], [11, 67]]  \n",
       "8   [[44, 29], [17, 61]]  [[52, 21], [11, 67]]  \n",
       "9   [[45, 28], [20, 58]]  [[53, 20], [18, 60]]  \n",
       "10   [[44, 29], [7, 71]]   [[53, 20], [9, 69]]  \n",
       "11  [[40, 33], [12, 66]]  [[55, 18], [15, 63]]  \n",
       "12  [[49, 24], [15, 63]]   [[45, 28], [9, 69]]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ 24 pontos - 8 raio ------\n",
      "--- Acuracia ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.523179</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.821192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.814570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.788079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.622517</td>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.576159</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.589404</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.701987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.668874</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.668874</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.629139</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.781457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.589404</td>\n",
       "      <td>0.615894</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.596026</td>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.655629</td>\n",
       "      <td>0.629139</td>\n",
       "      <td>0.649007</td>\n",
       "      <td>0.688742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.814570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.682119</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.774834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.860927</td>\n",
       "      <td>0.867550</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.827815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.655629</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.754967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.668874</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.748344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.642384</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.794702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.794702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.721854    0.754967  0.801325          0.807947       0.735099   \n",
       "1            0.708609    0.794702  0.827815          0.821192       0.721854   \n",
       "2            0.708609    0.788079  0.788079          0.788079       0.735099   \n",
       "3            0.622517    0.675497  0.741722          0.761589       0.576159   \n",
       "4            0.668874    0.721854  0.688742          0.728477       0.668874   \n",
       "5            0.589404    0.615894  0.695364          0.715232       0.596026   \n",
       "6            0.708609    0.794702  0.827815          0.821192       0.721854   \n",
       "7            0.715232    0.794702  0.774834          0.801325       0.682119   \n",
       "8            0.715232    0.847682  0.860927          0.867550       0.768212   \n",
       "9            0.761589    0.768212  0.768212          0.801325       0.708609   \n",
       "10           0.701987    0.794702  0.821192          0.807947       0.668874   \n",
       "11           0.748344    0.807947  0.821192          0.827815       0.642384   \n",
       "12           0.695364    0.794702  0.768212          0.814570       0.695364   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.794702    0.523179  0.774834     0.688742  0.781457  0.821192  \n",
       "1        0.821192    0.516556  0.801325     0.741722  0.774834  0.814570  \n",
       "2        0.788079    0.516556  0.788079     0.695364  0.735099  0.788079  \n",
       "3        0.708609    0.516556  0.721854     0.589404  0.715232  0.701987  \n",
       "4        0.768212    0.516556  0.629139     0.695364  0.741722  0.781457  \n",
       "5        0.675497    0.516556  0.655629     0.629139  0.649007  0.688742  \n",
       "6        0.827815    0.516556  0.801325     0.741722  0.781457  0.814570  \n",
       "7        0.794702    0.516556  0.748344     0.728477  0.774834  0.774834  \n",
       "8        0.854305    0.516556  0.754967     0.754967  0.728477  0.827815  \n",
       "9        0.788079    0.516556  0.715232     0.655629  0.761589  0.754967  \n",
       "10       0.754967    0.516556  0.761589     0.708609  0.801325  0.748344  \n",
       "11       0.794702    0.516556  0.761589     0.721854  0.675497  0.794702  \n",
       "12       0.774834    0.516556  0.735099     0.741722  0.748344  0.794702  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- F1 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.718557</td>\n",
       "      <td>0.749939</td>\n",
       "      <td>0.799524</td>\n",
       "      <td>0.804728</td>\n",
       "      <td>0.735030</td>\n",
       "      <td>0.793099</td>\n",
       "      <td>0.366499</td>\n",
       "      <td>0.772165</td>\n",
       "      <td>0.676393</td>\n",
       "      <td>0.780239</td>\n",
       "      <td>0.819796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.700767</td>\n",
       "      <td>0.790490</td>\n",
       "      <td>0.825774</td>\n",
       "      <td>0.818797</td>\n",
       "      <td>0.710017</td>\n",
       "      <td>0.818797</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.800004</td>\n",
       "      <td>0.737393</td>\n",
       "      <td>0.770649</td>\n",
       "      <td>0.810389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.700767</td>\n",
       "      <td>0.785567</td>\n",
       "      <td>0.784895</td>\n",
       "      <td>0.784895</td>\n",
       "      <td>0.734936</td>\n",
       "      <td>0.786671</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.786671</td>\n",
       "      <td>0.684122</td>\n",
       "      <td>0.727970</td>\n",
       "      <td>0.785567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.605321</td>\n",
       "      <td>0.658657</td>\n",
       "      <td>0.735348</td>\n",
       "      <td>0.758007</td>\n",
       "      <td>0.526935</td>\n",
       "      <td>0.699374</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.714369</td>\n",
       "      <td>0.563819</td>\n",
       "      <td>0.698511</td>\n",
       "      <td>0.696992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.659963</td>\n",
       "      <td>0.714369</td>\n",
       "      <td>0.679637</td>\n",
       "      <td>0.720535</td>\n",
       "      <td>0.654782</td>\n",
       "      <td>0.766402</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.626675</td>\n",
       "      <td>0.689702</td>\n",
       "      <td>0.739706</td>\n",
       "      <td>0.777794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.578354</td>\n",
       "      <td>0.582616</td>\n",
       "      <td>0.684122</td>\n",
       "      <td>0.703934</td>\n",
       "      <td>0.584210</td>\n",
       "      <td>0.671151</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.646361</td>\n",
       "      <td>0.608651</td>\n",
       "      <td>0.641805</td>\n",
       "      <td>0.683525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.700767</td>\n",
       "      <td>0.790490</td>\n",
       "      <td>0.825774</td>\n",
       "      <td>0.818797</td>\n",
       "      <td>0.710017</td>\n",
       "      <td>0.825774</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.800004</td>\n",
       "      <td>0.737393</td>\n",
       "      <td>0.777794</td>\n",
       "      <td>0.810389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.705480</td>\n",
       "      <td>0.791953</td>\n",
       "      <td>0.770649</td>\n",
       "      <td>0.799524</td>\n",
       "      <td>0.681194</td>\n",
       "      <td>0.792565</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.746672</td>\n",
       "      <td>0.724841</td>\n",
       "      <td>0.772165</td>\n",
       "      <td>0.771451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.710459</td>\n",
       "      <td>0.846493</td>\n",
       "      <td>0.859841</td>\n",
       "      <td>0.866941</td>\n",
       "      <td>0.766125</td>\n",
       "      <td>0.854074</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.753054</td>\n",
       "      <td>0.751685</td>\n",
       "      <td>0.720535</td>\n",
       "      <td>0.826254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.759429</td>\n",
       "      <td>0.765799</td>\n",
       "      <td>0.766402</td>\n",
       "      <td>0.800004</td>\n",
       "      <td>0.703768</td>\n",
       "      <td>0.787106</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.713644</td>\n",
       "      <td>0.649228</td>\n",
       "      <td>0.760896</td>\n",
       "      <td>0.754058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.694632</td>\n",
       "      <td>0.792565</td>\n",
       "      <td>0.819796</td>\n",
       "      <td>0.806877</td>\n",
       "      <td>0.668961</td>\n",
       "      <td>0.752416</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.758763</td>\n",
       "      <td>0.705155</td>\n",
       "      <td>0.800746</td>\n",
       "      <td>0.746064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.746064</td>\n",
       "      <td>0.804728</td>\n",
       "      <td>0.820195</td>\n",
       "      <td>0.826671</td>\n",
       "      <td>0.641817</td>\n",
       "      <td>0.794485</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.760494</td>\n",
       "      <td>0.711589</td>\n",
       "      <td>0.660715</td>\n",
       "      <td>0.793941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.685709</td>\n",
       "      <td>0.791261</td>\n",
       "      <td>0.765799</td>\n",
       "      <td>0.811783</td>\n",
       "      <td>0.688496</td>\n",
       "      <td>0.773338</td>\n",
       "      <td>0.351890</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.738263</td>\n",
       "      <td>0.744563</td>\n",
       "      <td>0.793941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.718557    0.749939  0.799524          0.804728       0.735030   \n",
       "1            0.700767    0.790490  0.825774          0.818797       0.710017   \n",
       "2            0.700767    0.785567  0.784895          0.784895       0.734936   \n",
       "3            0.605321    0.658657  0.735348          0.758007       0.526935   \n",
       "4            0.659963    0.714369  0.679637          0.720535       0.654782   \n",
       "5            0.578354    0.582616  0.684122          0.703934       0.584210   \n",
       "6            0.700767    0.790490  0.825774          0.818797       0.710017   \n",
       "7            0.705480    0.791953  0.770649          0.799524       0.681194   \n",
       "8            0.710459    0.846493  0.859841          0.866941       0.766125   \n",
       "9            0.759429    0.765799  0.766402          0.800004       0.703768   \n",
       "10           0.694632    0.792565  0.819796          0.806877       0.668961   \n",
       "11           0.746064    0.804728  0.820195          0.826671       0.641817   \n",
       "12           0.685709    0.791261  0.765799          0.811783       0.688496   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.793099    0.366499  0.772165     0.676393  0.780239  0.819796  \n",
       "1        0.818797    0.351890  0.800004     0.737393  0.770649  0.810389  \n",
       "2        0.786671    0.351890  0.786671     0.684122  0.727970  0.785567  \n",
       "3        0.699374    0.351890  0.714369     0.563819  0.698511  0.696992  \n",
       "4        0.766402    0.351890  0.626675     0.689702  0.739706  0.777794  \n",
       "5        0.671151    0.351890  0.646361     0.608651  0.641805  0.683525  \n",
       "6        0.825774    0.351890  0.800004     0.737393  0.777794  0.810389  \n",
       "7        0.792565    0.351890  0.746672     0.724841  0.772165  0.771451  \n",
       "8        0.854074    0.351890  0.753054     0.751685  0.720535  0.826254  \n",
       "9        0.787106    0.351890  0.713644     0.649228  0.760896  0.754058  \n",
       "10       0.752416    0.351890  0.758763     0.705155  0.800746  0.746064  \n",
       "11       0.794485    0.351890  0.760494     0.711589  0.660715  0.793941  \n",
       "12       0.773338    0.351890  0.735099     0.738263  0.744563  0.793941  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Precision Score ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.728072</td>\n",
       "      <td>0.770317</td>\n",
       "      <td>0.808142</td>\n",
       "      <td>0.823141</td>\n",
       "      <td>0.737286</td>\n",
       "      <td>0.800141</td>\n",
       "      <td>0.752053</td>\n",
       "      <td>0.783307</td>\n",
       "      <td>0.712879</td>\n",
       "      <td>0.784668</td>\n",
       "      <td>0.827344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.725264</td>\n",
       "      <td>0.813151</td>\n",
       "      <td>0.838541</td>\n",
       "      <td>0.833347</td>\n",
       "      <td>0.754237</td>\n",
       "      <td>0.833347</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.805864</td>\n",
       "      <td>0.752790</td>\n",
       "      <td>0.789780</td>\n",
       "      <td>0.837010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.725264</td>\n",
       "      <td>0.797115</td>\n",
       "      <td>0.800262</td>\n",
       "      <td>0.800262</td>\n",
       "      <td>0.735032</td>\n",
       "      <td>0.792320</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.792320</td>\n",
       "      <td>0.718332</td>\n",
       "      <td>0.754554</td>\n",
       "      <td>0.797115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.638589</td>\n",
       "      <td>0.706843</td>\n",
       "      <td>0.759795</td>\n",
       "      <td>0.772308</td>\n",
       "      <td>0.609734</td>\n",
       "      <td>0.729153</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.739909</td>\n",
       "      <td>0.605075</td>\n",
       "      <td>0.762730</td>\n",
       "      <td>0.710579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.681330</td>\n",
       "      <td>0.739909</td>\n",
       "      <td>0.704969</td>\n",
       "      <td>0.749319</td>\n",
       "      <td>0.691771</td>\n",
       "      <td>0.772938</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.629796</td>\n",
       "      <td>0.704756</td>\n",
       "      <td>0.745735</td>\n",
       "      <td>0.795001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.593461</td>\n",
       "      <td>0.653650</td>\n",
       "      <td>0.718332</td>\n",
       "      <td>0.743737</td>\n",
       "      <td>0.601486</td>\n",
       "      <td>0.680561</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.666685</td>\n",
       "      <td>0.651882</td>\n",
       "      <td>0.656093</td>\n",
       "      <td>0.696508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.725264</td>\n",
       "      <td>0.813151</td>\n",
       "      <td>0.838541</td>\n",
       "      <td>0.833347</td>\n",
       "      <td>0.754237</td>\n",
       "      <td>0.838541</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.805864</td>\n",
       "      <td>0.752790</td>\n",
       "      <td>0.795001</td>\n",
       "      <td>0.837010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.738841</td>\n",
       "      <td>0.805568</td>\n",
       "      <td>0.789780</td>\n",
       "      <td>0.808142</td>\n",
       "      <td>0.682437</td>\n",
       "      <td>0.802602</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.751689</td>\n",
       "      <td>0.736120</td>\n",
       "      <td>0.783307</td>\n",
       "      <td>0.786285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.724649</td>\n",
       "      <td>0.854547</td>\n",
       "      <td>0.868149</td>\n",
       "      <td>0.871284</td>\n",
       "      <td>0.784125</td>\n",
       "      <td>0.855049</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.759337</td>\n",
       "      <td>0.763899</td>\n",
       "      <td>0.749319</td>\n",
       "      <td>0.835472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.767148</td>\n",
       "      <td>0.775134</td>\n",
       "      <td>0.772938</td>\n",
       "      <td>0.805864</td>\n",
       "      <td>0.730601</td>\n",
       "      <td>0.790619</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.717212</td>\n",
       "      <td>0.662244</td>\n",
       "      <td>0.762627</td>\n",
       "      <td>0.756430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.716251</td>\n",
       "      <td>0.802602</td>\n",
       "      <td>0.827344</td>\n",
       "      <td>0.811651</td>\n",
       "      <td>0.669283</td>\n",
       "      <td>0.761400</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.769498</td>\n",
       "      <td>0.714263</td>\n",
       "      <td>0.802722</td>\n",
       "      <td>0.753483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.753483</td>\n",
       "      <td>0.823141</td>\n",
       "      <td>0.825142</td>\n",
       "      <td>0.832951</td>\n",
       "      <td>0.642155</td>\n",
       "      <td>0.794898</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.763731</td>\n",
       "      <td>0.748838</td>\n",
       "      <td>0.701849</td>\n",
       "      <td>0.796636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.714222</td>\n",
       "      <td>0.809071</td>\n",
       "      <td>0.775134</td>\n",
       "      <td>0.828215</td>\n",
       "      <td>0.707477</td>\n",
       "      <td>0.778776</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.750009</td>\n",
       "      <td>0.758331</td>\n",
       "      <td>0.796636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.728072    0.770317  0.808142          0.823141       0.737286   \n",
       "1            0.725264    0.813151  0.838541          0.833347       0.754237   \n",
       "2            0.725264    0.797115  0.800262          0.800262       0.735032   \n",
       "3            0.638589    0.706843  0.759795          0.772308       0.609734   \n",
       "4            0.681330    0.739909  0.704969          0.749319       0.691771   \n",
       "5            0.593461    0.653650  0.718332          0.743737       0.601486   \n",
       "6            0.725264    0.813151  0.838541          0.833347       0.754237   \n",
       "7            0.738841    0.805568  0.789780          0.808142       0.682437   \n",
       "8            0.724649    0.854547  0.868149          0.871284       0.784125   \n",
       "9            0.767148    0.775134  0.772938          0.805864       0.730601   \n",
       "10           0.716251    0.802602  0.827344          0.811651       0.669283   \n",
       "11           0.753483    0.823141  0.825142          0.832951       0.642155   \n",
       "12           0.714222    0.809071  0.775134          0.828215       0.707477   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.800141    0.752053  0.783307     0.712879  0.784668  0.827344  \n",
       "1        0.833347    0.266830  0.805864     0.752790  0.789780  0.837010  \n",
       "2        0.792320    0.266830  0.792320     0.718332  0.754554  0.797115  \n",
       "3        0.729153    0.266830  0.739909     0.605075  0.762730  0.710579  \n",
       "4        0.772938    0.266830  0.629796     0.704756  0.745735  0.795001  \n",
       "5        0.680561    0.266830  0.666685     0.651882  0.656093  0.696508  \n",
       "6        0.838541    0.266830  0.805864     0.752790  0.795001  0.837010  \n",
       "7        0.802602    0.266830  0.751689     0.736120  0.783307  0.786285  \n",
       "8        0.855049    0.266830  0.759337     0.763899  0.749319  0.835472  \n",
       "9        0.790619    0.266830  0.717212     0.662244  0.762627  0.756430  \n",
       "10       0.761400    0.266830  0.769498     0.714263  0.802722  0.753483  \n",
       "11       0.794898    0.266830  0.763731     0.748838  0.701849  0.796636  \n",
       "12       0.778776    0.266830  0.735099     0.750009  0.758331  0.796636  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Recall Score ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.523179</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.821192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.814570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.788079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.622517</td>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.576159</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.589404</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.701987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.668874</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.688742</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.668874</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.629139</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.781457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.589404</td>\n",
       "      <td>0.615894</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.596026</td>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.655629</td>\n",
       "      <td>0.629139</td>\n",
       "      <td>0.649007</td>\n",
       "      <td>0.688742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.814570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.682119</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.774834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.847682</td>\n",
       "      <td>0.860927</td>\n",
       "      <td>0.867550</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>0.827815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.788079</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.655629</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.754967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.668874</td>\n",
       "      <td>0.754967</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.748344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>0.821192</td>\n",
       "      <td>0.827815</td>\n",
       "      <td>0.642384</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.721854</td>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.794702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.516556</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.748344</td>\n",
       "      <td>0.794702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nearest Neighbors  Linear SVM   RBF SVM  Gaussian Process  Decision Tree  \\\n",
       "0            0.721854    0.754967  0.801325          0.807947       0.735099   \n",
       "1            0.708609    0.794702  0.827815          0.821192       0.721854   \n",
       "2            0.708609    0.788079  0.788079          0.788079       0.735099   \n",
       "3            0.622517    0.675497  0.741722          0.761589       0.576159   \n",
       "4            0.668874    0.721854  0.688742          0.728477       0.668874   \n",
       "5            0.589404    0.615894  0.695364          0.715232       0.596026   \n",
       "6            0.708609    0.794702  0.827815          0.821192       0.721854   \n",
       "7            0.715232    0.794702  0.774834          0.801325       0.682119   \n",
       "8            0.715232    0.847682  0.860927          0.867550       0.768212   \n",
       "9            0.761589    0.768212  0.768212          0.801325       0.708609   \n",
       "10           0.701987    0.794702  0.821192          0.807947       0.668874   \n",
       "11           0.748344    0.807947  0.821192          0.827815       0.642384   \n",
       "12           0.695364    0.794702  0.768212          0.814570       0.695364   \n",
       "\n",
       "    Random Forest  Neural Net  AdaBoost  Naive Bayes       QDA   XGBoost  \n",
       "0        0.794702    0.523179  0.774834     0.688742  0.781457  0.821192  \n",
       "1        0.821192    0.516556  0.801325     0.741722  0.774834  0.814570  \n",
       "2        0.788079    0.516556  0.788079     0.695364  0.735099  0.788079  \n",
       "3        0.708609    0.516556  0.721854     0.589404  0.715232  0.701987  \n",
       "4        0.768212    0.516556  0.629139     0.695364  0.741722  0.781457  \n",
       "5        0.675497    0.516556  0.655629     0.629139  0.649007  0.688742  \n",
       "6        0.827815    0.516556  0.801325     0.741722  0.781457  0.814570  \n",
       "7        0.794702    0.516556  0.748344     0.728477  0.774834  0.774834  \n",
       "8        0.854305    0.516556  0.754967     0.754967  0.728477  0.827815  \n",
       "9        0.788079    0.516556  0.715232     0.655629  0.761589  0.754967  \n",
       "10       0.754967    0.516556  0.761589     0.708609  0.801325  0.748344  \n",
       "11       0.794702    0.516556  0.761589     0.721854  0.675497  0.794702  \n",
       "12       0.774834    0.516556  0.735099     0.741722  0.748344  0.794702  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Matriz confusao ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Gaussian Process</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Neural Net</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>QDA</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[45, 28], [14, 64]]</td>\n",
       "      <td>[[45, 28], [9, 69]]</td>\n",
       "      <td>[[52, 21], [9, 69]]</td>\n",
       "      <td>[[50, 23], [6, 72]]</td>\n",
       "      <td>[[56, 17], [23, 55]]</td>\n",
       "      <td>[[52, 21], [10, 68]]</td>\n",
       "      <td>[[1, 72], [0, 78]]</td>\n",
       "      <td>[[49, 24], [10, 68]]</td>\n",
       "      <td>[[36, 37], [10, 68]]</td>\n",
       "      <td>[[52, 21], [12, 66]]</td>\n",
       "      <td>[[54, 19], [8, 70]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[40, 33], [11, 67]]</td>\n",
       "      <td>[[48, 25], [6, 72]]</td>\n",
       "      <td>[[53, 20], [6, 72]]</td>\n",
       "      <td>[[52, 21], [6, 72]]</td>\n",
       "      <td>[[38, 35], [7, 71]]</td>\n",
       "      <td>[[52, 21], [6, 72]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[53, 20], [10, 68]]</td>\n",
       "      <td>[[45, 28], [11, 67]]</td>\n",
       "      <td>[[47, 26], [8, 70]]</td>\n",
       "      <td>[[49, 24], [4, 74]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[40, 33], [11, 67]]</td>\n",
       "      <td>[[50, 23], [9, 69]]</td>\n",
       "      <td>[[49, 24], [8, 70]]</td>\n",
       "      <td>[[49, 24], [8, 70]]</td>\n",
       "      <td>[[52, 21], [19, 59]]</td>\n",
       "      <td>[[52, 21], [11, 67]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[52, 21], [11, 67]]</td>\n",
       "      <td>[[37, 36], [10, 68]]</td>\n",
       "      <td>[[42, 31], [9, 69]]</td>\n",
       "      <td>[[50, 23], [9, 69]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[30, 43], [14, 64]]</td>\n",
       "      <td>[[33, 40], [9, 69]]</td>\n",
       "      <td>[[43, 30], [9, 69]]</td>\n",
       "      <td>[[47, 26], [10, 68]]</td>\n",
       "      <td>[[18, 55], [9, 69]]</td>\n",
       "      <td>[[39, 34], [10, 68]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[41, 32], [10, 68]]</td>\n",
       "      <td>[[25, 48], [14, 64]]</td>\n",
       "      <td>[[35, 38], [5, 73]]</td>\n",
       "      <td>[[42, 31], [14, 64]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[37, 36], [14, 64]]</td>\n",
       "      <td>[[41, 32], [10, 68]]</td>\n",
       "      <td>[[38, 35], [12, 66]]</td>\n",
       "      <td>[[41, 32], [9, 69]]</td>\n",
       "      <td>[[34, 39], [11, 67]]</td>\n",
       "      <td>[[50, 23], [12, 66]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[40, 33], [23, 55]]</td>\n",
       "      <td>[[41, 32], [14, 64]]</td>\n",
       "      <td>[[48, 25], [14, 64]]</td>\n",
       "      <td>[[48, 25], [8, 70]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[[31, 42], [20, 58]]</td>\n",
       "      <td>[[24, 49], [9, 69]]</td>\n",
       "      <td>[[37, 36], [10, 68]]</td>\n",
       "      <td>[[38, 35], [8, 70]]</td>\n",
       "      <td>[[31, 42], [19, 59]]</td>\n",
       "      <td>[[41, 32], [17, 61]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[36, 37], [15, 63]]</td>\n",
       "      <td>[[29, 44], [12, 66]]</td>\n",
       "      <td>[[37, 36], [17, 61]]</td>\n",
       "      <td>[[41, 32], [15, 63]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[[40, 33], [11, 67]]</td>\n",
       "      <td>[[48, 25], [6, 72]]</td>\n",
       "      <td>[[53, 20], [6, 72]]</td>\n",
       "      <td>[[52, 21], [6, 72]]</td>\n",
       "      <td>[[38, 35], [7, 71]]</td>\n",
       "      <td>[[53, 20], [6, 72]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[53, 20], [10, 68]]</td>\n",
       "      <td>[[45, 28], [11, 67]]</td>\n",
       "      <td>[[48, 25], [8, 70]]</td>\n",
       "      <td>[[49, 24], [4, 74]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[[39, 34], [9, 69]]</td>\n",
       "      <td>[[50, 23], [8, 70]]</td>\n",
       "      <td>[[47, 26], [8, 70]]</td>\n",
       "      <td>[[52, 21], [9, 69]]</td>\n",
       "      <td>[[46, 27], [21, 57]]</td>\n",
       "      <td>[[51, 22], [9, 69]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[49, 24], [14, 64]]</td>\n",
       "      <td>[[45, 28], [13, 65]]</td>\n",
       "      <td>[[49, 24], [10, 68]]</td>\n",
       "      <td>[[48, 25], [9, 69]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[[43, 30], [13, 65]]</td>\n",
       "      <td>[[56, 17], [6, 72]]</td>\n",
       "      <td>[[57, 16], [5, 73]]</td>\n",
       "      <td>[[59, 14], [6, 72]]</td>\n",
       "      <td>[[64, 9], [26, 52]]</td>\n",
       "      <td>[[60, 13], [9, 69]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[49, 24], [13, 65]]</td>\n",
       "      <td>[[47, 26], [11, 67]]</td>\n",
       "      <td>[[41, 32], [9, 69]]</td>\n",
       "      <td>[[54, 19], [7, 71]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[[49, 24], [12, 66]]</td>\n",
       "      <td>[[49, 24], [11, 67]]</td>\n",
       "      <td>[[50, 23], [12, 66]]</td>\n",
       "      <td>[[53, 20], [10, 68]]</td>\n",
       "      <td>[[62, 11], [33, 45]]</td>\n",
       "      <td>[[53, 20], [12, 66]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[47, 26], [17, 61]]</td>\n",
       "      <td>[[38, 35], [17, 61]]</td>\n",
       "      <td>[[52, 21], [15, 63]]</td>\n",
       "      <td>[[51, 22], [15, 63]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[[40, 33], [12, 66]]</td>\n",
       "      <td>[[51, 22], [9, 69]]</td>\n",
       "      <td>[[54, 19], [8, 70]]</td>\n",
       "      <td>[[54, 19], [10, 68]]</td>\n",
       "      <td>[[49, 24], [26, 52]]</td>\n",
       "      <td>[[48, 25], [12, 66]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[48, 25], [11, 67]]</td>\n",
       "      <td>[[44, 29], [15, 63]]</td>\n",
       "      <td>[[55, 18], [12, 66]]</td>\n",
       "      <td>[[48, 25], [13, 65]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[[48, 25], [13, 65]]</td>\n",
       "      <td>[[50, 23], [6, 72]]</td>\n",
       "      <td>[[55, 18], [9, 69]]</td>\n",
       "      <td>[[55, 18], [8, 70]]</td>\n",
       "      <td>[[44, 29], [25, 53]]</td>\n",
       "      <td>[[56, 17], [14, 64]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[51, 22], [14, 64]]</td>\n",
       "      <td>[[39, 34], [8, 70]]</td>\n",
       "      <td>[[34, 39], [10, 68]]</td>\n",
       "      <td>[[54, 19], [12, 66]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[[38, 35], [11, 67]]</td>\n",
       "      <td>[[49, 24], [7, 71]]</td>\n",
       "      <td>[[49, 24], [11, 67]]</td>\n",
       "      <td>[[51, 22], [6, 72]]</td>\n",
       "      <td>[[40, 33], [13, 65]]</td>\n",
       "      <td>[[51, 22], [12, 66]]</td>\n",
       "      <td>[[0, 73], [0, 78]]</td>\n",
       "      <td>[[53, 20], [20, 58]]</td>\n",
       "      <td>[[46, 27], [12, 66]]</td>\n",
       "      <td>[[46, 27], [11, 67]]</td>\n",
       "      <td>[[54, 19], [12, 66]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Nearest Neighbors            Linear SVM               RBF SVM  \\\n",
       "0   [[45, 28], [14, 64]]   [[45, 28], [9, 69]]   [[52, 21], [9, 69]]   \n",
       "1   [[40, 33], [11, 67]]   [[48, 25], [6, 72]]   [[53, 20], [6, 72]]   \n",
       "2   [[40, 33], [11, 67]]   [[50, 23], [9, 69]]   [[49, 24], [8, 70]]   \n",
       "3   [[30, 43], [14, 64]]   [[33, 40], [9, 69]]   [[43, 30], [9, 69]]   \n",
       "4   [[37, 36], [14, 64]]  [[41, 32], [10, 68]]  [[38, 35], [12, 66]]   \n",
       "5   [[31, 42], [20, 58]]   [[24, 49], [9, 69]]  [[37, 36], [10, 68]]   \n",
       "6   [[40, 33], [11, 67]]   [[48, 25], [6, 72]]   [[53, 20], [6, 72]]   \n",
       "7    [[39, 34], [9, 69]]   [[50, 23], [8, 70]]   [[47, 26], [8, 70]]   \n",
       "8   [[43, 30], [13, 65]]   [[56, 17], [6, 72]]   [[57, 16], [5, 73]]   \n",
       "9   [[49, 24], [12, 66]]  [[49, 24], [11, 67]]  [[50, 23], [12, 66]]   \n",
       "10  [[40, 33], [12, 66]]   [[51, 22], [9, 69]]   [[54, 19], [8, 70]]   \n",
       "11  [[48, 25], [13, 65]]   [[50, 23], [6, 72]]   [[55, 18], [9, 69]]   \n",
       "12  [[38, 35], [11, 67]]   [[49, 24], [7, 71]]  [[49, 24], [11, 67]]   \n",
       "\n",
       "        Gaussian Process         Decision Tree         Random Forest  \\\n",
       "0    [[50, 23], [6, 72]]  [[56, 17], [23, 55]]  [[52, 21], [10, 68]]   \n",
       "1    [[52, 21], [6, 72]]   [[38, 35], [7, 71]]   [[52, 21], [6, 72]]   \n",
       "2    [[49, 24], [8, 70]]  [[52, 21], [19, 59]]  [[52, 21], [11, 67]]   \n",
       "3   [[47, 26], [10, 68]]   [[18, 55], [9, 69]]  [[39, 34], [10, 68]]   \n",
       "4    [[41, 32], [9, 69]]  [[34, 39], [11, 67]]  [[50, 23], [12, 66]]   \n",
       "5    [[38, 35], [8, 70]]  [[31, 42], [19, 59]]  [[41, 32], [17, 61]]   \n",
       "6    [[52, 21], [6, 72]]   [[38, 35], [7, 71]]   [[53, 20], [6, 72]]   \n",
       "7    [[52, 21], [9, 69]]  [[46, 27], [21, 57]]   [[51, 22], [9, 69]]   \n",
       "8    [[59, 14], [6, 72]]   [[64, 9], [26, 52]]   [[60, 13], [9, 69]]   \n",
       "9   [[53, 20], [10, 68]]  [[62, 11], [33, 45]]  [[53, 20], [12, 66]]   \n",
       "10  [[54, 19], [10, 68]]  [[49, 24], [26, 52]]  [[48, 25], [12, 66]]   \n",
       "11   [[55, 18], [8, 70]]  [[44, 29], [25, 53]]  [[56, 17], [14, 64]]   \n",
       "12   [[51, 22], [6, 72]]  [[40, 33], [13, 65]]  [[51, 22], [12, 66]]   \n",
       "\n",
       "            Neural Net              AdaBoost           Naive Bayes  \\\n",
       "0   [[1, 72], [0, 78]]  [[49, 24], [10, 68]]  [[36, 37], [10, 68]]   \n",
       "1   [[0, 73], [0, 78]]  [[53, 20], [10, 68]]  [[45, 28], [11, 67]]   \n",
       "2   [[0, 73], [0, 78]]  [[52, 21], [11, 67]]  [[37, 36], [10, 68]]   \n",
       "3   [[0, 73], [0, 78]]  [[41, 32], [10, 68]]  [[25, 48], [14, 64]]   \n",
       "4   [[0, 73], [0, 78]]  [[40, 33], [23, 55]]  [[41, 32], [14, 64]]   \n",
       "5   [[0, 73], [0, 78]]  [[36, 37], [15, 63]]  [[29, 44], [12, 66]]   \n",
       "6   [[0, 73], [0, 78]]  [[53, 20], [10, 68]]  [[45, 28], [11, 67]]   \n",
       "7   [[0, 73], [0, 78]]  [[49, 24], [14, 64]]  [[45, 28], [13, 65]]   \n",
       "8   [[0, 73], [0, 78]]  [[49, 24], [13, 65]]  [[47, 26], [11, 67]]   \n",
       "9   [[0, 73], [0, 78]]  [[47, 26], [17, 61]]  [[38, 35], [17, 61]]   \n",
       "10  [[0, 73], [0, 78]]  [[48, 25], [11, 67]]  [[44, 29], [15, 63]]   \n",
       "11  [[0, 73], [0, 78]]  [[51, 22], [14, 64]]   [[39, 34], [8, 70]]   \n",
       "12  [[0, 73], [0, 78]]  [[53, 20], [20, 58]]  [[46, 27], [12, 66]]   \n",
       "\n",
       "                     QDA               XGBoost  \n",
       "0   [[52, 21], [12, 66]]   [[54, 19], [8, 70]]  \n",
       "1    [[47, 26], [8, 70]]   [[49, 24], [4, 74]]  \n",
       "2    [[42, 31], [9, 69]]   [[50, 23], [9, 69]]  \n",
       "3    [[35, 38], [5, 73]]  [[42, 31], [14, 64]]  \n",
       "4   [[48, 25], [14, 64]]   [[48, 25], [8, 70]]  \n",
       "5   [[37, 36], [17, 61]]  [[41, 32], [15, 63]]  \n",
       "6    [[48, 25], [8, 70]]   [[49, 24], [4, 74]]  \n",
       "7   [[49, 24], [10, 68]]   [[48, 25], [9, 69]]  \n",
       "8    [[41, 32], [9, 69]]   [[54, 19], [7, 71]]  \n",
       "9   [[52, 21], [15, 63]]  [[51, 22], [15, 63]]  \n",
       "10  [[55, 18], [12, 66]]  [[48, 25], [13, 65]]  \n",
       "11  [[34, 39], [10, 68]]  [[54, 19], [12, 66]]  \n",
       "12  [[46, 27], [11, 67]]  [[54, 19], [12, 66]]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "obterResultados(4,1)\n",
    "obterResultados(8,1)\n",
    "obterResultados(8,2)\n",
    "obterResultados(12,2)\n",
    "obterResultados(16,2)\n",
    "obterResultados(16,3)\n",
    "obterResultados(24,3)\n",
    "obterResultados(24,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
